#!/usr/bin/env python3
"""
Test script for AI Tráº¯c Nghiá»‡m Pipeline
Kiá»ƒm tra pipeline xá»­ lÃ½ OMR má»›i vá»›i 7 bÆ°á»›c:
1. Äá»c áº£nh Ä‘áº§u vÃ o (grayscale + blur)
2. PhÃ¡t hiá»‡n marker Ä‘en lá»›n (vuÃ´ng) + perspective transform
3. Cáº¯t áº£nh thÃ nh 2 vÃ¹ng (top: thÃ´ng tin, bottom: cÃ¢u tráº£ lá»i)
4. PhÃ¢n tÃ­ch vÃ¹ng tráº£ lá»i (3 sections)
5. Tá»•ng há»£p káº¿t quáº£
6. Táº¡o áº£nh káº¿t quáº£ Ä‘Ã¡nh dáº¥u
"""

import sys
import os
from pathlib import Path

# Add the app directory to Python path
sys.path.insert(0, str(Path(__file__).parent / "app"))

from services.omr_pipeline_processor import omr_pipeline_processor

def test_pipeline_processing():
    """Test the AI Tráº¯c Nghiá»‡m Pipeline"""
    
    print("ğŸš€ AI Tráº¯c Nghiá»‡m Pipeline Test")
    print("=" * 60)
    print("ğŸ“‹ Pipeline Description:")
    print("   1. Äá»c áº£nh Ä‘áº§u vÃ o (grayscale + blur)")
    print("   2. PhÃ¡t hiá»‡n marker Ä‘en lá»›n (vuÃ´ng) + perspective transform")
    print("   3. Cáº¯t áº£nh thÃ nh 2 vÃ¹ng (top: thÃ´ng tin, bottom: cÃ¢u tráº£ lá»i)")
    print("   4. PhÃ¢n tÃ­ch vÃ¹ng tráº£ lá»i:")
    print("      â€¢ Section I: 40 cÃ¢u ABCD (4 cá»™t x 10 hÃ ng)")
    print("      â€¢ Section II: 8 cÃ¢u Ä‘Ãºng/sai vá»›i sub-questions")
    print("      â€¢ Section III: 6 cÃ¢u Ä‘iá»n sá»‘ 0-9")
    print("   5. Tá»•ng há»£p káº¿t quáº£")
    print("   6. Táº¡o áº£nh káº¿t quáº£ Ä‘Ã¡nh dáº¥u")
    print("=" * 60)
    
    # Test with sample.jpg
    sample_path = "data/grading/sample.jpg"
    
    if not os.path.exists(sample_path):
        print(f"âŒ Sample file not found: {sample_path}")
        return False
    
    print(f"âœ… Testing with: {sample_path}")
    print(f"ğŸ“ File size: {os.path.getsize(sample_path) / 1024:.1f} KB")
    
    try:
        # Process with pipeline
        print("\nğŸ”„ Processing with AI Tráº¯c Nghiá»‡m Pipeline...")
        result = omr_pipeline_processor.process_omr_sheet(sample_path)
        
        if not result.get('success'):
            print(f"âŒ Pipeline processing failed: {result.get('error')}")
            return False
        
        print(f"âœ… Pipeline processing successful!")
        print(f"   Processing steps: {result.get('processing_steps', 0)}")
        print(f"   Total markers detected: {result.get('total_markers', 0)}")
        
        # Analyze results
        results_data = result.get('results', {})
        print(f"\nğŸ“Š Results Analysis:")
        
        # Section I Analysis
        section1 = results_data.get('Section I', {})
        print(f"   ğŸ“ Section I (Multiple Choice ABCD):")
        print(f"      Total questions: {len(section1)}")
        if section1:
            # Show first 5 answers
            sample_answers = list(section1.items())[:5]
            for q, answer in sample_answers:
                print(f"      {q}: {answer}")
            if len(section1) > 5:
                print(f"      ... and {len(section1) - 5} more answers")
        
        # Section II Analysis
        section2 = results_data.get('Section II', {})
        print(f"   âœ… Section II (True/False):")
        print(f"      Total questions: {len(section2)}")
        if section2:
            # Show first 3 questions
            sample_tf = list(section2.items())[:3]
            for q, sub_answers in sample_tf:
                print(f"      {q}: {sub_answers}")
        
        # Section III Analysis
        section3 = results_data.get('Section III', {})
        print(f"   ğŸ”¢ Section III (Digit Selection):")
        print(f"      Total questions: {len(section3)}")
        if section3:
            # Show all digit answers
            for q, digit in section3.items():
                print(f"      {q}: {digit}")
        
        # Summary
        summary = results_data.get('summary', {})
        print(f"\nğŸ“ˆ Summary:")
        print(f"   Total Section I: {summary.get('total_section1', 0)}")
        print(f"   Total Section II: {summary.get('total_section2', 0)}")
        print(f"   Total Section III: {summary.get('total_section3', 0)}")
        print(f"   Grand Total: {summary.get('total_questions', 0)}")
        
        # Debug images
        debug_dir = Path(result.get('debug_dir', 'data/grading/debug'))
        if debug_dir.exists():
            debug_files = list(debug_dir.glob("*.jpg"))
            print(f"\nğŸ–¼ï¸ Debug Images Generated: {len(debug_files)}")
            
            # Show key pipeline images
            pipeline_images = [
                "01_original.jpg",
                "02_preprocessed.jpg",
                "03_markers_detected.jpg",
                "04_aligned.jpg",
                "05_top_region.jpg",
                "06_bottom_region.jpg",
                "07_section1_abcd.jpg",
                "08_section2_true_false.jpg",
                "09_section3_digits.jpg",
                "99_final_result.jpg"
            ]
            
            for img_name in pipeline_images:
                img_path = debug_dir / img_name
                if img_path.exists():
                    print(f"   âœ… {img_name}")
                else:
                    print(f"   âŒ {img_name} (missing)")
        
        # Expected vs Actual
        print(f"\nğŸ¯ Pipeline Validation:")
        expected_sections = {
            "Section I": 40,  # 40 cÃ¢u ABCD
            "Section II": 8,  # 8 cÃ¢u True/False
            "Section III": 6  # 6 cÃ¢u digits
        }
        
        for section_name, expected_count in expected_sections.items():
            actual_count = len(results_data.get(section_name, {}))
            if actual_count >= expected_count:
                print(f"   âœ… {section_name}: {actual_count} questions (â‰¥{expected_count} expected)")
            else:
                print(f"   âš ï¸ {section_name}: {actual_count} questions ({expected_count} expected)")
        
        print(f"\nğŸ‰ AI Tráº¯c Nghiá»‡m Pipeline test completed!")
        print(f"ğŸ“ Check outputs:")
        print(f"   Debug images: {debug_dir}")
        print(f"   Web viewer: http://localhost:8000/api/v1/omr_debug/viewer")
        print(f"   Pipeline API: http://localhost:8000/api/v1/omr_debug/process_pipeline")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error during pipeline testing: {e}")
        import traceback
        traceback.print_exc()
        return False

def show_pipeline_comparison():
    """Show comparison between old system and new pipeline"""
    print("\nğŸ“Š System Comparison:")
    print("=" * 60)
    print("OLD SYSTEM (OMRDebugProcessor):")
    print("   â€¢ Student ID: 8 digits")
    print("   â€¢ Test Code: 4 digits")
    print("   â€¢ Answers: 60 questions (4 regions)")
    print("   â€¢ Processing: 12 steps")
    print("   â€¢ Focus: Debug vÃ  coordinate-based")
    print()
    print("NEW PIPELINE (AI Tráº¯c Nghiá»‡m):")
    print("   â€¢ Section I: 40 cÃ¢u Multiple Choice (A/B/C/D)")
    print("   â€¢ Section II: 8 cÃ¢u True/False vá»›i sub-questions")
    print("   â€¢ Section III: 6 cÃ¢u digit selection (0-9)")
    print("   â€¢ Processing: 7 steps")
    print("   â€¢ Focus: Marker-based vÃ  intelligent detection")
    print("=" * 60)

def test_api_integration():
    """Test API integration"""
    print("\nğŸŒ API Integration Test:")
    print("=" * 40)
    
    try:
        import requests
        
        # Test pipeline endpoint
        response = requests.post("http://localhost:8000/api/v1/omr_debug/process_pipeline")
        
        if response.status_code == 200:
            data = response.json()
            print("âœ… Pipeline API endpoint working")
            print(f"   Pipeline version: {data.get('pipeline_version')}")
            print(f"   Processing steps: {data.get('processing_steps')}")
            print(f"   Total markers: {data.get('total_markers')}")
        else:
            print(f"âŒ Pipeline API failed: {response.status_code}")
            
    except Exception as e:
        print(f"âš ï¸ API test skipped (server not running): {e}")
        print("ğŸ’¡ Start server with: python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload")

if __name__ == "__main__":
    print("ğŸš€ AI Tráº¯c Nghiá»‡m Pipeline Test Suite")
    print("=" * 60)
    
    # Show comparison
    show_pipeline_comparison()
    
    # Run pipeline test
    success = test_pipeline_processing()
    
    # Test API integration
    test_api_integration()
    
    if success:
        print("\nâœ… AI Tráº¯c Nghiá»‡m Pipeline test completed successfully!")
        print("ğŸ’¡ The new pipeline is ready for production!")
        sys.exit(0)
    else:
        print("\nâŒ AI Tráº¯c Nghiá»‡m Pipeline test failed!")
        print("ğŸ’¡ Check the debug images and logs for issues.")
        sys.exit(1)
