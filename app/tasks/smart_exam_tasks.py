"""
Celery tasks cho Smart Exam Generation
X·ª≠ l√Ω t·∫°o ƒë·ªÅ thi th√¥ng minh theo chu·∫©n THPT 2025 b·∫•t ƒë·ªìng b·ªô v·ªõi progress tracking
"""

import logging
import asyncio
import os
from typing import Dict, Any

from app.core.celery_app import celery_app
from app.services.mongodb_task_service import get_mongodb_task_service
from app.services.smart_exam_generation_service import get_smart_exam_generation_service
from app.services.textbook_retrieval_service import get_textbook_retrieval_service
from app.services.smart_exam_docx_service import smart_exam_docx_service
from app.services.google_drive_service import get_google_drive_service
from app.services.kafka_service import kafka_service, safe_kafka_call
from app.models.smart_exam_models import SmartExamRequest

logger = logging.getLogger(__name__)



def run_async_task(coro):
    """Helper function ƒë·ªÉ ch·∫°y async code trong Celery worker"""
    try:
        # Always create a new event loop for each task to avoid "Event loop is closed" error
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            return loop.run_until_complete(coro)
        finally:
            # Always close the loop after use
            try:
                # Cancel all pending tasks
                pending = asyncio.all_tasks(loop)
                for task in pending:
                    task.cancel()

                # Wait for all tasks to be cancelled
                if pending:
                    loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))

                loop.close()
            except Exception as cleanup_error:
                logger.warning(f"Error during loop cleanup: {cleanup_error}")

    except Exception as e:
        logger.error(f"Error in run_async_task: {e}")
        raise e


def create_error_result(task_id: str, error_msg: str, error_type: str, stage: str, **kwargs) -> Dict[str, Any]:
    """T·∫°o error result chu·∫©n v·ªõi format output"""
    return {
        "success": False,
        "error": error_msg,
        "output": {
            "task_id": task_id,
            "error_details": {
                "error_type": error_type,
                "error_message": error_msg,
                "task_stage": stage,
                **kwargs
            }
        }
    }





@celery_app.task(name="app.tasks.smart_exam_tasks.process_smart_exam_generation")
def process_smart_exam_generation(task_id: str) -> Dict[str, Any]:
    """
    Celery task x·ª≠ l√Ω t·∫°o ƒë·ªÅ thi th√¥ng minh v·ªõi progress tracking b·∫±ng ti·∫øng Vi·ªát

    Args:
        task_id: ID c·ªßa task trong MongoDB

    Returns:
        Dict ch·ª©a k·∫øt qu·∫£ x·ª≠ l√Ω
    """
    logger.info(f"B·∫Øt ƒë·∫ßu t·∫°o ƒë·ªÅ thi th√¥ng minh task: {task_id}")

    # T·∫°o m·ªôt event loop duy nh·∫•t cho to√†n b·ªô task
    loop = None
    try:
        # Always create a completely fresh event loop
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        # Run the async task
        result = loop.run_until_complete(_process_smart_exam_generation_async(task_id))
        logger.info(f"Task {task_id} completed successfully")
        return result

    except Exception as e:
        logger.error(f"Task {task_id} failed with error: {e}")
        raise
    finally:
        # Comprehensive cleanup
        if loop:
            try:
                # Cancel all pending tasks first
                pending = asyncio.all_tasks(loop)
                if pending:
                    logger.info(f"Cancelling {len(pending)} pending tasks for task {task_id}")
                    for task in pending:
                        task.cancel()

                    # Wait for all tasks to be cancelled with timeout
                    try:
                        loop.run_until_complete(
                            asyncio.wait_for(
                                asyncio.gather(*pending, return_exceptions=True),
                                timeout=5.0
                            )
                        )
                    except asyncio.TimeoutError:
                        logger.warning(f"Timeout waiting for tasks to cancel for task {task_id}")

                # Close the loop
                if not loop.is_closed():
                    loop.close()
                    logger.info(f"Event loop closed for task {task_id}")

            except Exception as cleanup_error:
                logger.warning(f"Error during loop cleanup for task {task_id}: {cleanup_error}")
            finally:
                # Clear the event loop reference
                asyncio.set_event_loop(None)


async def _process_smart_exam_generation_async(task_id: str) -> Dict[str, Any]:
    """
    Async implementation c·ªßa smart exam generation
    """
    try:
        # Kh·ªüi t·∫°o services
        task_service = get_mongodb_task_service()

        # L·∫•y th√¥ng tin task t·ª´ database
        task_info = await task_service.get_task_status(task_id)
        if not task_info:
            return create_error_result(task_id, f"Kh√¥ng t√¨m th·∫•y task: {task_id}",
                                     "TaskNotFoundError", "initialization")

        # Parse request data
        task_data = task_info.get("data", {})
        request_data = task_data.get("request_data", {})

        # Extract metadata fields
        user_id = request_data.get("user_id")
        tool_log_id = request_data.get("tool_log_id")
        # Create exam request (remove metadata fields)
        exam_params = {k: v for k, v in request_data.items()
                      if k not in ["user_id", "tool_log_id", "lesson_id", "book_id"]}

        # Handle invalid examCode - if it's not a valid 4-digit number, set to None
        if "examCode" in exam_params:
            exam_code = exam_params["examCode"]
            if not isinstance(exam_code, str) or not exam_code.isdigit() or len(exam_code) != 4:
                logger.warning(f"Invalid examCode '{exam_code}', setting to None for auto-generation")
                exam_params["examCode"] = None

        # Handle invalid grade - ensure it's an integer between 1-12
        if "grade" in exam_params:
            try:
                grade = int(exam_params["grade"])
                if grade < 1 or grade > 12:
                    logger.warning(f"Invalid grade '{grade}', setting to 12")
                    exam_params["grade"] = 12
                else:
                    exam_params["grade"] = grade
            except (ValueError, TypeError):
                logger.warning(f"Invalid grade '{exam_params['grade']}', setting to 12")
                exam_params["grade"] = 12

        # Handle invalid duration - ensure it's an integer between 15-180
        if "duration" in exam_params:
            try:
                duration = int(exam_params["duration"])
                if duration < 15 or duration > 180:
                    logger.warning(f"Invalid duration '{duration}', setting to 45")
                    exam_params["duration"] = 45
                else:
                    exam_params["duration"] = duration
            except (ValueError, TypeError):
                logger.warning(f"Invalid duration '{exam_params['duration']}', setting to 45")
                exam_params["duration"] = 45

        try:
            exam_request = SmartExamRequest(**exam_params)
        except Exception as validation_error:
            error_msg = f"L·ªói validation: {str(validation_error)}"
            logger.error(f"SmartExamRequest validation failed: {validation_error}")

            error_result = create_error_result(task_id, error_msg, "ValidationError", "validation")

            # Send Kafka error notification if user_id is present
            if user_id:
                safe_kafka_call(
                    kafka_service.send_final_result_sync,
                    task_id=task_id,
                    user_id=user_id,
                    result=error_result,
                    tool_log_id=tool_log_id
                )

            return error_result

        logger.info(f"[DEBUG] User ID for Kafka notifications: {user_id}")
        logger.info(f"[DEBUG] Tool Log ID for Kafka notifications: {tool_log_id}")

        # Progress callback function with Kafka notification
        async def progress_callback(percentage: int, message: str):
            try:
                await task_service.update_task_progress(task_id, percentage, message)
                logger.info(f"Task {task_id}: {percentage}% - {message}")

                # Send Kafka progress notification if user_id is present
                if user_id:
                    logger.info(f"[DEBUG] Sending Kafka progress notification: {percentage}% - {message}")
                    safe_kafka_call(
                        kafka_service.send_progress_update_sync,
                        tool_log_id=tool_log_id,
                        task_id=task_id,
                        user_id=user_id,
                        progress=percentage,
                        message=message,
                        status="processing"
                    )
                else:
                    logger.info(f"[DEBUG] Skipping Kafka notification - no user_id")

            except Exception as e:
                logger.error(f"Error updating task progress {task_id}: {e}")
                # Continue execution even if progress update fails
        
        # B∆∞·ªõc 1: Ph√¢n t√≠ch ma tr·∫≠n ƒë·ªÅ thi
        await progress_callback(10, "ƒêang ph√¢n t√≠ch ma tr·∫≠n ƒë·ªÅ thi...")
        
        if not exam_request.matrix:
            error_result = create_error_result(task_id, "Ma tr·∫≠n ƒë·ªÅ thi kh√¥ng ƒë∆∞·ª£c r·ªóng",
                                             "EmptyMatrixError", "matrix_validation")
            await progress_callback(100, f"L·ªói: {error_result['error']}")
            await task_service.mark_task_completed(task_id=task_id, result=error_result)
            return error_result

        # L·∫•y lesson_ids v√† th·ªëng k√™
        lesson_ids = [lesson.lessonId for lesson in exam_request.matrix]
        total_lessons = len(lesson_ids)

        # Debug logging
        logger.info(f"[DEBUG] Lesson IDs to search: {lesson_ids}")
        logger.info(f"[DEBUG] Book ID: {getattr(exam_request, 'bookID', None)}")

        # T√≠nh t·ªïng s·ªë c√¢u h·ªèi t·ª´ parts
        total_questions = 0
        for lesson in exam_request.matrix:
            for part in lesson.parts:
                total_questions += part.objectives.Bi·∫øt + part.objectives.Hi·ªÉu + part.objectives.V·∫≠n_d·ª•ng

        await progress_callback(15, f"T√¨m th·∫•y {total_lessons} b√†i h·ªçc, t·ªïng {total_questions} c√¢u h·ªèi c·∫ßn t·∫°o")

        # B∆∞·ªõc 2: L·∫•y n·ªôi dung b√†i h·ªçc
        await progress_callback(20, "ƒêang t√¨m ki·∫øm n·ªôi dung b√†i h·ªçc t·ª´ c∆° s·ªü d·ªØ li·ªáu...")
        textbook_service = get_textbook_retrieval_service()

        # L·∫•y bookID t·ª´ request n·∫øu c√≥
        book_id = getattr(exam_request, 'bookID', None)
        if book_id:
            await progress_callback(22, f"T√¨m ki·∫øm trong s√°ch: {book_id}")

        lesson_content = await textbook_service.get_multiple_lessons_content_for_exam(lesson_ids, book_id)

        # Debug logging cho k·∫øt qu·∫£
        logger.info(f"[DEBUG] Lesson content result: success={lesson_content.get('success')}")
        if not lesson_content.get('success'):
            logger.error(f"[DEBUG] Lesson content errors: {lesson_content.get('errors', [])}")
            logger.error(f"[DEBUG] Full lesson content response: {lesson_content}")

        if not lesson_content.get("success", False):
            error_result = create_error_result(task_id,
                f"Kh√¥ng th·ªÉ l·∫•y n·ªôi dung b√†i h·ªçc: {lesson_content.get('error', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')}",
                "ContentRetrievalError", "content_retrieval")
            await progress_callback(100, f"L·ªói: {error_result['error']}")
            await task_service.mark_task_completed(task_id=task_id, result=error_result)
            return error_result
            
        # Ki·ªÉm tra n·ªôi dung b√†i h·ªçc
        lessons_content_data = lesson_content.get("lessons_content", {})
        available_lessons = [lid for lid in lesson_ids if lid in lessons_content_data and lessons_content_data[lid]]
        missing_lessons = [lid for lid in lesson_ids if lid not in available_lessons]

        if missing_lessons:
            if len(missing_lessons) == len(lesson_ids):
                error_result = create_error_result(task_id, "Kh√¥ng t√¨m th·∫•y n·ªôi dung cho b·∫•t k·ª≥ b√†i h·ªçc n√†o",
                                                 "NoLessonsFoundError", "content_validation",
                                                 missing_lessons=missing_lessons)
                await progress_callback(100, f"L·ªói: {error_result['error']}")
                await task_service.mark_task_completed(task_id=task_id, result=error_result)
                return error_result
            else:
                await progress_callback(25, f"C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y {len(missing_lessons)} b√†i h·ªçc. Ti·∫øp t·ª•c v·ªõi {len(available_lessons)} b√†i h·ªçc c√≥ s·∫µn")
        else:
            await progress_callback(25, f"ƒê√£ t√¨m th·∫•y n·ªôi dung cho t·∫•t c·∫£ {len(available_lessons)} b√†i h·ªçc")
        
        # B∆∞·ªõc 3: T·∫°o ƒë·ªÅ thi th√¥ng minh
        await progress_callback(30, "ƒêang t·∫°o c√¢u h·ªèi theo ma tr·∫≠n ƒë·ªÅ thi...")
        smart_exam_service = get_smart_exam_generation_service()

        # Import formatter service
        from app.services.smart_exam_json_formatter import get_smart_exam_json_formatter
        formatter = get_smart_exam_json_formatter()

        # T√≠nh t·ªïng s·ªë c√¢u h·ªèi c·∫ßn t·∫°o t·ª´ ma tr·∫≠n
        total_questions_needed = 0
        for lesson_matrix in exam_request.matrix:
            for part in lesson_matrix.parts:
                objectives = part.objectives
                total_questions_needed += objectives.Bi·∫øt + objectives.Hi·ªÉu + objectives.V·∫≠n_d·ª•ng

        logger.info(f"üìä Total questions needed: {total_questions_needed}")

        # T·∫°o c·∫•u tr√∫c exam_data t·ªïng th·ªÉ ƒë·ªÉ append c√¢u h·ªèi
        accumulated_questions = []
        final_formatted_exam = None  # L∆∞u format cu·ªëi c√πng ƒë·ªÉ t√°i s·ª≠ d·ª•ng

        # T·∫°o callback function ƒë·ªÉ g·ª≠i t·ª´ng c√¢u h·ªèi qua Kafka
        async def question_callback(question: Dict[str, Any]):
            """Callback ƒë·ªÉ append t·ª´ng c√¢u h·ªèi v√†o danh s√°ch v√† g·ª≠i qua Kafka"""
            nonlocal final_formatted_exam

            # Th√™m c√¢u h·ªèi v√†o danh s√°ch t√≠ch l≈©y (lu√¥n lu√¥n, kh√¥ng ch·ªâ khi c√≥ user_id)
            accumulated_questions.append(question)

            # T√≠nh progress d·ª±a tr√™n s·ªë c√¢u ƒë√£ t·∫°o
            questions_created = len(accumulated_questions)
            if total_questions_needed > 0:
                # Progress t·ª´ 30% (b·∫Øt ƒë·∫ßu t·∫°o) ƒë·∫øn 90% (ho√†n th√†nh t·∫°o)
                # 30% + (60% * questions_created / total_questions_needed)
                progress = 30 + int(60 * questions_created / total_questions_needed)
                progress = min(progress, 90)  # Kh√¥ng v∆∞·ª£t qu√° 90%
            else:
                progress = 60  # Fallback n·∫øu kh√¥ng t√≠nh ƒë∆∞·ª£c

            # Format to√†n b·ªô danh s√°ch c√¢u h·ªèi hi·ªán t·∫°i b·∫±ng formatter c√≥ s·∫µn
            exam_data = {"questions": accumulated_questions}
            formatted_exam = formatter.format_exam_to_json_response(exam_data)
            final_formatted_exam = formatted_exam  # L∆∞u l·∫°i ƒë·ªÉ d√πng cu·ªëi

            # G·ª≠i qua Kafka n·∫øu c√≥ user_id
            if user_id:
                try:
                    # Wrap trong c·∫•u tr√∫c exam_data
                    response_data = {"exam_data": formatted_exam}

                    # G·ª≠i to√†n b·ªô c·∫•u tr√∫c ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t qua Kafka
                    safe_kafka_call(
                        kafka_service.send_progress_update_sync,
                        tool_log_id=tool_log_id,
                        task_id=task_id,
                        user_id=user_id,
                        progress=progress,
                        message=f"ƒê√£ t·∫°o xong {questions_created}/{total_questions_needed} c√¢u h·ªèi",
                        status="processing",
                        additional_data=response_data
                    )
                    logger.info(f"‚úÖ Sent accumulated exam data via Kafka for task {task_id} - Progress: {progress}% - Questions: {questions_created}/{total_questions_needed}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Error sending accumulated exam data via Kafka: {e}")

        exam_result = await smart_exam_service.generate_smart_exam(
            exam_request, lessons_content_data, question_callback
        )

        if not exam_result.get("success", False):
            error_result = create_error_result(task_id,
                f"Kh√¥ng th·ªÉ t·∫°o ƒë·ªÅ thi: {exam_result.get('error', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')}",
                "ExamGenerationError", "exam_generation")
            await progress_callback(100, f"L·ªói: {error_result['error']}")
            await task_service.mark_task_completed(task_id=task_id, result=error_result)
            return error_result

        generated_questions = len(exam_result.get("questions", []))
        # Kh√¥ng c·∫ßn progress callback ·ªü ƒë√¢y n·ªØa v√¨ callback cu·ªëi c√πng ƒë√£ l√† 90%

        # Ki·ªÉm tra isExportDocx ƒë·ªÉ quy·∫øt ƒë·ªãnh x·ª≠ l√Ω
        is_export_docx = exam_request.isExportDocx

        if is_export_docx:
            # B∆∞·ªõc 4: T·∫°o file DOCX
            await progress_callback(92, "ƒêang t·∫°o file Word (.docx)...")
            docx_result = await smart_exam_docx_service.create_smart_exam_docx(exam_result, exam_request.model_dump())

            if not docx_result.get("success", False):
                error_result = create_error_result(task_id,
                    f"Kh√¥ng th·ªÉ t·∫°o file DOCX: {docx_result.get('error', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')}",
                    "DocxCreationError", "docx_creation")
                await progress_callback(100, f"L·ªói: {error_result['error']}")
                await task_service.mark_task_completed(task_id=task_id, result=error_result)
                return error_result

            file_path = docx_result.get("file_path")
            filename = docx_result.get("filename")
            await progress_callback(94, f"ƒê√£ t·∫°o file Word: {filename}")

            # B∆∞·ªõc 5: Upload l√™n Google Drive
            await progress_callback(96, "ƒêang t·∫£i l√™n Google Drive...")
            google_drive_service = get_google_drive_service()
            upload_result = await google_drive_service.upload_docx_file(
                file_path, filename or "smart_exam.docx", convert_to_google_docs=True)

            if not upload_result.get("success", False):
                error_result = create_error_result(task_id,
                    f"Kh√¥ng th·ªÉ t·∫£i l√™n Google Drive: {upload_result.get('error', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')}",
                    "GoogleDriveUploadError", "file_upload")
                await progress_callback(100, f"L·ªói: {error_result['error']}")
                await task_service.mark_task_completed(task_id=task_id, result=error_result)
                return error_result

            await progress_callback(98, "ƒê√£ t·∫£i l√™n Google Drive th√†nh c√¥ng")

            # B∆∞·ªõc 6: D·ªçn d·∫πp file t·∫°m
            try:
                if file_path and os.path.exists(file_path):
                    os.remove(file_path)
                    logger.info(f"ƒê√£ x√≥a file t·∫°m: {file_path}")
            except Exception as e:
                logger.warning(f"Kh√¥ng th·ªÉ x√≥a file t·∫°m: {e}")

            # B∆∞·ªõc 7: Ho√†n th√†nh v·ªõi DOCX
            await progress_callback(95, "ƒêang ho√†n thi·ªán k·∫øt qu·∫£...")
            statistics = exam_result.get("statistics", {})
            statistics_dict = statistics.model_dump() if hasattr(statistics, 'model_dump') else statistics

            result = {
                "success": True,
                "output": {
                    "exam_id": exam_result.get("exam_id"),
                    "message": "ƒê·ªÅ thi th√¥ng minh ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng theo chu·∫©n THPT 2025",
                    "online_links": upload_result.get("links", {}),
                    "statistics": statistics_dict,
                    "task_id": task_id,
                    "processing_info": {
                        "total_questions_generated": generated_questions,
                        "total_lessons_used": len(available_lessons),
                        "missing_lessons": missing_lessons,
                        "processing_method": "celery_smart_exam_generation"
                    }
                }
            }
        else:
            # B∆∞·ªõc 4: Ho√†n th√†nh v·ªõi JSON format (ƒë√£ ƒë∆∞·ª£c format trong callback)
            await progress_callback(90, "ƒêang ho√†n thi·ªán k·∫øt qu·∫£ JSON...")

            # S·ª≠ d·ª•ng format ƒë√£ ƒë∆∞·ª£c t·∫°o trong callback, fallback n·∫øu c·∫ßn
            if final_formatted_exam:
                formatted_json = final_formatted_exam
            else:
                # Fallback n·∫øu kh√¥ng c√≥ callback data
                formatted_json = formatter.format_exam_to_json_response(exam_result)

            await progress_callback(100, "ƒê√£ ho√†n th√†nh format JSON")

            statistics = exam_result.get("statistics", {})
            statistics_dict = statistics.model_dump() if hasattr(statistics, 'model_dump') else statistics

            result = {
                "success": True,
                "output": {
                    "exam_id": exam_result.get("exam_id"),
                    "message": "ƒê·ªÅ thi th√¥ng minh ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng theo chu·∫©n THPT 2025",
                    "exam_data": formatted_json,
                    "statistics": statistics_dict,
                    "task_id": task_id,
                    "processing_info": {
                        "total_questions_generated": generated_questions,
                        "total_lessons_used": len(available_lessons),
                        "missing_lessons": missing_lessons,
                        "processing_method": "celery_smart_exam_generation"
                    }
                }
            }

        await progress_callback(100, f"Ho√†n th√†nh! ƒê√£ t·∫°o {generated_questions}/{total_questions_needed} c√¢u h·ªèi t·ª´ {len(available_lessons)} b√†i h·ªçc")
        await task_service.mark_task_completed(task_id=task_id, result=result)

        # Send Kafka completion notification if user_id is present
        if user_id:
            safe_kafka_call(
                kafka_service.send_final_result_sync,
                task_id=task_id,
                user_id=user_id,
                result=result,
                tool_log_id=tool_log_id
            )

        logger.info(f"Smart exam generation task {task_id} ho√†n th√†nh th√†nh c√¥ng")
        return result

    except Exception as e:
        logger.error(f"L·ªói trong smart exam generation task {task_id}: {e}")
        error_result = create_error_result(task_id, f"L·ªói h·ªá th·ªëng: {str(e)}",
                                         type(e).__name__, "validation_or_processing")

        try:
            task_service = get_mongodb_task_service()
            await task_service.update_task_progress(task_id, 100, f"L·ªói: {error_result['error']}")
            await task_service.mark_task_completed(task_id=task_id, result=error_result)

            # Send Kafka error notification if user_id is present
            try:
                task_info = await task_service.get_task_status(task_id)
                if task_info:
                    task_data = task_info.get("data", {})
                    request_data = task_data.get("request_data", {})
                    user_id = request_data.get("user_id")
                    tool_log_id = request_data.get("tool_log_id")
                    if user_id:
                        safe_kafka_call(
                            kafka_service.send_final_result_sync,
                            task_id=task_id,
                            user_id=user_id,
                            result=error_result,
                            tool_log_id=tool_log_id
                        )
            except Exception as kafka_error:
                logger.error(f"Error sending Kafka error notification for task {task_id}: {kafka_error}")

            logger.info(f"‚úÖ Saved error result to database for task {task_id}")
        except Exception as save_error:
            logger.error(f"Error saving error result for task {task_id}: {save_error}")

        return error_result
