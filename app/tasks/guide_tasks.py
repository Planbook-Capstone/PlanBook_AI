"""
Celery tasks cho x·ª≠ l√Ω guide import t·ª´ file DOCX v·ªõi LLM formatting v√† smart chunking
"""

import asyncio
import logging
from typing import Dict, Any
from celery import Celery
from app.core.celery_app import celery_app
from app.services.mongodb_task_service import get_mongodb_task_service

logger = logging.getLogger(__name__)


def run_async_task(coro):
    """Helper ƒë·ªÉ ch·∫°y async function trong Celery task"""
    try:
        # Always create a new event loop for each task to avoid "Event loop is closed" error
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            return loop.run_until_complete(coro)
        finally:
            # Always close the loop after use
            try:
                # Cancel all pending tasks
                pending = asyncio.all_tasks(loop)
                for task in pending:
                    task.cancel()

                # Wait for all tasks to be cancelled
                if pending:
                    loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))

                loop.close()
            except Exception as cleanup_error:
                logger.warning(f"Error during loop cleanup: {cleanup_error}")

    except Exception as e:
        logger.error(f"Error in run_async_task: {e}")
        raise e


async def process_guide_import_task(task_id: str) -> Dict[str, Any]:
    """
    X·ª≠ l√Ω task import h∆∞·ªõng d·∫´n t·ª´ file DOCX v·ªõi LLM formatting v√† smart chunking

    Lu·ªìng x·ª≠ l√Ω:
    1. Tr√≠ch xu·∫•t text t·ª´ DOCX
    2. LLM formatting ƒë·ªÉ c·∫•u tr√∫c l·∫°i n·ªôi dung
    3. Upload DOCX file l√™n Supabase Storage
    4. Smart chunking v√† t·∫°o embeddings

    L∆∞u √Ω: B√°o l·ªói thay v√¨ fallback khi c√≥ l·ªói x·∫£y ra
    """
    task_service = get_mongodb_task_service()
    task = await task_service.get_task_status(task_id)
    if not task:
        logger.error(f"Task {task_id} not found")
        return {"success": False, "error": "Task not found"}

    try:
        await task_service.mark_task_processing(task_id)

        # L·∫•y d·ªØ li·ªáu task
        file_content = task["data"]["file_content"]
        filename = task["data"]["filename"]
        book_id = task["data"]["book_id"]
        create_embeddings = task["data"].get("create_embeddings", True)

        await task_service.update_task_progress(task_id, 10, "B·∫Øt ƒë·∫ßu import h∆∞·ªõng d·∫´n DOCX...")

        # Import services
        from app.services.exam_import_service import get_exam_import_service
        from app.services.llm_service import get_llm_service
        from app.services.qdrant_service import get_qdrant_service

        exam_import_service = get_exam_import_service()
        llm_service = get_llm_service()
        qdrant_service = get_qdrant_service()

        # B∆∞·ªõc 1: Tr√≠ch xu·∫•t text t·ª´ DOCX
        await task_service.update_task_progress(task_id, 15, "ƒêang tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ DOCX...")

        extracted_text = exam_import_service._extract_text_from_docx_bytes(file_content)

        if not extracted_text or len(extracted_text.strip()) < 50:
            raise Exception("Kh√¥ng th·ªÉ tr√≠ch xu·∫•t n·ªôi dung t·ª´ file DOCX ho·∫∑c n·ªôi dung qu√° ng·∫Øn")

        await task_service.update_task_progress(task_id, 25, "Ho√†n th√†nh tr√≠ch xu·∫•t vƒÉn b·∫£n")

        # B∆∞·ªõc 2: LLM formatting ƒë·ªÉ c·∫•u tr√∫c l·∫°i n·ªôi dung
        await task_service.update_task_progress(task_id, 35, "ƒêang ƒë·ªãnh d·∫°ng n·ªôi dung v·ªõi LLM...")

        # S·ª≠ d·ª•ng format_document_text v·ªõi document_type="guide" ƒë·ªÉ t·ªëi ∆∞u cho guide content
        format_result = await llm_service.format_document_text(
            raw_text=extracted_text,
            document_type="guide"
        )

        if not format_result.get("success"):
            # B√°o l·ªói thay v√¨ fallback
            error_msg = f"LLM formatting failed: {format_result.get('error', 'Unknown error')}"
            logger.error(error_msg)
            raise Exception(error_msg)

        formatted_text = format_result["formatted_text"]
        await task_service.update_task_progress(task_id, 50, "Ho√†n th√†nh ƒë·ªãnh d·∫°ng n·ªôi dung")

        # B∆∞·ªõc 3: Upload DOCX file l√™n Supabase Storage
        await task_service.update_task_progress(task_id, 50, "ƒêang t·∫£i DOCX l√™n Supabase Storage...")

        file_url = None
        uploaded_at = None
        try:
            from app.services.supabase_storage_service import get_supabase_storage_service

            supabase_service = get_supabase_storage_service()
            if supabase_service.is_available():
                upload_result = await supabase_service.upload_document_file(
                    file_content=file_content,
                    book_id=book_id,
                    lesson_id=f"guide_{filename.replace('.docx', '')}",
                    original_filename=filename,
                    file_type="docx"
                )

                if upload_result.get("success"):
                    file_url = upload_result.get("file_url")
                    uploaded_at = upload_result.get("uploaded_at")
                    logger.info(f"‚úÖ DOCX uploaded to Supabase: {file_url}")
                    logger.info(f"‚úÖ Upload time: {uploaded_at}")
                    logger.info(f"üîç Full upload result: {upload_result}")
                else:
                    logger.error(f"‚ùå Failed to upload DOCX to Supabase: {upload_result.get('error')}")
                    logger.error(f"üîç Full upload result: {upload_result}")
            else:
                logger.warning("Supabase service not available, skipping DOCX upload")
        except Exception as e:
            logger.warning(f"Error uploading DOCX to Supabase: {e}")

        # B∆∞·ªõc 4: T·∫°o embeddings v·ªõi smart chunking n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
        embeddings_result = None
        if create_embeddings:
            await task_service.update_task_progress(task_id, 70, "ƒêang t·∫°o embeddings v·ªõi smart chunking...")

            # Log metadata tr∆∞·ªõc khi t·∫°o embeddings
            logger.info(f"üîç Creating embeddings with metadata:")
            logger.info(f"   - book_id: {book_id}")
            logger.info(f"   - lesson_id: guide_{filename}")
            logger.info(f"   - content_type: guide")
            logger.info(f"   - file_url: {file_url}")
            logger.info(f"   - uploaded_at: {uploaded_at}")

            # S·ª≠ d·ª•ng process_textbook v·ªõi formatted content v√† metadata t·ª´ Supabase
            embeddings_result = await qdrant_service.process_textbook(
                book_id=book_id,
                content=formatted_text,  # S·ª≠ d·ª•ng formatted text thay v√¨ raw text
                lesson_id=f"guide_{filename}",
                content_type="guide",
                file_url=file_url,  # Truy·ªÅn URL c·ªßa file DOCX t·ª´ Supabase
                uploaded_at=uploaded_at  # Truy·ªÅn th·ªùi gian upload
            )

            if not embeddings_result.get("success"):
                # B√°o l·ªói thay v√¨ fallback
                error_msg = f"Embeddings creation failed: {embeddings_result.get('error', 'Unknown error')}"
                logger.error(error_msg)
                raise Exception(error_msg)

            await task_service.update_task_progress(task_id, 85, "T·∫°o embeddings th√†nh c√¥ng")

        # T·∫°o k·∫øt qu·∫£ cu·ªëi c√πng
        result = {
            "success": True,
            "book_id": book_id,
            "filename": filename,
            "content_length": len(formatted_text),  # S·ª≠ d·ª•ng formatted text length
            "content_preview": formatted_text[:500] + "..." if len(formatted_text) > 500 else formatted_text,
            "processing_info": {
                "file_type": "docx",
                "processing_method": "guide_import_with_llm_formatting",
                "text_extraction": True,
                "llm_formatting": True,
                "smart_chunking": True,
                "original_length": len(extracted_text),
                "formatted_length": len(formatted_text),
            },
            "file_storage": {
                "uploaded_to_supabase": file_url is not None,
                "file_url": file_url,
                "uploaded_at": uploaded_at,
            },
            "embeddings_created": embeddings_result.get("success", False) if embeddings_result else False,
            "embeddings_info": {
                "collection_name": embeddings_result.get("collection_name") if embeddings_result else None,
                "vector_count": embeddings_result.get("total_chunks", 0) if embeddings_result else 0,
                "vector_dimension": embeddings_result.get("vector_dimension") if embeddings_result else None,
            },
            "message": "Import h∆∞·ªõng d·∫´n th√†nh c√¥ng v·ªõi ƒë·ªãnh d·∫°ng LLM, smart chunking v√† t·∫£i l√™n Supabase storage, s·∫µn s√†ng cho RAG search"
        }

        await task_service.update_task_progress(task_id, 100, "Ho√†n th√†nh import h∆∞·ªõng d·∫´n")
        await task_service.mark_task_completed(task_id, result)
        return result

    except Exception as e:
        logger.error(f"Error processing guide import task {task_id}: {e}")
        await task_service.mark_task_failed(task_id, str(e))
        return {"success": False, "error": str(e)}


@celery_app.task(bind=True, name="app.tasks.guide_tasks.process_guide_import")
def process_guide_import(self, task_id: str):
    """
    Celery task ƒë·ªÉ x·ª≠ l√Ω guide import t·ª´ file DOCX v·ªõi LLM formatting v√† smart chunking

    Args:
        task_id: ID c·ªßa task trong MongoDB
    """
    logger.info(f"Starting Celery task for guide import: {task_id}")

    try:
        # Ch·∫°y task processing tr·ª±c ti·∫øp trong guide_tasks
        result = run_async_task(process_guide_import_task(task_id))

        logger.info(f"Completed Celery task for guide import: {task_id}")
        return {"status": "completed", "task_id": task_id, "result": result}

    except Exception as e:
        logger.error(f"Error in Celery guide import task {task_id}: {e}")

        # Mark task as failed in MongoDB
        try:
            run_async_task(
                get_mongodb_task_service().mark_task_failed(task_id, str(e))
            )
        except Exception as mark_error:
            logger.error(f"Failed to mark task as failed: {mark_error}")

        # Re-raise ƒë·ªÉ Celery bi·∫øt task failed
        raise e
