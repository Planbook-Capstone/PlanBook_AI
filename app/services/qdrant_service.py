"""
Qdrant Service - Qu·∫£n l√Ω vector embeddings v·ªõi Qdrant
"""

import logging
from typing import Dict, Any, Optional
import datetime

# Heavy imports s·∫Ω ƒë∆∞·ª£c lazy load trong __init__ method

from app.core.config import settings
from app.services.semantic_analysis_service import get_semantic_analysis_service
from app.services.smart_chunking_service import get_smart_chunking_service

logger = logging.getLogger(__name__)


class QdrantService:
    """
    Service qu·∫£n l√Ω vector embeddings v·ªõi Qdrant - Individual Collections per Book
    """

    def __init__(self):
        """Initialize Qdrant service"""
        self.embedding_model = None
        self.qdrant_client = None
        self.vector_size: Optional[int] = None
        self._service_initialized = False
        self.semantic_analysis_service = get_semantic_analysis_service()
        self.smart_chunking_service = get_smart_chunking_service()

    def is_available(self) -> bool:
        """Check if Qdrant service is available"""
        try:
            self._ensure_service_initialized()
            return (
                self._service_initialized and
                self.qdrant_client is not None and
                self.embedding_model is not None
            )
        except Exception as e:
            logger.error(f"‚ùå QdrantService availability check failed: {e}")
            return False

    def _ensure_service_initialized(self):
        """Ensure Qdrant service is initialized"""
        if not self._service_initialized:
            logger.info("üîÑ QdrantService: First-time initialization triggered")
            self._init_embedding_model()
            self._init_qdrant_client()
            self._service_initialized = True
            logger.info("‚úÖ QdrantService: Initialization completed")

    def _init_embedding_model(self):
        """Kh·ªüi t·∫°o m√¥ h√¨nh embedding"""
        try:
            from sentence_transformers import SentenceTransformer
            import torch
            import warnings

            model_name = settings.EMBEDDING_MODEL
            logger.info(f"üîß Initializing embedding model: {model_name}")

            # Suppress the specific pin_memory warning when no CUDA is available
            if not torch.cuda.is_available():
                warnings.filterwarnings(
                    "ignore",
                    message=".*pin_memory.*no accelerator.*",
                    category=UserWarning,
                    module="torch.utils.data.dataloader",
                )

            # Initialize model with appropriate device
            device = "cuda" if torch.cuda.is_available() else "cpu"
            logger.info(f"üîß Using device: {device}")

            # Special handling for different models
            if "nvidia" in model_name.lower():
                logger.info(f"üîß Loading nvidia model with trust_remote_code=True")
                self.embedding_model = SentenceTransformer(model_name, device=device, trust_remote_code=True)
            else:
                logger.info(f"üîß Loading standard model")
                self.embedding_model = SentenceTransformer(model_name, device=device)

            self.vector_size = self.embedding_model.get_sentence_embedding_dimension()
            logger.info(
                f"‚úÖ Embedding model initialized successfully: {model_name} (dim={self.vector_size}, device={device})"
            )

            # Test encoding ƒë·ªÉ ƒë·∫£m b·∫£o model ho·∫°t ƒë·ªông
            test_text = "Test embedding"
            test_embedding = self.embedding_model.encode(test_text)
            logger.info(f"‚úÖ Model test successful, embedding shape: {test_embedding.shape}")

        except Exception as e:
            logger.error(f"‚ùå Failed to initialize embedding model: {e}")
            import traceback
            logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
            self.embedding_model = None
            self.vector_size = None

    def _init_qdrant_client(self):
        """Kh·ªüi t·∫°o k·∫øt n·ªëi Qdrant"""
        try:
            from qdrant_client import QdrantClient

            logger.info(f"üîÑ Initializing Qdrant client...")
            logger.info(f"   - URL: {settings.QDRANT_URL}")
            logger.info(f"   - API Key: {'***' if settings.QDRANT_API_KEY else 'None'}")

            self.qdrant_client = QdrantClient(
                url=settings.QDRANT_URL,
                api_key=settings.QDRANT_API_KEY if settings.QDRANT_API_KEY else None,
            )

            # Test connection
            collections = self.qdrant_client.get_collections()
            logger.info(f"‚úÖ Qdrant client initialized successfully: {settings.QDRANT_URL}")
            logger.info(f"   - Found {len(collections.collections)} existing collections")

        except Exception as e:
            logger.error(f"‚ùå Failed to initialize Qdrant client: {e}")
            logger.error(f"   - URL: {settings.QDRANT_URL}")
            logger.error(f"   - Make sure Qdrant server is running")
            self.qdrant_client = None



    def _ensure_collection_exists(self, collection_name: str) -> bool:
        """
        ƒê·∫£m b·∫£o collection t·ªìn t·∫°i - t·ª± ƒë·ªông t·∫°o n·∫øu ch∆∞a c√≥

        Args:
            collection_name: T√™n collection c·∫ßn ƒë·∫£m b·∫£o t·ªìn t·∫°i

        Returns:
            bool: True n·∫øu collection t·ªìn t·∫°i ho·∫∑c ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng, False n·∫øu c√≥ l·ªói
        """
        if not self.qdrant_client or not self.vector_size:
            logger.error("Cannot create collection: Qdrant client or vector size not initialized")
            return False

        try:
            from qdrant_client.http import models as qdrant_models

            # Ki·ªÉm tra xem collection ƒë√£ t·ªìn t·∫°i ch∆∞a
            collections = self.qdrant_client.get_collections().collections
            existing_names = [c.name for c in collections]

            if collection_name not in existing_names:
                logger.info(f"Collection '{collection_name}' not found. Creating new collection...")

                # T·∫°o collection m·ªõi
                self.qdrant_client.create_collection(
                    collection_name=collection_name,
                    vectors_config=qdrant_models.VectorParams(
                        size=self.vector_size, distance=qdrant_models.Distance.COSINE
                    ),
                )
                logger.info(f"‚úÖ Successfully created new collection: {collection_name}")

                # T·∫°o payload index cho c√°c tr∆∞·ªùng quan tr·ªçng
                logger.info(f"Creating indexes for collection: {collection_name}")
                self.qdrant_client.create_payload_index(
                    collection_name=collection_name,
                    field_name="book_id",
                    field_schema="keyword",
                )
                self.qdrant_client.create_payload_index(
                    collection_name=collection_name,
                    field_name="lesson_id",
                    field_schema="keyword",
                )
                self.qdrant_client.create_payload_index(
                    collection_name=collection_name,
                    field_name="type",
                    field_schema="keyword",
                )
                self.qdrant_client.create_payload_index(
                    collection_name=collection_name,
                    field_name="content_type",
                    field_schema="keyword",
                )
                logger.info(f"‚úÖ Successfully created indexes for collection: {collection_name}")
            else:
                logger.info(f"‚úÖ Collection '{collection_name}' already exists - ready to add content")

            return True

        except Exception as e:
            logger.error(f"‚ùå Error ensuring collection '{collection_name}' exists: {e}")
            return False

    async def process_textbook(
        self,
        book_id: str,
        content: Optional[Any] = None,  # C√≥ th·ªÉ l√† str ho·∫∑c Dict
        lesson_id: Optional[str] = None,
        content_type: str = "textbook",  # "textbook" | "guide"
        file_url: Optional[str] = None,  # URL c·ªßa file PDF tr√™n Supabase
        uploaded_at: Optional[str] = None,  # Th·ªùi gian upload file
        # Backward compatibility parameters
        text_content: Optional[str] = None,
        book_content: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω s√°ch gi√°o khoa/guide v√† t·∫°o embeddings v√†o collection ri√™ng

        Args:
            book_id: ID c·ªßa s√°ch ho·∫∑c guide
            content: N·ªôi dung c·∫ßn x·ª≠ l√Ω (str cho guide, Dict ho·∫∑c str cho textbook)
            lesson_id: ID b√†i h·ªçc
            content_type: Lo·∫°i n·ªôi dung ("textbook" ho·∫∑c "guide")
            text_content: [DEPRECATED] S·ª≠ d·ª•ng content thay th·∫ø
            book_content: [DEPRECATED] S·ª≠ d·ª•ng content thay th·∫ø
        """
        self._ensure_service_initialized()

        # Debug logging
        logger.info(f"üîç process_textbook called with:")
        logger.info(f"   - book_id: {book_id}")
        logger.info(f"   - lesson_id: {lesson_id} (type: {type(lesson_id)})")
        logger.info(f"   - content_type: {content_type}")
        logger.info(f"   - has_content: {content is not None}")
        logger.info(f"   - content_type_obj: {type(content)}")
        logger.info(f"   - has_text_content (deprecated): {text_content is not None}")
        logger.info(f"   - has_book_content (deprecated): {book_content is not None}")

        if (
            not self.qdrant_client
            or not self.embedding_model
            or self.vector_size is None
        ):
            return {
                "success": False,
                "error": "Qdrant client or embedding model not initialized",
            }

        try:
            # X√°c ƒë·ªãnh collection name d·ª±a tr√™n content_type v√† book_id
            if content_type == "guide":
                collection_name = f"guide_{book_id}"
            else:  # textbook
                collection_name = f"textbook_{book_id}"

            # ƒê·∫£m b·∫£o collection t·ªìn t·∫°i - t·ª± ƒë·ªông t·∫°o n·∫øu ch∆∞a c√≥
            if not self._ensure_collection_exists(collection_name):
                logger.error(f"‚ùå Failed to create or access collection '{collection_name}'. Check Qdrant connection and permissions.")
                return {"success": False, "error": f"Failed to create or access collection '{collection_name}'. Check Qdrant connection and logs for details."}

            # X·ª≠ l√Ω d·ªØ li·ªáu ƒë·∫ßu v√†o - th·ªëng nh·∫•t cho c·∫£ guide v√† textbook
            content_text = None

            # ∆Øu ti√™n s·ª≠ d·ª•ng parameter content m·ªõi
            if content is not None:
                if isinstance(content, dict):
                    content_text = str(content)  # Convert dict to string
                else:
                    content_text = str(content)  # Convert to string
            # Backward compatibility v·ªõi c√°c parameter c≈©
            elif content_type == "guide" and text_content:
                content_text = text_content
            elif content_type == "textbook" and book_content:
                if isinstance(book_content, dict):
                    content_text = str(book_content)  # Convert dict to string
                else:
                    content_text = str(book_content)  # Convert to string

            if not content_text:
                return {"success": False, "error": "Missing required content. Please provide 'content' parameter."}

            # X·ª≠ l√Ω content th·ªëng nh·∫•t
            return await self._process_content_to_collection(
                book_id=book_id,
                content=content_text,
                content_type=content_type,
                lesson_id=lesson_id,
                collection_name=collection_name,
                file_url=file_url,
                uploaded_at=uploaded_at
            )
        except Exception as e:
            logger.error(f"Error processing textbook: {e}")
            return {"success": False, "error": str(e)}

    async def _process_content_to_collection(
        self, book_id: str, content: str, content_type: str, collection_name: str,
        lesson_id: Optional[str] = None, file_url: Optional[str] = None, uploaded_at: Optional[str] = None
    ) -> Dict[str, Any]:
        """X·ª≠ l√Ω n·ªôi dung text v√†o collection c·ª• th·ªÉ - h√†m th·ªëng nh·∫•t cho c·∫£ textbook v√† guide"""
        from qdrant_client.http import models as qdrant_models

        # Debug logging
        logger.info(f"üîç Processing content to collection: {collection_name}")
        logger.info(f"   - book_id: {book_id}")
        logger.info(f"   - lesson_id: {lesson_id} (type: {type(lesson_id)})")
        logger.info(f"   - content_type: {content_type}")

        # T·∫°o chunks t·ª´ content s·ª≠ d·ª•ng smart chunking service
        chunk_infos = self.smart_chunking_service.chunk_textbook_content(
            content,
            max_tokens=settings.MAX_CHUNK_SIZE
        )

        # Chu·∫©n b·ªã d·ªØ li·ªáu
        points = []
        import uuid

        # T·∫°o embeddings cho t·ª´ng chunk v·ªõi semantic metadata t·ª´ smart chunking
        for i, chunk_info in enumerate(chunk_infos):
            try:
                chunk_id = str(uuid.uuid4())
                chunk_text = getattr(chunk_info, 'text', '')
                if not chunk_text:
                    logger.warning(f"Empty chunk text at index {i}, skipping...")
                    continue

                chunk_vector = self.embedding_model.encode(chunk_text).tolist()

                # S·ª≠ d·ª•ng semantic info t·ª´ smart chunking service
                semantic_info = {
                    'chunk_type': chunk_info.chunk_type,
                    'semantic_tag': chunk_info.semantic_tag,
                    'concepts': chunk_info.concepts,
                    'token_count': chunk_info.token_count,
                    'is_semantic_complete': chunk_info.is_semantic_complete
                }

                # Debug logging ƒë·ªÉ ki·ªÉm tra c·∫•u tr√∫c d·ªØ li·ªáu
                if i == 0:
                    logger.info(f"üîç ChunkInfo attributes: {dir(chunk_info)}")
                    logger.info(f"üîç semantic_info keys: {list(semantic_info.keys())}")
                    logger.info(f"üîç semantic_tag value: {semantic_info.get('semantic_tag', 'NOT_FOUND')}")

                # X√°c ƒë·ªãnh content_type_detail d·ª±a tr√™n content_type
                if content_type == "guide":
                    content_type_detail = "guide_content"
                else:
                    content_type_detail = "lesson_content"

                # ƒê·∫£m b·∫£o lesson_id c√≥ gi√° tr·ªã h·ª£p l·ªá
                safe_lesson_id = lesson_id if lesson_id is not None else ""

                # Debug logging cho chunk ƒë·∫ßu ti√™n
                if i == 0:
                    logger.info(f"üîç Creating point with lesson_id: {lesson_id} -> safe_lesson_id: {safe_lesson_id} (type: {type(safe_lesson_id)})")

                points.append(
                    qdrant_models.PointStruct(
                        id=chunk_id,
                        vector=chunk_vector,
                        payload={
                            "book_id": book_id,
                            "lesson_id": safe_lesson_id,
                            "chunk_index": i,
                            "type": "content",
                            "content_type": content_type_detail,
                            "text": chunk_text,
                            # Smart chunking metadata - defensive access
                            "chunk_type": semantic_info.get("chunk_type", "content"),
                            "semantic_tag": semantic_info.get("semantic_tag", "theory"),
                            "concepts": semantic_info.get("concepts", []),
                            "token_count": semantic_info.get("token_count", 0),
                            "is_semantic_complete": semantic_info.get("is_semantic_complete", False),
                            "parent_title": getattr(chunk_info, 'parent_title', ''),
                            "overlap_context": getattr(chunk_info, 'overlap_context', ''),
                            # Legacy compatibility - defensive access
                            "semantic_tags": [semantic_info.get("semantic_tag", "theory")],
                            "key_concepts": semantic_info.get("concepts", []),
                            "contains_examples": semantic_info.get("chunk_type", "content") == "example",
                            "contains_definitions": semantic_info.get("chunk_type", "content") == "definition",
                            "contains_formulas": "formula" in chunk_text.lower(),
                            "estimated_difficulty": "basic",
                            "analysis_method": "smart_chunking",
                            "word_count": len(chunk_text.split()),
                            "char_count": len(chunk_text),
                            "processed_at": datetime.datetime.now().isoformat(),
                        },
                    )
                )
            except Exception as e:
                logger.error(f"Error processing chunk {i}: {e}")
                logger.error(f"ChunkInfo type: {type(chunk_info)}")
                logger.error(f"ChunkInfo attributes: {dir(chunk_info) if hasattr(chunk_info, '__dict__') else 'No attributes'}")
                continue

        total_chunks = len(chunk_infos)

        # L∆∞u v√†o Qdrant theo batch v√†o collection c·ª• th·ªÉ
        batch_size = 100
        for i in range(0, len(points), batch_size):
            batch = points[i : i + batch_size]
            self.qdrant_client.upsert(collection_name=collection_name, points=batch)
            logger.info(
                f"Uploaded batch {i//batch_size + 1}/{(len(points)-1)//batch_size + 1} to collection {collection_name}"
            )

        # L∆∞u metadata v√†o collection
        zero_vector = [0.0] * self.vector_size
        safe_lesson_id = lesson_id if lesson_id is not None else ""
        metadata_payload = {
            "book_id": book_id,
            "lesson_id": safe_lesson_id,
            "type": "metadata",
            "content_type": content_type,
            "total_chunks": total_chunks,
            "processed_at": datetime.datetime.now().isoformat(),
            "model": settings.EMBEDDING_MODEL,
            "chunk_size": settings.MAX_CHUNK_SIZE,
            "chunk_overlap": settings.CHUNK_OVERLAP,
        }

        # Debug logging cho file metadata
        logger.info(f"üîç Adding file metadata to Qdrant:")
        logger.info(f"   - file_url: {file_url} (type: {type(file_url)})")
        logger.info(f"   - uploaded_at: {uploaded_at} (type: {type(uploaded_at)})")

        # Th√™m fileUrl v√† uploaded_at n·∫øu c√≥
        if file_url:
            metadata_payload["file_url"] = file_url
            logger.info(f"‚úÖ Added file_url to metadata: {file_url}")
        else:
            logger.warning("‚ö†Ô∏è  file_url is None or empty, not adding to metadata")

        if uploaded_at:
            metadata_payload["uploaded_at"] = uploaded_at
            logger.info(f"‚úÖ Added uploaded_at to metadata: {uploaded_at}")
        else:
            logger.warning("‚ö†Ô∏è  uploaded_at is None or empty, not adding to metadata")

        metadata_point = qdrant_models.PointStruct(
            id=str(uuid.uuid4()),
            vector=zero_vector,
            payload=metadata_payload,
        )

        self.qdrant_client.upsert(
            collection_name=collection_name, points=[metadata_point]
        )

        return {
            "success": True,
            "book_id": book_id,
            "lesson_id": lesson_id,
            "collection_name": collection_name,
            "total_chunks": total_chunks,
            "vector_dimension": self.vector_size,
        }







    async def search_textbook(
        self, book_id: str, query: str, limit: int = 5, semantic_filters: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """T√¨m ki·∫øm trong s√°ch gi√°o khoa b·∫±ng vector similarity trong collection ri√™ng theo book_id"""
        from qdrant_client.http import models as qdrant_models
        self._ensure_service_initialized()

        if not self.qdrant_client or not self.embedding_model:
            return {
                "success": False,
                "error": "Qdrant client or embedding model not initialized",
            }

        try:
            # S·ª≠ d·ª•ng collection ri√™ng cho textbook
            collection_name = f"textbook_{book_id}"

            # Ki·ªÉm tra xem collection c√≥ t·ªìn t·∫°i kh√¥ng
            collections = self.qdrant_client.get_collections().collections
            existing_names = [c.name for c in collections]

            if collection_name not in existing_names:
                return {
                    "success": False,
                    "error": f"Textbook collection {collection_name} not found. Please create embeddings first.",
                }

            # T·∫°o embedding cho query
            query_vector = self.embedding_model.encode(query).tolist()

            # Chu·∫©n b·ªã filters cho Qdrant - b·∫Øt bu·ªôc filter theo book_id v√† type="content"
            filter_conditions = [
                qdrant_models.FieldCondition(
                    key="book_id",
                    match=qdrant_models.MatchValue(value=book_id)
                ),
                qdrant_models.FieldCondition(
                    key="type",
                    match=qdrant_models.MatchValue(value="content")
                )
            ]

            # Th√™m semantic filters n·∫øu c√≥
            if semantic_filters:
                # Filter by semantic tags
                if "semantic_tags" in semantic_filters:
                    tag_types = semantic_filters["semantic_tags"]
                    if isinstance(tag_types, str):
                        tag_types = [tag_types]

                    # T·∫°o filter cho semantic_tags array
                    for tag_type in tag_types:
                        filter_conditions.append(
                            qdrant_models.FieldCondition(
                                key="semantic_tags",
                                match=qdrant_models.MatchAny(any=[tag_type])
                            )
                        )

                # Filter by difficulty
                if "difficulty" in semantic_filters:
                    filter_conditions.append(
                        qdrant_models.FieldCondition(
                            key="estimated_difficulty",
                            match=qdrant_models.MatchValue(value=semantic_filters["difficulty"])
                        )
                    )

                # Filter by content features
                if "has_examples" in semantic_filters:
                    filter_conditions.append(
                        qdrant_models.FieldCondition(
                            key="contains_examples",
                            match=qdrant_models.MatchValue(value=semantic_filters["has_examples"])
                        )
                    )

                if "has_formulas" in semantic_filters:
                    filter_conditions.append(
                        qdrant_models.FieldCondition(
                            key="contains_formulas",
                            match=qdrant_models.MatchValue(value=semantic_filters["has_formulas"])
                        )
                    )

                # Filter by lesson_id (n·∫øu mu·ªën t√¨m trong lesson c·ª• th·ªÉ)
                if "lesson_id" in semantic_filters:
                    filter_conditions.append(
                        qdrant_models.FieldCondition(
                            key="lesson_id",
                            match=qdrant_models.MatchValue(value=semantic_filters["lesson_id"])
                        )
                    )

            # T·∫°o filter cu·ªëi c√πng
            qdrant_filter = qdrant_models.Filter(must=filter_conditions)

            # T√¨m ki·∫øm trong Qdrant
            search_result = self.qdrant_client.search(
                collection_name=collection_name,
                query_vector=query_vector,
                query_filter=qdrant_filter,
                limit=limit,
                with_payload=True,
                score_threshold=0.3,  # Gi·∫£m threshold ƒë·ªÉ c√≥ nhi·ªÅu k·∫øt qu·∫£ h∆°n
            )

            # Format k·∫øt qu·∫£
            results = []
            for scored_point in search_result:
                # S·ª≠a l·ªói: Ki·ªÉm tra payload tr∆∞·ªõc khi truy c·∫≠p
                payload = scored_point.payload or {}

                # B·ªè qua metadata point b·∫±ng c√°ch check payload
                if payload.get("type") == "metadata":
                    continue

                # Chu·∫©n b·ªã semantic metadata
                semantic_tags = payload.get("semantic_tags", [])

                # Backward compatibility: convert old semantic_type to new format
                if not semantic_tags and "semantic_type" in payload:
                    semantic_tags = [{"type": payload["semantic_type"], "confidence": 0.8}]

                results.append(
                    {
                        "text": payload.get("text", ""),
                        "score": scored_point.score,
                        "lesson_id": payload.get("lesson_id", ""),
                        "chapter_id": payload.get("chapter_id", ""),
                        "type": payload.get("type", ""),
                        "semantic_tags": semantic_tags,
                        "key_concepts": payload.get("key_concepts", []),
                        "estimated_difficulty": payload.get("estimated_difficulty", "basic"),
                        "contains_examples": payload.get("contains_examples", False),
                        "contains_definitions": payload.get("contains_definitions", False),
                        "contains_formulas": payload.get("contains_formulas", False),
                        "analysis_method": payload.get("analysis_method", "unknown")
                    }
                )

            return {
                "success": True,
                "book_id": book_id,
                "query": query,
                "results": results,
            }

        except Exception as e:
            logger.error(f"Error searching textbook: {e}")
            return {"success": False, "error": str(e)}

    async def get_lessons_by_type(
        self,
        content_type: str = "textbook",
        book_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        L·∫•y b√†i h·ªçc t·ª´ Qdrant theo lo·∫°i content v√† book_id - Optimized version
        Ch·ªâ l·∫•y nh·ªØng th√¥ng tin c·∫ßn thi·∫øt ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô response

        Args:
            content_type: Lo·∫°i content ("textbook" ho·∫∑c "guide")
            book_id: ID c·ªßa s√°ch (optional, ƒë·ªÉ filter theo book c·ª• th·ªÉ)

        Returns:
            Dict ch·ª©a danh s√°ch b√†i h·ªçc v·ªõi th√¥ng tin c∆° b·∫£n
        """
        from qdrant_client.http import models as qdrant_models

        self._ensure_service_initialized()

        if not self.qdrant_client:
            return {
                "success": False,
                "error": "Qdrant client not initialized"
            }

        try:
            # L·∫•y danh s√°ch t·∫•t c·∫£ collections
            collections_response = self.qdrant_client.get_collections()
            all_collections = [col.name for col in collections_response.collections]

            # L·ªçc collections theo content_type
            if content_type == "textbook":
                target_collections = [col for col in all_collections if col.startswith("textbook_")]
            elif content_type == "guide":
                target_collections = [col for col in all_collections if col.startswith("guide_")]
            else:
                target_collections = [col for col in all_collections if col.startswith("textbook_") or col.startswith("guide_")]

            # N·∫øu c√≥ book_id, l·ªçc th√™m theo book_id
            if book_id:
                target_collections = [col for col in target_collections if col.endswith(f"_{book_id}")]

            logger.info(f"Found {len(target_collections)} {content_type} collections" + (f" for book_id={book_id}" if book_id else ""))

            lessons = []

            for collection_name in target_collections:
                try:
                    # T·ªëi ∆∞u: L·∫•y t·∫•t c·∫£ metadata points nh∆∞ng kh√¥ng l·∫•y vectors ƒë·ªÉ tƒÉng t·ªëc
                    search_result = self.qdrant_client.scroll(
                        collection_name=collection_name,
                        scroll_filter=qdrant_models.Filter(
                            must=[
                                qdrant_models.FieldCondition(
                                    key="type",
                                    match=qdrant_models.MatchValue(value="metadata")
                                )
                            ]
                        ),
                        limit=100,  # TƒÉng limit ƒë·ªÉ l·∫•y nhi·ªÅu lessons trong 1 collection
                        with_payload=True,
                        with_vectors=False  # Kh√¥ng c·∫ßn vectors ƒë·ªÉ tƒÉng t·ªëc
                    )

                    # X·ª≠ l√Ω t·∫•t c·∫£ metadata points trong collection
                    for point in search_result[0]:  # search_result[0] ch·ª©a danh s√°ch points
                        payload = point.payload

                        # Ch·ªâ l·∫•y nh·ªØng field c·∫ßn thi·∫øt
                        lesson_info = {
                            "book_id": payload.get("book_id", ""),
                            "lesson_id": payload.get("lesson_id", ""),
                            "file_url": payload.get("file_url", ""),
                            "uploaded_at": payload.get("uploaded_at", payload.get("processed_at", "")),
                            "processed_at": payload.get("processed_at", ""),
                            "content_type": payload.get("content_type", content_type),
                            "collection_name": collection_name,
                            "total_chunks": payload.get("total_chunks", 0)
                        }

                        # Ch·ªâ th√™m v√†o danh s√°ch n·∫øu c√≥ book_id v√† lesson_id
                        if lesson_info["book_id"] and lesson_info["lesson_id"]:
                            lessons.append(lesson_info)

                except Exception as e:
                    logger.warning(f"Error processing collection {collection_name}: {e}")
                    continue

            # S·∫Øp x·∫øp theo uploaded_at (m·ªõi nh·∫•t tr∆∞·ªõc), fallback processed_at
            lessons.sort(key=lambda x: x.get("uploaded_at", x.get("processed_at", "")), reverse=True)

            logger.info(f"Retrieved {len(lessons)} {content_type} lessons from Qdrant" + (f" for book_id={book_id}" if book_id else ""))

            return {
                "success": True,
                "lessons": lessons,
                "total_lessons": len(lessons),
                "collections_processed": len(target_collections),
                "content_type": content_type,
                "book_id": book_id
            }

        except Exception as e:
            logger.error(f"Error getting {content_type} lessons: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    async def get_all_lessons(self) -> Dict[str, Any]:
        """
        Backward compatibility method - l·∫•y t·∫•t c·∫£ textbook lessons
        """
        return await self.get_lessons_by_type(content_type="textbook")

    async def get_all_guides(self) -> Dict[str, Any]:
        """
        L·∫•y t·∫•t c·∫£ guide lessons
        """
        return await self.get_lessons_by_type(content_type="guide")

    async def get_file_urls_for_deletion(self, book_id: str, lesson_id: Optional[str] = None) -> list:
        """
        L·∫•y danh s√°ch file URLs c·∫ßn x√≥a t·ª´ Supabase tr∆∞·ªõc khi x√≥a kh·ªèi Qdrant

        Args:
            book_id: ID c·ªßa book
            lesson_id: ID c·ªßa lesson (optional)

        Returns:
            List c√°c file URLs c·∫ßn x√≥a
        """
        from qdrant_client.http import models as qdrant_models

        self._ensure_service_initialized()

        if not self.qdrant_client:
            return []

        file_urls = []

        try:
            # L·∫•y danh s√°ch collections
            collections_response = self.qdrant_client.get_collections()
            all_collections = [col.name for col in collections_response.collections]

            # T√¨m collections li√™n quan ƒë·∫øn book_id
            target_collections = []
            for col in all_collections:
                if col.endswith(f"_{book_id}"):
                    target_collections.append(col)

            # T·∫°o filter
            filter_conditions = [
                qdrant_models.FieldCondition(
                    key="type",
                    match=qdrant_models.MatchValue(value="metadata")
                ),
                qdrant_models.FieldCondition(
                    key="book_id",
                    match=qdrant_models.MatchValue(value=book_id)
                )
            ]

            # N·∫øu c√≥ lesson_id, th√™m filter
            if lesson_id:
                filter_conditions.append(
                    qdrant_models.FieldCondition(
                        key="lesson_id",
                        match=qdrant_models.MatchValue(value=lesson_id)
                    )
                )

            search_filter = qdrant_models.Filter(must=filter_conditions)

            # T√¨m ki·∫øm trong c√°c collections
            for collection_name in target_collections:
                try:
                    scroll_result = self.qdrant_client.scroll(
                        collection_name=collection_name,
                        scroll_filter=search_filter,
                        limit=1000,
                        with_payload=True,
                        with_vectors=False
                    )

                    points = scroll_result[0]
                    for point in points:
                        file_url = point.payload.get("file_url")
                        if file_url and file_url not in file_urls:
                            file_urls.append(file_url)

                except Exception as e:
                    logger.warning(f"Error searching collection {collection_name}: {e}")
                    continue

            logger.info(f"Found {len(file_urls)} file URLs for deletion: book_id={book_id}, lesson_id={lesson_id}")
            return file_urls

        except Exception as e:
            logger.error(f"Error getting file URLs for deletion: {e}")
            return []

    async def update_lesson_id_in_book(
        self, book_id: str, old_lesson_id: str, new_lesson_id: str
    ) -> Dict[str, Any]:
        """
        Update t·∫•t c·∫£ lessonID c≈© th√†nh lessonID m·ªõi trong m·ªôt bookID

        Args:
            book_id: ID c·ªßa book
            old_lesson_id: lessonID c≈© c·∫ßn thay ƒë·ªïi
            new_lesson_id: lessonID m·ªõi

        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ update
        """
        from qdrant_client.http import models as qdrant_models

        self._ensure_service_initialized()

        if not self.qdrant_client:
            return {
                "success": False,
                "error": "Qdrant client not initialized"
            }

        try:
            # T√¨m collection cho book_id (textbook ho·∫∑c guide)
            collections = self.qdrant_client.get_collections()
            target_collection = None

            for collection in collections.collections:
                collection_name = collection.name
                if collection_name == f"textbook_{book_id}" or collection_name == f"guide_{book_id}":
                    target_collection = collection_name
                    break

            if not target_collection:
                return {
                    "success": False,
                    "error": f"No collection found for book_id '{book_id}'"
                }

            logger.info(f"Updating lesson_id from '{old_lesson_id}' to '{new_lesson_id}' in collection '{target_collection}'")

            # T√¨m t·∫•t c·∫£ points c√≥ old_lesson_id
            filter_condition = qdrant_models.Filter(
                must=[
                    qdrant_models.FieldCondition(
                        key="book_id",
                        match=qdrant_models.MatchValue(value=book_id)
                    ),
                    qdrant_models.FieldCondition(
                        key="lesson_id",
                        match=qdrant_models.MatchValue(value=old_lesson_id)
                    )
                ]
            )

            # Scroll ƒë·ªÉ l·∫•y t·∫•t c·∫£ points c·∫ßn update
            scroll_result = self.qdrant_client.scroll(
                collection_name=target_collection,
                scroll_filter=filter_condition,
                limit=10000,  # L·∫•y nhi·ªÅu points
                with_payload=True,
                with_vectors=False
            )

            points_to_update = scroll_result[0]

            if not points_to_update:
                return {
                    "success": False,
                    "error": f"No points found with lesson_id '{old_lesson_id}' in book '{book_id}'"
                }

            logger.info(f"Found {len(points_to_update)} points to update")

            # Update t·ª´ng point
            updated_count = 0
            for point in points_to_update:
                try:
                    # Update payload v·ªõi lesson_id m·ªõi
                    self.qdrant_client.set_payload(
                        collection_name=target_collection,
                        payload={"lesson_id": new_lesson_id},
                        points=[point.id]
                    )
                    updated_count += 1
                except Exception as e:
                    logger.error(f"Error updating point {point.id}: {e}")
                    continue

            logger.info(f"Successfully updated {updated_count} points")

            return {
                "success": True,
                "book_id": book_id,
                "old_lesson_id": old_lesson_id,
                "new_lesson_id": new_lesson_id,
                "collection_name": target_collection,
                "points_updated": updated_count,
                "message": f"Updated {updated_count} points from lesson_id '{old_lesson_id}' to '{new_lesson_id}' in book '{book_id}'"
            }

        except Exception as e:
            logger.error(f"Error updating lesson_id in book {book_id}: {e}")
            return {
                "success": False,
                "error": f"Failed to update lesson_id: {str(e)}"
            }

    async def update_book_id_in_qdrant(
        self, old_book_id: str, new_book_id: str
    ) -> Dict[str, Any]:
        """
        Update bookID c≈© th√†nh bookID m·ªõi trong Qdrant (rename collection v√† update metadata)

        Args:
            old_book_id: bookID c≈©
            new_book_id: bookID m·ªõi

        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ update
        """
        from qdrant_client.http import models as qdrant_models

        self._ensure_service_initialized()

        if not self.qdrant_client:
            return {
                "success": False,
                "error": "Qdrant client not initialized"
            }

        try:
            # T√¨m collections cho old_book_id
            collections = self.qdrant_client.get_collections()
            old_collections = []

            for collection in collections.collections:
                collection_name = collection.name
                if collection_name == f"textbook_{old_book_id}" or collection_name == f"guide_{old_book_id}":
                    old_collections.append(collection_name)

            if not old_collections:
                return {
                    "success": False,
                    "error": f"No collections found for book_id '{old_book_id}'"
                }

            logger.info(f"Found {len(old_collections)} collections to update for book_id '{old_book_id}'")

            results = []

            for old_collection_name in old_collections:
                try:
                    # X√°c ƒë·ªãnh lo·∫°i collection v√† t·∫°o t√™n m·ªõi
                    if old_collection_name.startswith("textbook_"):
                        new_collection_name = f"textbook_{new_book_id}"
                        content_type = "textbook"
                    else:  # guide_
                        new_collection_name = f"guide_{new_book_id}"
                        content_type = "guide"

                    logger.info(f"Processing collection: {old_collection_name} -> {new_collection_name}")

                    # Ki·ªÉm tra xem collection m·ªõi ƒë√£ t·ªìn t·∫°i ch∆∞a
                    existing_collections = [c.name for c in self.qdrant_client.get_collections().collections]
                    if new_collection_name in existing_collections:
                        return {
                            "success": False,
                            "error": f"Collection '{new_collection_name}' already exists. Cannot update book_id to '{new_book_id}'"
                        }

                    # T·∫°o collection m·ªõi
                    if not self._ensure_collection_exists(new_collection_name):
                        return {
                            "success": False,
                            "error": f"Failed to create new collection '{new_collection_name}'"
                        }

                    # L·∫•y t·∫•t c·∫£ points t·ª´ collection c≈©
                    scroll_result = self.qdrant_client.scroll(
                        collection_name=old_collection_name,
                        limit=10000,  # L·∫•y nhi·ªÅu points
                        with_payload=True,
                        with_vectors=True
                    )

                    points_to_copy = scroll_result[0]
                    logger.info(f"Found {len(points_to_copy)} points to copy from {old_collection_name}")

                    if points_to_copy:
                        # T·∫°o points m·ªõi v·ªõi book_id ƒë∆∞·ª£c update
                        new_points = []
                        for point in points_to_copy:
                            # Update payload v·ªõi book_id m·ªõi
                            updated_payload = point.payload.copy()
                            updated_payload["book_id"] = new_book_id

                            new_points.append(
                                qdrant_models.PointStruct(
                                    id=point.id,
                                    vector=point.vector,
                                    payload=updated_payload
                                )
                            )

                        # Upsert points v√†o collection m·ªõi theo batch
                        batch_size = 100
                        for i in range(0, len(new_points), batch_size):
                            batch = new_points[i:i + batch_size]
                            self.qdrant_client.upsert(
                                collection_name=new_collection_name,
                                points=batch
                            )
                            logger.info(f"Copied batch {i//batch_size + 1}/{(len(new_points)-1)//batch_size + 1}")

                    # X√≥a collection c≈©
                    self.qdrant_client.delete_collection(old_collection_name)
                    logger.info(f"Deleted old collection: {old_collection_name}")

                    results.append({
                        "old_collection": old_collection_name,
                        "new_collection": new_collection_name,
                        "content_type": content_type,
                        "points_copied": len(points_to_copy),
                        "success": True
                    })

                except Exception as e:
                    logger.error(f"Error processing collection {old_collection_name}: {e}")
                    results.append({
                        "old_collection": old_collection_name,
                        "success": False,
                        "error": str(e)
                    })

            # Ki·ªÉm tra k·∫øt qu·∫£ t·ªïng th·ªÉ
            successful_updates = [r for r in results if r.get("success")]
            failed_updates = [r for r in results if not r.get("success")]

            if failed_updates:
                return {
                    "success": False,
                    "old_book_id": old_book_id,
                    "new_book_id": new_book_id,
                    "results": results,
                    "error": f"Some collections failed to update: {len(failed_updates)} failed, {len(successful_updates)} succeeded"
                }

            return {
                "success": True,
                "old_book_id": old_book_id,
                "new_book_id": new_book_id,
                "collections_updated": len(successful_updates),
                "results": results,
                "message": f"Successfully updated book_id from '{old_book_id}' to '{new_book_id}' across {len(successful_updates)} collections"
            }

        except Exception as e:
            logger.error(f"Error updating book_id from {old_book_id} to {new_book_id}: {e}")
            return {
                "success": False,
                "error": f"Failed to update book_id: {str(e)}"
            }

    async def global_search(
        self, query: str, limit: int = 10, book_id: Optional[str] = None, lesson_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """T√¨m ki·∫øm to√†n c·ª•c trong t·∫•t c·∫£ s√°ch gi√°o khoa v·ªõi filter t√πy ch·ªçn"""
        from qdrant_client.http import models as qdrant_models

        if not self.qdrant_client or not self.embedding_model:
            return {
                "success": False,
                "error": "Qdrant client or embedding model not initialized",
            }

        try:
            # L·∫•y danh s√°ch t·∫•t c·∫£ collections
            collections = self.qdrant_client.get_collections().collections
            collection_names = [c.name for c in collections]

            # L·ªçc c√°c collection textbook v√† guide
            textbook_collections = [name for name in collection_names if name.startswith("textbook_")]
            guide_collections = [name for name in collection_names if name.startswith("guide_")]

            if book_id:
                # N·∫øu c√≥ book_id, ch·ªâ t√¨m trong collection c·ªßa book ƒë√≥
                target_collection = f"textbook_{book_id}"
                if target_collection not in collection_names:
                    return {
                        "success": True,
                        "query": query,
                        "results": [],
                        "message": f"Collection {target_collection} not found"
                    }
                search_collections = [target_collection]
            else:
                # N·∫øu kh√¥ng c√≥ book_id, t√¨m trong t·∫•t c·∫£ collections
                search_collections = textbook_collections + guide_collections

            if not search_collections:
                return {
                    "success": True,
                    "query": query,
                    "results": [],
                    "message": "No textbook or guide collections found"
                }

            # T·∫°o embedding cho query
            query_vector = self.embedding_model.encode(query).tolist()

            # Chu·∫©n b·ªã filters cho Qdrant - ch·ªâ t√¨m content, kh√¥ng t√¨m metadata
            filter_conditions = [
                qdrant_models.FieldCondition(
                    key="type",
                    match=qdrant_models.MatchValue(value="content")
                )
            ]

            # Th√™m filter cho lesson_id n·∫øu c√≥
            if lesson_id:
                filter_conditions.append(
                    qdrant_models.FieldCondition(
                        key="lesson_id",
                        match=qdrant_models.MatchValue(value=lesson_id)
                    )
                )



            # T·∫°o filter cu·ªëi c√πng
            qdrant_filter = qdrant_models.Filter(must=filter_conditions)

            # T√¨m ki·∫øm trong t·∫•t c·∫£ collections
            all_results = []

            for collection_name in search_collections:
                try:
                    search_result = self.qdrant_client.search(
                        collection_name=collection_name,
                        query_vector=query_vector,
                        query_filter=qdrant_filter,
                        limit=limit,
                        with_payload=True,
                        score_threshold=0.3,
                    )

                    # Th√™m collection_name v√†o m·ªói result
                    for result in search_result:
                        result.payload["source_collection"] = collection_name
                        all_results.append(result)

                except Exception as e:
                    logger.warning(f"Error searching in collection {collection_name}: {e}")
                    continue

            # S·∫Øp x·∫øp k·∫øt qu·∫£ theo score
            all_results.sort(key=lambda x: x.score, reverse=True)

            # L·∫•y top results
            search_result = all_results[:limit]

            # Format k·∫øt qu·∫£
            results = []
            for scored_point in search_result:
                payload = scored_point.payload or {}

                # B·ªè qua metadata point (ƒë√£ ƒë∆∞·ª£c filter ·ªü tr√™n nh∆∞ng double check)
                if payload.get("type") == "metadata":
                    continue

                # Chu·∫©n b·ªã semantic metadata
                semantic_tags = payload.get("semantic_tags", [])

                # Backward compatibility
                if not semantic_tags and "semantic_type" in payload:
                    semantic_tags = [{"type": payload["semantic_type"], "confidence": 0.8}]

                results.append({
                    "text": payload.get("text", ""),
                    "score": scored_point.score,
                    "book_id": payload.get("book_id", ""),
                    "lesson_id": payload.get("lesson_id", ""),
                    "type": payload.get("type", ""),
                    "content_type": payload.get("content_type", ""),
                    "semantic_tags": semantic_tags,
                    "key_concepts": payload.get("key_concepts", []),
                    "estimated_difficulty": payload.get("estimated_difficulty", "basic"),
                    "contains_examples": payload.get("contains_examples", False),
                    "contains_definitions": payload.get("contains_definitions", False),
                    "contains_formulas": payload.get("contains_formulas", False),
                    "analysis_method": payload.get("analysis_method", "unknown")
                })

            # S·∫Øp x·∫øp theo score (k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c gi·ªõi h·∫°n b·ªüi limit trong search)
            results.sort(key=lambda x: x["score"], reverse=True)

            return {
                "success": True,
                "query": query,
                "results": results,
                "collections_searched": search_collections,
                "total_results_found": len(results)
            }

        except Exception as e:
            logger.error(f"Error in global search: {e}")
            return {"success": False, "error": str(e)}

    async def delete_textbook_by_book_id(self, book_id: str) -> Dict[str, Any]:
        """
        X√≥a textbook b·∫±ng book_id (x√≥a collection ri√™ng c·ªßa book_id)

        Args:
            book_id: ID c·ªßa textbook c·∫ßn x√≥a

        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ x√≥a
        """
        try:
            if not self.qdrant_client:
                return {
                    "success": False,
                    "error": "Qdrant client not initialized"
                }

            # X√°c ƒë·ªãnh collection name theo pattern textbook_bookId
            collection_name = f"textbook_{book_id}"

            # Ki·ªÉm tra collection c√≥ t·ªìn t·∫°i kh√¥ng
            collections = self.qdrant_client.get_collections().collections
            existing_names = [c.name for c in collections]

            if collection_name not in existing_names:
                return {
                    "success": False,
                    "error": f"Textbook collection {collection_name} not found",
                    "book_id": book_id
                }

            # X√≥a to√†n b·ªô collection
            self.qdrant_client.delete_collection(collection_name=collection_name)

            logger.info(f"Deleted collection: {collection_name} for book_id: {book_id}")

            return {
                "success": True,
                "message": f"Textbook '{book_id}' deleted successfully (collection removed)",
                "book_id": book_id,
                "collection_name": collection_name,
                "operation": "collection_deleted"
            }

        except Exception as e:
            logger.error(f"Error deleting textbook {book_id}: {e}")
            return {
                "success": False,
                "error": str(e),
                "book_id": book_id
            }

    async def delete_book_clean(self, book_id: str) -> Dict[str, Any]:
        """
        X√≥a to√†n b·ªô book (collection) - Clean version v·ªõi exception handling

        Args:
            book_id: ID c·ªßa book c·∫ßn x√≥a

        Returns:
            Dict ch·ª©a th√¥ng tin x√≥a th√†nh c√¥ng

        Raises:
            ValueError: N·∫øu book_id kh√¥ng h·ª£p l·ªá
            RuntimeError: N·∫øu Qdrant client ch∆∞a kh·ªüi t·∫°o
            FileNotFoundError: N·∫øu collection kh√¥ng t·ªìn t·∫°i
            Exception: C√°c l·ªói kh√°c t·ª´ Qdrant
        """
        self._ensure_service_initialized()

        if not book_id or not book_id.strip():
            raise ValueError("book_id cannot be empty")

        if not self.qdrant_client:
            raise RuntimeError("Qdrant client not initialized")

        # T√¨m t·∫•t c·∫£ collections li√™n quan ƒë·∫øn book_id (c·∫£ textbook v√† guide)
        collections = self.qdrant_client.get_collections().collections
        existing_names = [c.name for c in collections]

        target_collections = []
        for name in existing_names:
            if name.endswith(f"_{book_id}"):
                target_collections.append(name)

        if not target_collections:
            raise FileNotFoundError(f"Book '{book_id}' not found (no collections found for book_id)")

        # X√≥a t·∫•t c·∫£ collections li√™n quan
        deleted_collections = []
        for collection_name in target_collections:
            self.qdrant_client.delete_collection(collection_name=collection_name)
            deleted_collections.append(collection_name)
            logger.info(f"‚úÖ Deleted collection: {collection_name}")

        logger.info(f"‚úÖ Deleted book '{book_id}' ({len(deleted_collections)} collections)")

        return {
            "book_id": book_id,
            "deleted_collections": deleted_collections,
            "operation": "book_deleted",
            "message": f"Book '{book_id}' and all its lessons deleted successfully from {len(deleted_collections)} collections"
        }

    async def delete_lesson_clean(self, lesson_id: str) -> Dict[str, Any]:
        """
        X√≥a lesson c·ª• th·ªÉ - Clean version v·ªõi exception handling

        Args:
            lesson_id: ID c·ªßa lesson c·∫ßn x√≥a

        Returns:
            Dict ch·ª©a th√¥ng tin x√≥a th√†nh c√¥ng

        Raises:
            ValueError: N·∫øu lesson_id kh√¥ng h·ª£p l·ªá
            RuntimeError: N·∫øu Qdrant client ch∆∞a kh·ªüi t·∫°o
            FileNotFoundError: N·∫øu lesson kh√¥ng t·ªìn t·∫°i
            Exception: C√°c l·ªói kh√°c t·ª´ Qdrant
        """
        from qdrant_client.http import models as qdrant_models

        self._ensure_service_initialized()

        if not lesson_id or not lesson_id.strip():
            raise ValueError("lesson_id cannot be empty")

        if not self.qdrant_client:
            raise RuntimeError("Qdrant client not initialized")

        # T√¨m lesson trong c√°c collections
        collections = self.qdrant_client.get_collections().collections
        textbook_collections = [c.name for c in collections if c.name.startswith("textbook_")]

        if not textbook_collections:
            raise FileNotFoundError("No textbook collections found")

        # T·∫°o filter ƒë·ªÉ t√¨m lesson
        lesson_filter = qdrant_models.Filter(
            must=[
                qdrant_models.FieldCondition(
                    key="lesson_id",
                    match=qdrant_models.MatchValue(value=lesson_id)
                ),
                qdrant_models.FieldCondition(
                    key="type",
                    match=qdrant_models.MatchValue(value="content")
                )
            ]
        )

        # T√¨m lesson trong t·ª´ng collection
        found_collection = None
        found_book_id = None

        for collection_name in textbook_collections:
            try:
                scroll_result = self.qdrant_client.scroll(
                    collection_name=collection_name,
                    scroll_filter=lesson_filter,
                    limit=1,
                    with_payload=True,
                    with_vectors=False
                )

                points = scroll_result[0]
                if points:
                    found_collection = collection_name
                    found_book_id = points[0].payload.get("book_id", collection_name.replace("textbook_", ""))
                    break

            except Exception as e:
                logger.warning(f"Error checking collection {collection_name}: {e}")
                continue

        if not found_collection:
            raise FileNotFoundError(f"Lesson '{lesson_id}' not found in any textbook collection")

        # X√≥a lesson
        delete_filter = qdrant_models.Filter(
            must=[
                qdrant_models.FieldCondition(
                    key="lesson_id",
                    match=qdrant_models.MatchValue(value=lesson_id)
                )
            ]
        )

        self.qdrant_client.delete(
            collection_name=found_collection,
            points_selector=qdrant_models.FilterSelector(filter=delete_filter)
        )

        logger.info(f"‚úÖ Deleted lesson '{lesson_id}' from book '{found_book_id}' (collection: {found_collection})")

        return {
            "lesson_id": lesson_id,
            "book_id": found_book_id,
            "collection_name": found_collection,
            "operation": "lesson_deleted",
            "message": f"Lesson '{lesson_id}' deleted successfully from book '{found_book_id}'"
        }

    async def delete_lesson_in_book_clean(self, book_id: str, lesson_id: str) -> Dict[str, Any]:
        """
        X√≥a lesson c·ª• th·ªÉ trong book c·ª• th·ªÉ - Clean version v·ªõi exception handling

        Args:
            book_id: ID c·ªßa book ch·ª©a lesson
            lesson_id: ID c·ªßa lesson c·∫ßn x√≥a

        Returns:
            Dict ch·ª©a th√¥ng tin x√≥a th√†nh c√¥ng

        Raises:
            ValueError: N·∫øu book_id ho·∫∑c lesson_id kh√¥ng h·ª£p l·ªá
            RuntimeError: N·∫øu Qdrant client ch∆∞a kh·ªüi t·∫°o
            FileNotFoundError: N·∫øu book ho·∫∑c lesson kh√¥ng t·ªìn t·∫°i
            Exception: C√°c l·ªói kh√°c t·ª´ Qdrant
        """
        from qdrant_client.http import models as qdrant_models

        self._ensure_service_initialized()

        if not book_id or not book_id.strip():
            raise ValueError("book_id cannot be empty")

        if not lesson_id or not lesson_id.strip():
            raise ValueError("lesson_id cannot be empty")

        if not self.qdrant_client:
            raise RuntimeError("Qdrant client not initialized")

        collection_name = f"textbook_{book_id}"

        # Ki·ªÉm tra collection c√≥ t·ªìn t·∫°i kh√¥ng
        collections = self.qdrant_client.get_collections().collections
        existing_names = [c.name for c in collections]

        if collection_name not in existing_names:
            raise FileNotFoundError(f"Book '{book_id}' not found (collection '{collection_name}' does not exist)")

        # Ki·ªÉm tra lesson c√≥ t·ªìn t·∫°i trong collection kh√¥ng
        lesson_filter = qdrant_models.Filter(
            must=[
                qdrant_models.FieldCondition(
                    key="lesson_id",
                    match=qdrant_models.MatchValue(value=lesson_id)
                ),
                qdrant_models.FieldCondition(
                    key="type",
                    match=qdrant_models.MatchValue(value="content")
                )
            ]
        )

        try:
            scroll_result = self.qdrant_client.scroll(
                collection_name=collection_name,
                scroll_filter=lesson_filter,
                limit=1,
                with_payload=True,
                with_vectors=False
            )

            points = scroll_result[0]
            if not points:
                raise FileNotFoundError(f"Lesson '{lesson_id}' not found in book '{book_id}'")

        except Exception as e:
            if "not found" in str(e).lower():
                raise FileNotFoundError(f"Lesson '{lesson_id}' not found in book '{book_id}'")
            raise

        # X√≥a lesson
        delete_filter = qdrant_models.Filter(
            must=[
                qdrant_models.FieldCondition(
                    key="lesson_id",
                    match=qdrant_models.MatchValue(value=lesson_id)
                )
            ]
        )

        self.qdrant_client.delete(
            collection_name=collection_name,
            points_selector=qdrant_models.FilterSelector(filter=delete_filter)
        )

        logger.info(f"‚úÖ Deleted lesson '{lesson_id}' from book '{book_id}' (collection: {collection_name})")

        return {
            "lesson_id": lesson_id,
            "book_id": book_id,
            "collection_name": collection_name,
            "operation": "lesson_deleted_in_book",
            "message": f"Lesson '{lesson_id}' deleted successfully from book '{book_id}'"
        }

    async def check_lesson_id_exists(self, lesson_id: str) -> Dict[str, Any]:
        """
        Ki·ªÉm tra lesson_id ƒë√£ t·ªìn t·∫°i trong c√°c textbook collections ch∆∞a

        Args:
            lesson_id: ID c·ªßa lesson c·∫ßn ki·ªÉm tra

        Returns:
            Dict ch·ª©a th√¥ng tin v·ªÅ lesson_id existence
        """
        self._ensure_service_initialized()

        if not self.qdrant_client:
            return {
                "success": False,
                "exists": False,
                "error": "Qdrant client not initialized"
            }

        try:
            from qdrant_client.http import models as qdrant_models

            # L·∫•y t·∫•t c·∫£ collections
            collections = self.qdrant_client.get_collections().collections
            existing_names = [c.name for c in collections]

            # T√¨m trong t·∫•t c·∫£ textbook collections
            textbook_collections = [name for name in existing_names if name.startswith("textbook_")]

            if not textbook_collections:
                return {
                    "success": True,
                    "exists": False,
                    "message": "No textbook collections found - lesson_id is available"
                }

            # T·∫°o filter ƒë·ªÉ t√¨m lesson_id
            lesson_filter = qdrant_models.Filter(
                must=[
                    qdrant_models.FieldCondition(
                        key="lesson_id",
                        match=qdrant_models.MatchValue(value=lesson_id)
                    ),
                    qdrant_models.FieldCondition(
                        key="type",
                        match=qdrant_models.MatchValue(value="content")
                    )
                ]
            )

            # T√¨m trong t·ª´ng collection
            for collection_name in textbook_collections:
                try:
                    scroll_result = self.qdrant_client.scroll(
                        collection_name=collection_name,
                        scroll_filter=lesson_filter,
                        limit=1,
                        with_payload=True,
                        with_vectors=False
                    )

                    points = scroll_result[0]

                    if points:
                        # Lesson_id ƒë√£ t·ªìn t·∫°i
                        existing_point = points[0]
                        existing_book_id = existing_point.payload.get("book_id", "unknown")

                        return {
                            "success": True,
                            "exists": True,
                            "lesson_id": lesson_id,
                            "existing_book_id": existing_book_id,
                            "collection_name": collection_name,
                            "message": f"Lesson ID '{lesson_id}' already exists in book '{existing_book_id}'"
                        }
                except Exception as e:
                    logger.warning(f"Error checking collection {collection_name}: {e}")
                    continue

            # Lesson_id ch∆∞a t·ªìn t·∫°i trong b·∫•t k·ª≥ collection n√†o
            return {
                "success": True,
                "exists": False,
                "lesson_id": lesson_id,
                "message": f"Lesson ID '{lesson_id}' is available"
            }

        except Exception as e:
            logger.error(f"Error checking lesson_id existence {lesson_id}: {e}")
            return {
                "success": False,
                "exists": False,
                "error": f"Error checking lesson_id: {str(e)}",
                "lesson_id": lesson_id
            }

    async def delete_textbook_by_lesson_id(self, lesson_id: str) -> Dict[str, Any]:
        """
        X√≥a lesson b·∫±ng lesson_id (x√≥a t·∫•t c·∫£ points c√≥ lesson_id t·ª´ collection ri√™ng)

        Args:
            lesson_id: ID c·ªßa lesson c·∫ßn x√≥a

        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ x√≥a
        """
        from qdrant_client.http import models as qdrant_models

        try:
            if not self.qdrant_client:
                return {
                    "success": False,
                    "error": "Qdrant client not initialized"
                }

            # T√¨m lesson trong c√°c textbook collections
            collections = self.qdrant_client.get_collections().collections
            existing_names = [c.name for c in collections]
            textbook_collections = [name for name in existing_names if name.startswith("textbook_")]

            if not textbook_collections:
                return {
                    "success": False,
                    "error": "No textbook collections found",
                    "lesson_id": lesson_id
                }

            # T·∫°o filter ƒë·ªÉ t√¨m lesson_id
            delete_filter = qdrant_models.Filter(
                must=[
                    qdrant_models.FieldCondition(
                        key="lesson_id",
                        match=qdrant_models.MatchValue(value=lesson_id)
                    )
                ]
            )

            # T√¨m lesson trong t·ª´ng collection
            found_collection = None
            found_book_id = None

            for collection_name in textbook_collections:
                try:
                    scroll_result = self.qdrant_client.scroll(
                        collection_name=collection_name,
                        scroll_filter=delete_filter,
                        limit=1,
                        with_payload=True,
                        with_vectors=False
                    )

                    if scroll_result[0]:  # T√¨m th·∫•y lesson
                        found_collection = collection_name
                        found_book_id = scroll_result[0][0].payload.get("book_id", "unknown")
                        break
                except Exception as e:
                    logger.warning(f"Error checking collection {collection_name}: {e}")
                    continue

            if not found_collection:
                return {
                    "success": False,
                    "error": f"No lesson found with lesson_id: {lesson_id}",
                    "lesson_id": lesson_id
                }

            # X√≥a t·∫•t c·∫£ points c√≥ lesson_id n√†y t·ª´ collection t√¨m th·∫•y
            delete_result = self.qdrant_client.delete(
                collection_name=found_collection,
                points_selector=qdrant_models.FilterSelector(
                    filter=delete_filter
                )
            )

            logger.info(f"Deleted all points for lesson_id: {lesson_id} from collection: {found_collection}")

            return {
                "success": True,
                "message": f"Lesson '{lesson_id}' deleted successfully from collection {found_collection}",
                "lesson_id": lesson_id,
                "book_id": found_book_id,
                "collection_name": found_collection,
                "operation_info": delete_result.operation_id if hasattr(delete_result, 'operation_id') else "completed"
            }

        except Exception as e:
            logger.error(f"Error deleting textbook by lesson_id {lesson_id}: {e}")
            return {
                "success": False,
                "error": str(e),
                "lesson_id": lesson_id
            }

    async def get_textbook_info_by_book_id(self, book_id: str) -> Dict[str, Any]:
        """
        L·∫•y th√¥ng tin chi ti·∫øt v·ªÅ textbook theo book_id t·ª´ collection ri√™ng

        Args:
            book_id: ID c·ªßa textbook c·∫ßn l·∫•y th√¥ng tin

        Returns:
            Dict ch·ª©a th√¥ng tin chi ti·∫øt v·ªÅ textbook
        """
        self._ensure_service_initialized()

        if not self.qdrant_client:
            return {
                "success": False,
                "error": "Qdrant client not initialized"
            }

        try:
            from qdrant_client.http import models as qdrant_models

            # Ki·ªÉm tra c·∫£ textbook v√† guide collections
            textbook_collection = f"textbook_{book_id}"
            guide_collection = f"guide_{book_id}"

            collections = self.qdrant_client.get_collections().collections
            existing_names = [c.name for c in collections]

            # ∆Øu ti√™n textbook collection, fallback sang guide collection
            if textbook_collection in existing_names:
                collection_name = textbook_collection
                content_type = "textbook"
            elif guide_collection in existing_names:
                collection_name = guide_collection
                content_type = "guide"
            else:
                return {
                    "success": False,
                    "error": f"No collection found for book_id '{book_id}'. Checked: {textbook_collection}, {guide_collection}",
                    "book_id": book_id
                }

            # T√¨m metadata point c·ªßa textbook
            metadata_filter = qdrant_models.Filter(
                must=[
                    qdrant_models.FieldCondition(
                        key="book_id",
                        match=qdrant_models.MatchValue(value=book_id)
                    ),
                    qdrant_models.FieldCondition(
                        key="type",
                        match=qdrant_models.MatchValue(value="metadata")
                    )
                ]
            )

            metadata_result = self.qdrant_client.scroll(
                collection_name=collection_name,
                scroll_filter=metadata_filter,
                limit=1,
                with_payload=True,
                with_vectors=False
            )

            if not metadata_result[0]:
                return {
                    "success": False,
                    "error": f"Textbook with book_id '{book_id}' not found",
                    "book_id": book_id
                }

            # L·∫•y metadata
            metadata_point = metadata_result[0][0]
            metadata_payload = metadata_point.payload or {}

            # T√¨m content points ƒë·ªÉ l·∫•y th·ªëng k√™
            content_filter = qdrant_models.Filter(
                must=[
                    qdrant_models.FieldCondition(
                        key="book_id",
                        match=qdrant_models.MatchValue(value=book_id)
                    ),
                    qdrant_models.FieldCondition(
                        key="type",
                        match=qdrant_models.MatchValue(value="content")
                    )
                ]
            )

            content_result = self.qdrant_client.scroll(
                collection_name=collection_name,
                scroll_filter=content_filter,
                limit=1000,
                with_payload=True,
                with_vectors=False
            )

            # T√≠nh to√°n th·ªëng k√™
            total_chunks = len(content_result[0])
            unique_lessons = set()

            for point in content_result[0]:
                payload = point.payload or {}
                lesson_id = payload.get("lesson_id")
                if lesson_id:
                    unique_lessons.add(lesson_id)

            return {
                "success": True,
                "book_id": book_id,
                "content_type": content_type,  # Th√™m th√¥ng tin lo·∫°i content
                "book_info": {
                    "book_id": book_id,
                    "content_type": content_type,
                    "total_chunks": metadata_payload.get("total_chunks", total_chunks),
                    "total_lessons": len(unique_lessons),
                    "processed_at": metadata_payload.get("processed_at"),
                },
                "metadata": metadata_payload,  # Tr·∫£ v·ªÅ to√†n b·ªô metadata bao g·ªìm file_url v√† uploaded_at
                "statistics": {
                    "total_chunks": total_chunks,
                    "total_lessons": len(unique_lessons),
                    "unique_lesson_ids": list(unique_lessons)
                },
                "collection_name": collection_name
            }

        except Exception as e:
            logger.error(f"Error getting textbook info for book_id {book_id}: {e}")
            return {
                "success": False,
                "error": f"Error getting textbook info: {str(e)}",
                "book_id": book_id
            }

    async def get_textbook_lessons_by_book_id(self, book_id: str) -> Dict[str, Any]:
        """
        L·∫•y danh s√°ch lessons theo book_id t·ª´ collection ri√™ng

        Args:
            book_id: ID c·ªßa textbook

        Returns:
            Dict ch·ª©a danh s√°ch lessons
        """
        self._ensure_service_initialized()

        if not self.qdrant_client:
            return {
                "success": False,
                "error": "Qdrant client not initialized"
            }

        try:
            from qdrant_client.http import models as qdrant_models

            # S·ª≠ d·ª•ng collection ri√™ng cho textbook
            collection_name = f"textbook_{book_id}"

            # Ki·ªÉm tra collection c√≥ t·ªìn t·∫°i kh√¥ng
            collections = self.qdrant_client.get_collections().collections
            existing_names = [c.name for c in collections]

            if collection_name not in existing_names:
                return {
                    "success": False,
                    "error": f"Textbook collection {collection_name} not found",
                    "book_id": book_id
                }

            # T√¨m t·∫•t c·∫£ content points c·ªßa book_id
            content_filter = qdrant_models.Filter(
                must=[
                    qdrant_models.FieldCondition(
                        key="book_id",
                        match=qdrant_models.MatchValue(value=book_id)
                    ),
                    qdrant_models.FieldCondition(
                        key="type",
                        match=qdrant_models.MatchValue(value="content")
                    )
                ]
            )

            content_result = self.qdrant_client.scroll(
                collection_name=collection_name,
                scroll_filter=content_filter,
                limit=1000,
                with_payload=True,
                with_vectors=False
            )

            if not content_result[0]:
                return {
                    "success": False,
                    "error": f"No lessons found for book_id '{book_id}'",
                    "book_id": book_id
                }

            # T·ªïng h·ª£p th√¥ng tin lessons
            lessons_map = {}

            for point in content_result[0]:
                payload = point.payload or {}
                lesson_id = payload.get("lesson_id")

                if lesson_id and lesson_id not in lessons_map:
                    lessons_map[lesson_id] = {
                        "lesson_id": lesson_id,
                        "book_id": book_id,
                        "chunk_count": 0,
                        "has_examples": False,
                        "has_definitions": False,
                        "has_formulas": False
                    }

                if lesson_id:
                    lessons_map[lesson_id]["chunk_count"] += 1

                    # C·∫≠p nh·∫≠t content features
                    if payload.get("contains_examples"):
                        lessons_map[lesson_id]["has_examples"] = True
                    if payload.get("contains_definitions"):
                        lessons_map[lesson_id]["has_definitions"] = True
                    if payload.get("contains_formulas"):
                        lessons_map[lesson_id]["has_formulas"] = True

            lessons_list = list(lessons_map.values())
            lessons_list.sort(key=lambda x: x["lesson_id"])  # Sort by lesson_id

            return {
                "success": True,
                "book_id": book_id,
                "total_lessons": len(lessons_list),
                "lessons": lessons_list,
                "collection_name": collection_name
            }

        except Exception as e:
            logger.error(f"Error getting textbook lessons for book_id {book_id}: {e}")
            return {
                "success": False,
                "error": f"Error getting textbook lessons: {str(e)}",
                "book_id": book_id
            }

    async def get_lesson_info_by_lesson_id(self, lesson_id: str, book_id: Optional[str] = None) -> Dict[str, Any]:
        """
        L·∫•y th√¥ng tin chi ti·∫øt v·ªÅ lesson theo lesson_id t·ª´ c√°c textbook collections

        T·ªëi ∆∞u h√≥a: N·∫øu c√≥ book_id th√¨ t√¨m tr·ª±c ti·∫øp trong collection ƒë√≥,
        ch·ªâ tr·∫£ v·ªÅ metadata (ƒë·∫∑c bi·ªát l√† file_url) m√† kh√¥ng c·∫ßn chunks ƒë·ªÉ ti·∫øt ki·ªám th·ªùi gian

        Args:
            lesson_id: ID c·ªßa lesson
            book_id: Optional - ID c·ªßa book ƒë·ªÉ t√¨m tr·ª±c ti·∫øp trong collection c·ª• th·ªÉ

        Returns:
            Dict ch·ª©a th√¥ng tin metadata c·ªßa lesson (kh√¥ng bao g·ªìm chunks)
        """
        self._ensure_service_initialized()

        if not self.qdrant_client:
            return {
                "success": False,
                "error": "Qdrant client not initialized"
            }

        try:
            from qdrant_client.http import models as qdrant_models

            # X√°c ƒë·ªãnh collections c·∫ßn t√¨m
            if book_id:
                # N·∫øu c√≥ book_id, t√¨m tr·ª±c ti·∫øp trong collection c·ª• th·ªÉ
                target_collections = [f"textbook_{book_id}"]
                logger.info(f"Searching for lesson_id '{lesson_id}' in specific collection: textbook_{book_id}")
            else:
                # N·∫øu kh√¥ng c√≥ book_id, t√¨m trong t·∫•t c·∫£ textbook collections
                collections = self.qdrant_client.get_collections().collections
                existing_names = [c.name for c in collections]
                target_collections = [name for name in existing_names if name.startswith("textbook_")]
                logger.info(f"Searching for lesson_id '{lesson_id}' in all textbook collections: {target_collections}")

            if not target_collections:
                return {
                    "success": False,
                    "error": "No textbook collections found" + (f" for book_id '{book_id}'" if book_id else ""),
                    "lesson_id": lesson_id,
                    "book_id": book_id
                }

            # T√¨m lesson trong collections (ch·ªâ l·∫•y 1 point ƒë·ªÉ c√≥ metadata)
            lesson_filter = qdrant_models.Filter(
                must=[
                    qdrant_models.FieldCondition(
                        key="lesson_id",
                        match=qdrant_models.MatchValue(value=lesson_id)
                    ),
                    qdrant_models.FieldCondition(
                        key="type",
                        match=qdrant_models.MatchValue(value="content")
                    )
                ]
            )

            found_collection = None
            lesson_point = None

            for collection_name in target_collections:
                try:
                    result = self.qdrant_client.scroll(
                        collection_name=collection_name,
                        scroll_filter=lesson_filter,
                        limit=1,  # Ch·ªâ l·∫•y 1 point ƒë·ªÉ c√≥ metadata
                        with_payload=True,
                        with_vectors=False  # Kh√¥ng c·∫ßn vectors
                    )

                    if result[0]:  # T√¨m th·∫•y lesson
                        found_collection = collection_name
                        lesson_point = result[0][0]  # L·∫•y point ƒë·∫ßu ti√™n
                        break
                except Exception as e:
                    logger.warning(f"Error checking collection {collection_name}: {e}")
                    continue

            if not lesson_point:
                return {
                    "success": False,
                    "error": f"Lesson with lesson_id '{lesson_id}' not found" + (f" in book '{book_id}'" if book_id else ""),
                    "lesson_id": lesson_id,
                    "book_id": book_id
                }

            # L·∫•y metadata t·ª´ point ƒë·∫ßu ti√™n (kh√¥ng c·∫ßn l·∫•y t·∫•t c·∫£ chunks)
            payload = lesson_point.payload or {}

            # ƒê·∫øm t·ªïng s·ªë chunks trong lesson (n·∫øu c·∫ßn)
            count_filter = qdrant_models.Filter(
                must=[
                    qdrant_models.FieldCondition(
                        key="lesson_id",
                        match=qdrant_models.MatchValue(value=lesson_id)
                    ),
                    qdrant_models.FieldCondition(
                        key="type",
                        match=qdrant_models.MatchValue(value="content")
                    )
                ]
            )

            try:
                count_result = self.qdrant_client.count(
                    collection_name=found_collection,
                    count_filter=count_filter
                )
                total_chunks = count_result.count
            except Exception as e:
                logger.warning(f"Error counting chunks: {e}")
                total_chunks = 1

            # T·∫°o lesson info v·ªõi metadata c·∫ßn thi·∫øt
            lesson_data = {
                "lessonId": lesson_id,
                "bookId": payload.get("book_id", "Unknown"),
                "fileUrl": payload.get("file_url", ""),
                "uploaded_at": payload.get("uploaded_at", ""),
                "processed_at": payload.get("processed_at", ""),
                "content_type": payload.get("content_type", "textbook"),
                "total_chunks": total_chunks,
                "collection_name": found_collection,
                # Th√™m m·ªôt s·ªë metadata h·ªØu √≠ch kh√°c
                "lesson_title": payload.get("lesson_title", ""),
                "chapter_title": payload.get("chapter_title", ""),
                "page_range": payload.get("page_range", ""),
                "word_count_total": payload.get("word_count_total", 0),
                "estimated_difficulty": payload.get("estimated_difficulty", "basic")
            }

            return {
                "success": True,
                "data": lesson_data,
                "message": f"Retrieved lesson '{lesson_id}' metadata successfully" + (f" from book '{book_id}'" if book_id else "")
            }

        except Exception as e:
            logger.error(f"Error getting lesson info for lesson_id {lesson_id}: {e}")
            return {
                "success": False,
                "error": f"Error getting lesson info: {str(e)}",
                "lesson_id": lesson_id,
                "book_id": book_id
            }

    async def get_all_textbooks(self) -> Dict[str, Any]:
        """
        L·∫•y danh s√°ch t·∫•t c·∫£ textbooks t·ª´ individual collections

        Returns:
            Dict ch·ª©a danh s√°ch textbooks v·ªõi metadata
        """
        from qdrant_client.http import models as qdrant_models

        try:
            if not self.qdrant_client:
                logger.error("‚ùå Qdrant client not initialized in get_all_textbooks")
                return {
                    "success": False,
                    "error": "Qdrant client not initialized"
                }

            # L·∫•y t·∫•t c·∫£ collections
            collections = self.qdrant_client.get_collections().collections
            existing_names = [c.name for c in collections]

            logger.info(f"üîç Found {len(existing_names)} collections: {existing_names}")

            # T√¨m c√°c collections textbook v√† guide
            textbook_collections = [name for name in existing_names if name.startswith(('textbook_', 'guide_'))]

            if not textbook_collections:
                return {
                    "success": True,
                    "textbooks": [],
                    "message": "No textbooks found. No textbook or guide collections exist."
                }

            # T√¨m metadata t·ª´ t·∫•t c·∫£ collections
            textbooks = []

            for collection_name in textbook_collections:
                try:
                    logger.info(f"üîç Checking collection: {collection_name}")

                    # T√¨m metadata points trong collection n√†y
                    metadata_filter = qdrant_models.Filter(
                        must=[
                            qdrant_models.FieldCondition(
                                key="type",
                                match=qdrant_models.MatchValue(value="metadata")
                            )
                        ]
                    )

                    scroll_result = self.qdrant_client.scroll(
                        collection_name=collection_name,
                        scroll_filter=metadata_filter,
                        limit=100,
                        with_payload=True,
                        with_vectors=False
                    )

                    if scroll_result[0]:
                        for point in scroll_result[0]:
                            payload = point.payload or {}

                            # L·∫•y th√¥ng tin t·ª´ metadata point
                            book_id = payload.get("book_id", "unknown")
                            content_type = payload.get("content_type", "unknown")

                            textbook_data = {
                                "book_id": book_id,
                                "content_type": content_type,
                                "collection_name": collection_name,
                                "total_chunks": payload.get("total_chunks", 0),
                                "processed_at": payload.get("processed_at"),
                                "model": payload.get("model", "unknown"),
                                "chunk_size": payload.get("chunk_size", 0),
                                "chunk_overlap": payload.get("chunk_overlap", 0),
                            }
                            textbooks.append(textbook_data)

                except Exception as e:
                    logger.warning(f"Error processing collection {collection_name}: {e}")
                    continue

            return {
                "success": True,
                "textbooks": textbooks,
                "total_textbooks": len(textbooks),
                "collections_checked": textbook_collections
            }

        except Exception as e:
            logger.error(f"Error getting all textbooks: {e}")
            return {
                "success": False,
                "error": str(e)
            }


# Factory function ƒë·ªÉ t·∫°o QdrantService instance
def get_qdrant_service() -> QdrantService:
    """
    T·∫°o QdrantService instance m·ªõi

    Returns:
        QdrantService: Fresh instance
    """
    return QdrantService()
