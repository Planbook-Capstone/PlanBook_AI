"""
Enhanced Textbook Service - C·∫£i ti·∫øn x·ª≠ l√Ω s√°ch gi√°o khoa v·ªõi OCR v√† LLM
Tr·∫£ v·ªÅ c·∫•u tr√∫c: S√°ch ‚Üí Ch∆∞∆°ng ‚Üí B√†i ‚Üí N·ªôi dung
"""

import logging
import asyncio
import json
import base64
import uuid
from typing import Dict, Any, List, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor
import fitz  # PyMuPDF
from PIL import Image
import io

from app.services.simple_ocr_service import simple_ocr_service
from app.services.llm_service import llm_service
from app.services.docling_service import docling_service

logger = logging.getLogger(__name__)


class EnhancedTextbookService:
    """Service c·∫£i ti·∫øn ƒë·ªÉ x·ª≠ l√Ω s√°ch gi√°o khoa v·ªõi OCR v√† LLM"""

    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=4)

    async def process_textbook_to_structure(
        self,
        pdf_content: bytes,
        filename: str,
        book_metadata: Optional[Dict[str, Any]] = None,
        lesson_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω PDF s√°ch gi√°o khoa v√† tr·∫£ v·ªÅ c·∫•u tr√∫c ho√†n ch·ªânh

        Args:
            pdf_content: N·ªôi dung PDF
            filename: T√™n file
            book_metadata: Metadata s√°ch (title, subject, grade, etc.)
            lesson_id: ID b√†i h·ªçc t√πy ch·ªçn ƒë·ªÉ li√™n k·∫øt v·ªõi lesson c·ª• th·ªÉ

        Returns:
            Dict v·ªõi c·∫•u tr√∫c: book -> chapters -> lessons -> content
        """
        try:
            logger.info(f"üöÄ Starting enhanced textbook processing: {filename}")

            # Step 1: Extract all pages with Docling (advanced) or OCR (fallback)
            logger.info("üìÑ Extracting pages with Docling...")
            pages_data = await self._extract_pages_with_docling(pdf_content, filename)
            logger.info(f"‚úÖ Extracted {len(pages_data)} pages")

            # Step 2: Add LLM-generated image descriptions
            logger.info("üñºÔ∏è Adding LLM-generated image descriptions...")
            await self._add_image_descriptions(pages_data)
            logger.info("‚úÖ Image descriptions completed")

            # Step 3: Analyze book structure with LLM
            logger.info("üß† Analyzing book structure...")
            book_structure = await self._analyze_book_structure_enhanced(
                pages_data, book_metadata
            )
            logger.info(
                f"üìö Detected {len(book_structure.get('chapters', []))} chapters"
            )

            # Step 4: Build final structure with content and lesson IDs
            logger.info("üîÑ Building final lesson structure...")
            processed_book = await self._build_final_structure(
                book_structure,
                pages_data,
                book_metadata or {},
                lesson_id,  # Pass lesson_id
            )

            logger.info("‚úÖ Textbook processing completed successfully")

            # Extract images for separate storage
            images_data = self.extract_images_for_storage(processed_book)
            logger.info(f"üñºÔ∏è Extracted {len(images_data)} images for storage")

            # Upload images to Supabase if available
            if images_data:
                logger.info("üì§ Uploading images to Supabase...")
                uploaded_images = await docling_service.upload_images_to_supabase(
                    images=images_data,
                    book_id=book_metadata.get("id", "unknown")
                )

                # Update images_data with Supabase URLs
                images_data = uploaded_images

                # Update lesson_images in book structure with Supabase URLs
                self._update_lesson_images_with_supabase_urls(processed_book, uploaded_images)

                logger.info(f"‚úÖ Supabase upload completed for {len(images_data)} images")

            # Prepare clean structure for Qdrant
            clean_book_structure = self.prepare_structure_for_qdrant(processed_book)

            return {
                "success": True,
                "book": processed_book,  # Full structure with image data
                "clean_book_structure": clean_book_structure,  # Structure without image data for Qdrant
                "images_data": images_data,  # Separate image data for external storage
                "total_pages": len(pages_data),
                "total_chapters": len(processed_book.get("chapters", [])),
                "total_lessons": sum(
                    len(ch.get("lessons", []))
                    for ch in processed_book.get("chapters", [])
                ),
                "total_images": len(images_data),
                "message": "Textbook processed successfully with image extraction",
            }

        except Exception as e:
            logger.error(f"‚ùå Error processing textbook: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Failed to process textbook",
            }

    async def _extract_pages_with_docling(self, pdf_content: bytes, filename: str) -> List[Dict[str, Any]]:
        """Extract pages using Docling library for advanced PDF processing"""
        try:
            logger.info("üîß Using Docling for advanced PDF image extraction...")

            # Use Docling service to extract images and content
            docling_result = await docling_service.extract_images_from_pdf(pdf_content, filename)

            if not docling_result.get("success"):
                logger.warning("Docling extraction failed, falling back to PyMuPDF")
                return await self._extract_pages_with_ocr(pdf_content)

            # Convert Docling result to our expected format
            pages_data = []

            # Process page images from Docling
            for page_img in docling_result.get("page_images", []):
                page_num = page_img["page_number"]

                # Find or create page data
                page_data = None
                for p in pages_data:
                    if p["page_number"] == page_num:
                        page_data = p
                        break

                if not page_data:
                    page_data = {
                        "page_number": page_num,
                        "text": "",
                        "images": [],
                        "has_text": False,
                        "docling_processed": True
                    }
                    pages_data.append(page_data)

            # Add extracted figures/pictures from Docling
            for img in docling_result.get("images", []):
                page_num = img.get("page", 1)
                if page_num is None:
                    page_num = 1

                # Find page data
                page_data = None
                for p in pages_data:
                    if p["page_number"] == page_num:
                        page_data = p
                        break

                if not page_data:
                    page_data = {
                        "page_number": page_num,
                        "text": "",
                        "images": [],
                        "has_text": False,
                        "docling_processed": True
                    }
                    pages_data.append(page_data)

                # Add image with Docling metadata
                page_data["images"].append({
                    "index": img.get("index", 0),
                    "data": img.get("image_data", ""),
                    "format": img.get("format", "png"),
                    "page": page_num,
                    "description": img.get("caption", ""),
                    "type": img.get("type", "figure"),
                    "width": img.get("width", 0),
                    "height": img.get("height", 0),
                    "extraction_method": "docling"
                })

            # Add table images from Docling
            for table in docling_result.get("tables", []):
                page_num = table.get("page", 1)
                if page_num is None:
                    page_num = 1

                # Find page data
                page_data = None
                for p in pages_data:
                    if p["page_number"] == page_num:
                        page_data = p
                        break

                if not page_data:
                    page_data = {
                        "page_number": page_num,
                        "text": "",
                        "images": [],
                        "has_text": False,
                        "docling_processed": True
                    }
                    pages_data.append(page_data)

                # Add table as image
                page_data["images"].append({
                    "index": table.get("index", 0),
                    "data": table.get("image_data", ""),
                    "format": table.get("format", "png"),
                    "page": page_num,
                    "description": table.get("caption", ""),
                    "type": "table",
                    "width": table.get("width", 0),
                    "height": table.get("height", 0),
                    "extraction_method": "docling"
                })

            # Extract text content from Docling markdown
            text_content = docling_result.get("text_content", "")
            if text_content:
                # Split text by pages (this is approximate)
                text_lines = text_content.split('\n')
                current_page = 1
                current_text = ""

                for line in text_lines:
                    if line.strip().startswith('---') and 'page' in line.lower():
                        # Save previous page text
                        if current_text.strip():
                            for p in pages_data:
                                if p["page_number"] == current_page:
                                    p["text"] = current_text.strip()
                                    p["has_text"] = len(current_text.strip()) > 50
                                    break

                        # Start new page
                        current_page += 1
                        current_text = ""
                    else:
                        current_text += line + "\n"

                # Save last page
                if current_text.strip():
                    for p in pages_data:
                        if p["page_number"] == current_page:
                            p["text"] = current_text.strip()
                            p["has_text"] = len(current_text.strip()) > 50
                            break

            # Sort pages by page number
            pages_data.sort(key=lambda x: x["page_number"])

            logger.info(f"‚úÖ Docling extracted {len(pages_data)} pages with {sum(len(p['images']) for p in pages_data)} images")
            return pages_data

        except Exception as e:
            logger.error(f"Docling extraction failed: {e}")
            logger.info("Falling back to PyMuPDF extraction...")
            return await self._extract_pages_with_ocr(pdf_content)

    async def _extract_pages_with_ocr(self, pdf_content: bytes) -> List[Dict[str, Any]]:
        """Extract t·∫•t c·∫£ pages v·ªõi OCR n·∫øu c·∫ßn (PyMuPDF fallback)"""

        def extract_page_data():
            doc = fitz.open(stream=pdf_content, filetype="pdf")
            pages_data = []

            for page_num in range(doc.page_count):
                page = doc[page_num]

                # Extract text normally first
                text = page.get_text("text")  # type: ignore

                # Extract images
                images = []
                image_list = page.get_images()

                for img_index, img in enumerate(image_list):
                    try:
                        xref = img[0]
                        pix = fitz.Pixmap(doc, xref)

                        if pix.n - pix.alpha < 4:  # GRAY or RGB
                            img_data = pix.tobytes("png")
                            img_base64 = base64.b64encode(img_data).decode()

                            images.append(
                                {
                                    "index": img_index,
                                    "data": img_base64,
                                    "format": "png",
                                    "page": page_num + 1,
                                }
                            )

                        pix = None
                    except Exception as e:
                        logger.warning(
                            f"Error extracting image {img_index} from page {page_num}: {e}"
                        )

                pages_data.append(
                    {
                        "page_number": page_num + 1,
                        "text": text,
                        "images": images,
                        "has_text": len(text.strip()) > 50,
                    }
                )

            doc.close()
            return pages_data

        # Extract pages in background thread
        pages_data = await asyncio.get_event_loop().run_in_executor(
            self.executor, extract_page_data
        )

        # Apply OCR to pages with insufficient text
        ocr_tasks = []
        for page in pages_data:
            if not page["has_text"]:
                ocr_tasks.append(self._apply_ocr_to_page(page, pdf_content))

        if ocr_tasks:
            logger.info(
                f"üîç Applying OCR to {len(ocr_tasks)} pages with insufficient text"
            )
            ocr_results = await asyncio.gather(*ocr_tasks, return_exceptions=True)

            # Update pages with OCR results
            ocr_index = 0
            for page in pages_data:
                if not page["has_text"] and ocr_index < len(ocr_results):
                    if not isinstance(ocr_results[ocr_index], Exception):
                        page["text"] = ocr_results[ocr_index]
                        page["ocr_applied"] = True
                    ocr_index += 1

        return pages_data

    async def _apply_ocr_to_page(
        self, page_data: Dict[str, Any], pdf_content: bytes
    ) -> str:
        """Apply OCR to a specific page"""
        try:
            # Use existing OCR service for this page
            page_num = page_data["page_number"]

            # Extract just this page as bytes
            def extract_single_page():
                doc = fitz.open(stream=pdf_content, filetype="pdf")
                page = doc[page_num - 1]

                # Convert page to image
                mat = fitz.Matrix(2.0, 2.0)  # 2x zoom for better OCR
                pix = page.get_pixmap(matrix=mat)
                img_data = pix.tobytes("png")
                pix = None
                doc.close()

                return img_data

            img_data = await asyncio.get_event_loop().run_in_executor(
                self.executor, extract_single_page
            )

            # Apply OCR using PIL and simple_ocr_service logic
            image = Image.open(io.BytesIO(img_data))

            # Use simple OCR service's OCR logic
            if (
                hasattr(simple_ocr_service, "easyocr_reader")
                and simple_ocr_service.easyocr_reader
            ):
                import numpy as np

                results = simple_ocr_service.easyocr_reader.readtext(np.array(image))
                text_parts = []
                for result in results:
                    if isinstance(result, (list, tuple)) and len(result) >= 2:
                        # EasyOCR returns [bbox, text, confidence]
                        text_parts.append(str(result[1]))
                return " ".join(text_parts)
            else:
                # Fallback to Tesseract
                import pytesseract

                return pytesseract.image_to_string(
                    image, config=simple_ocr_service.tesseract_config
                )

        except Exception as e:
            logger.error(f"OCR failed for page {page_data['page_number']}: {e}")
            return ""

    async def _analyze_book_structure_enhanced(
        self,
        pages_data: List[Dict[str, Any]],
        book_metadata: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """Ph√¢n t√≠ch c·∫•u tr√∫c s√°ch v·ªõi LLM c·∫£i ti·∫øn"""

        if not llm_service.is_available():
            logger.warning("LLM not available, using pattern-based analysis")
            return await self._pattern_based_structure_analysis(
                pages_data, book_metadata
            )

        # T·∫°o text sample t·ª´ c√°c trang ƒë·ªÉ ph√¢n t√≠ch
        sample_text = ""
        for i, page in enumerate(pages_data[:20]):  # L·∫•y 20 trang ƒë·∫ßu ƒë·ªÉ ph√¢n t√≠ch
            if page["text"].strip():
                sample_text += f"\n--- Trang {page['page_number']} ---\n{page['text'][:500]}"  # 500 chars per page

        prompt = f"""
B·∫°n l√† chuy√™n gia ph√¢n t√≠ch s√°ch gi√°o khoa Vi·ªát Nam. Ph√¢n t√≠ch n·ªôi dung v√† tr·∫£ v·ªÅ c·∫•u tr√∫c ch√≠nh x√°c.

TH√îNG TIN S√ÅCH:
- T·ªïng s·ªë trang: {len(pages_data)}
- Metadata: {json.dumps(book_metadata or {}, ensure_ascii=False)}

N·ªòI DUNG SAMPLE:
{sample_text}

Y√äU C·∫¶U:
1. X√°c ƒë·ªãnh ti√™u ƒë·ªÅ s√°ch, m√¥n h·ªçc, l·ªõp
2. T√¨m t·∫•t c·∫£ CH∆Ø∆†NG (Chapter) trong s√°ch
3. T√¨m t·∫•t c·∫£ B√ÄI H·ªåC (Lesson) trong m·ªói ch∆∞∆°ng
4. X√°c ƒë·ªãnh trang b·∫Øt ƒë·∫ßu v√† k·∫øt th√∫c cho m·ªói ch∆∞∆°ng/b√†i
5. Tr·∫£ v·ªÅ JSON chu·∫©n

JSON FORMAT:
{{
  "book_info": {{
    "title": "T√™n s√°ch ch√≠nh x√°c",
    "subject": "M√¥n h·ªçc (To√°n/L√Ω/H√≥a/...)",
    "grade": "L·ªõp (10/11/12)",
    "total_pages": {len(pages_data)}
  }},
  "chapters": [
    {{
      "chapter_id": "chapter_01",
      "chapter_title": "T√™n ch∆∞∆°ng ch√≠nh x√°c",
      "start_page": 1,
      "end_page": 20,
      "lessons": [
        {{
          "lesson_id": "lesson_01_01",
          "lesson_title": "T√™n b√†i h·ªçc ch√≠nh x√°c",
          "start_page": 1,
          "end_page": 5
        }}
      ]
    }}
  ]
}}

Tr·∫£ v·ªÅ JSON:"""

        try:
            if not llm_service.model:
                raise Exception("LLM model not available")

            response = llm_service.model.generate_content(prompt)
            json_text = response.text.strip()

            # Clean JSON - c·∫£i thi·ªán vi·ªác x·ª≠ l√Ω
            if json_text.startswith("```json"):
                json_text = json_text[7:]
            if json_text.startswith("```"):
                json_text = json_text[3:]
            if json_text.endswith("```"):
                json_text = json_text[:-3]

            # T√¨m JSON h·ª£p l·ªá trong response
            json_text = json_text.strip()

            # T√¨m v·ªã tr√≠ b·∫Øt ƒë·∫ßu v√† k·∫øt th√∫c c·ªßa JSON
            start_idx = json_text.find("{")
            if start_idx == -1:
                raise ValueError("No JSON object found in response")

            # T√¨m v·ªã tr√≠ k·∫øt th√∫c JSON b·∫±ng c√°ch ƒë·∫øm d·∫•u ngo·∫∑c
            brace_count = 0
            end_idx = start_idx
            for i, char in enumerate(json_text[start_idx:], start_idx):
                if char == "{":
                    brace_count += 1
                elif char == "}":
                    brace_count -= 1
                    if brace_count == 0:
                        end_idx = i + 1
                        break

            # Extract JSON h·ª£p l·ªá
            clean_json = json_text[start_idx:end_idx]

            structure = json.loads(clean_json)

            # Validate structure
            if "chapters" in structure and len(structure["chapters"]) > 0:
                logger.info(f"LLM detected {len(structure['chapters'])} chapters")
                return structure
            else:
                logger.warning("LLM returned invalid structure, using fallback")
                return await self._pattern_based_structure_analysis(
                    pages_data, book_metadata
                )

        except Exception as e:
            logger.error(f"LLM structure analysis failed: {e}")
            logger.debug(
                f"Raw LLM response: {response.text[:500] if 'response' in locals() else 'No response'}"
            )
            return await self._pattern_based_structure_analysis(
                pages_data, book_metadata
            )

    async def _pattern_based_structure_analysis(
        self,
        pages_data: List[Dict[str, Any]],
        book_metadata: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """Ph√¢n t√≠ch c·∫•u tr√∫c d·ª±a tr√™n pattern matching"""

        total_pages = len(pages_data)

        # Extract book info from metadata or first pages
        book_info = {
            "title": book_metadata.get("title", "S√°ch gi√°o khoa")
            if book_metadata
            else "S√°ch gi√°o khoa",
            "subject": book_metadata.get("subject", "Ch∆∞a x√°c ƒë·ªãnh")
            if book_metadata
            else "Ch∆∞a x√°c ƒë·ªãnh",
            "grade": book_metadata.get("grade", "Ch∆∞a x√°c ƒë·ªãnh")
            if book_metadata
            else "Ch∆∞a x√°c ƒë·ªãnh",
            "total_pages": total_pages,
        }

        # Find chapters and lessons using pattern matching
        chapters = []
        current_chapter = None
        current_lesson = None

        for page in pages_data:
            lines = page["text"].split("\n")

            # Look for chapter patterns
            for line in lines:
                line_clean = line.strip()
                if len(line_clean) > 5 and len(line_clean) < 100:
                    # Chapter detection
                    if any(
                        pattern in line_clean.lower()
                        for pattern in ["ch∆∞∆°ng", "chapter", "ph·∫ßn", "b√†i t·∫≠p ch∆∞∆°ng"]
                    ):
                        # Save previous chapter
                        if current_chapter:
                            chapters.append(current_chapter)

                        # Start new chapter
                        chapter_num = len(chapters) + 1
                        current_chapter = {
                            "chapter_id": f"chapter_{chapter_num:02d}",
                            "chapter_title": line_clean,
                            "start_page": page["page_number"],
                            "end_page": page["page_number"],
                            "lessons": [],
                        }
                        current_lesson = None

                    # Lesson detection
                    elif (
                        any(
                            pattern in line_clean.lower()
                            for pattern in ["b√†i", "lesson", "ti·∫øt"]
                        )
                        and current_chapter
                    ):
                        # Save previous lesson
                        if current_lesson:
                            current_chapter["lessons"].append(current_lesson)

                        # Start new lesson
                        lesson_num = len(current_chapter["lessons"]) + 1
                        current_lesson = {
                            "lesson_id": f"lesson_{len(chapters)+1:02d}_{lesson_num:02d}",
                            "lesson_title": line_clean,
                            "start_page": page["page_number"],
                            "end_page": page["page_number"],
                        }

            # Update end pages
            if current_chapter:
                current_chapter["end_page"] = page["page_number"]
            if current_lesson:
                current_lesson["end_page"] = page["page_number"]

        # Add final chapter and lesson
        if current_lesson and current_chapter:
            current_chapter["lessons"].append(current_lesson)
        if current_chapter:
            chapters.append(current_chapter)

        # If no chapters found, create default structure
        if not chapters:
            chapters = self._create_default_structure(total_pages)

        return {"book_info": book_info, "chapters": chapters}

    def _create_default_structure(self, total_pages: int) -> List[Dict[str, Any]]:
        """T·∫°o c·∫•u tr√∫c m·∫∑c ƒë·ªãnh khi kh√¥ng detect ƒë∆∞·ª£c"""

        chapters = []
        pages_per_chapter = max(total_pages // 3, 10)  # √çt nh·∫•t 3 ch∆∞∆°ng

        for chapter_num in range(1, 4):  # 3 ch∆∞∆°ng
            start_page = (chapter_num - 1) * pages_per_chapter + 1
            end_page = min(chapter_num * pages_per_chapter, total_pages)

            if start_page > total_pages:
                break

            # T·∫°o 2-3 b√†i trong m·ªói ch∆∞∆°ng
            lessons = []
            pages_per_lesson = max((end_page - start_page + 1) // 3, 3)

            for lesson_num in range(1, 4):  # 3 b√†i m·ªói ch∆∞∆°ng
                lesson_start = start_page + (lesson_num - 1) * pages_per_lesson
                lesson_end = min(
                    start_page + lesson_num * pages_per_lesson - 1, end_page
                )

                if lesson_start > end_page:
                    break

                lessons.append(
                    {
                        "lesson_id": f"lesson_{chapter_num:02d}_{lesson_num:02d}",
                        "lesson_title": f"B√†i {lesson_num}",
                        "start_page": lesson_start,
                        "end_page": lesson_end,
                    }
                )

            chapters.append(
                {
                    "chapter_id": f"chapter_{chapter_num:02d}",
                    "chapter_title": f"Ch∆∞∆°ng {chapter_num}",
                    "start_page": start_page,
                    "end_page": end_page,
                    "lessons": lessons,
                }
            )

        return chapters

    async def _process_lessons_content(
        self,
        book_structure: Dict[str, Any],
        pages_data: List[Dict[str, Any]],
        external_lesson_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """X·ª≠ l√Ω n·ªôi dung chi ti·∫øt cho t·ª´ng b√†i h·ªçc"""

        processed_book = {
            "book_info": book_structure.get("book_info", {}),
            "chapters": [],
        }

        for chapter in book_structure.get("chapters", []):
            processed_chapter = {
                "chapter_id": chapter["chapter_id"],
                "chapter_title": chapter["chapter_title"],
                "start_page": chapter["start_page"],
                "end_page": chapter["end_page"],
                "lessons": [],
            }

            for lesson in chapter.get("lessons", []):
                logger.info(f"Processing lesson: {lesson['lesson_title']}")

                # Extract content for this lesson
                lesson_content = await self._extract_lesson_content(lesson, pages_data)

                processed_lesson = {
                    "lesson_id": lesson["lesson_id"],
                    "lesson_title": lesson["lesson_title"],
                    "start_page": lesson["start_page"],
                    "end_page": lesson["end_page"],
                    "content": lesson_content,
                }

                processed_chapter["lessons"].append(processed_lesson)

            processed_book["chapters"].append(processed_chapter)

        return processed_book

    async def _extract_lesson_content(
        self, lesson: Dict[str, Any], pages_data: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Extract n·ªôi dung chi ti·∫øt c·ªßa m·ªôt b√†i h·ªçc"""

        start_page = lesson["start_page"]
        end_page = lesson["end_page"]

        # Collect all text and images for this lesson
        lesson_text = ""
        lesson_images = []
        lesson_pages = []

        for page_num in range(start_page, end_page + 1):
            # Find page data (pages_data is 0-indexed but page_number is 1-indexed)
            page_data = None
            for page in pages_data:
                if page["page_number"] == page_num:
                    page_data = page
                    break

            if not page_data:
                continue

            lesson_pages.append(page_num)

            # Add text content
            if page_data["text"].strip():
                # Clean text with LLM if available
                cleaned_text = await self._clean_text_with_llm(page_data["text"])
                lesson_text += f"\n--- Trang {page_num} ---\n{cleaned_text}\n"

            # Add images with LLM descriptions only
            for img in page_data.get("images", []):
                # Describe image with LLM using base64 data
                img_description = await self._describe_image_with_llm(img["data"])

                lesson_images.append(
                    {
                        "page": page_num,
                        "index": img["index"],
                        "format": img["format"],
                        "description": img_description,
                        # Note: Removed base64 data to reduce response size
                    }
                )

        return {
            "text": lesson_text.strip(),
            "images": lesson_images,
            "pages": lesson_pages,
            "total_pages": len(lesson_pages),
            "has_images": len(lesson_images) > 0,
        }

    async def _clean_text_with_llm(self, raw_text: str) -> str:
        """Clean v√† format text b·∫±ng LLM"""

        if not llm_service.is_available() or not raw_text.strip():
            return raw_text.strip()

        try:
            prompt = f"""
B·∫°n l√† chuy√™n gia x·ª≠ l√Ω text t·ª´ s√°ch gi√°o khoa. H√£y l√†m s·∫°ch v√† format text sau:

Y√äU C·∫¶U:
1. S·ª≠a l·ªói OCR (k√Ω t·ª± nh·∫≠n d·∫°ng sai)
2. Lo·∫°i b·ªè k√Ω t·ª± l·∫°, kho·∫£ng tr·∫Øng th·ª´a
3. S·∫Øp x·∫øp ƒëo·∫°n vƒÉn cho d·ªÖ ƒë·ªçc
4. Gi·ªØ nguy√™n √Ω nghƒ©a v√† c·∫•u tr√∫c
5. Tr·∫£ v·ªÅ text ti·∫øng Vi·ªát chu·∫©n

Text g·ªëc:
{raw_text[:1000]}  # Limit to 1000 chars

Text ƒë√£ l√†m s·∫°ch:"""

            if not llm_service.model:
                return raw_text.strip()

            response = llm_service.model.generate_content(prompt)
            cleaned_text = response.text.strip()

            return cleaned_text if cleaned_text else raw_text.strip()

        except Exception as e:
            logger.error(f"Text cleaning failed: {e}")
            return raw_text.strip()

    async def _describe_image_with_llm(self, image_base64: str) -> str:
        """M√¥ t·∫£ h√¨nh ·∫£nh b·∫±ng LLM v·ªõi Gemini Vision API"""

        if not llm_service.is_available():
            return "H√¨nh ·∫£nh minh h·ªça trong s√°ch gi√°o khoa"

        try:
            if not llm_service.model:
                return "H√¨nh ·∫£nh minh h·ªça trong s√°ch gi√°o khoa"

            # S·ª≠ d·ª•ng Gemini ƒë·ªÉ m√¥ t·∫£ h√¨nh ·∫£nh
            prompt = """
B·∫°n l√† chuy√™n gia ph√¢n t√≠ch h√¨nh ·∫£nh trong s√°ch gi√°o khoa Vi·ªát Nam.
H√£y m√¥ t·∫£ h√¨nh ·∫£nh n√†y m·ªôt c√°ch chi ti·∫øt v√† h·ªØu √≠ch cho vi·ªác t·∫°o gi√°o √°n.

Y√äU C·∫¶U M√î T·∫¢:
1. X√°c ƒë·ªãnh lo·∫°i h√¨nh ·∫£nh: bi·ªÉu ƒë·ªì, c√¥ng th·ª©c, s∆° ƒë·ªì, h√¨nh minh h·ªça, b·∫£ng bi·ªÉu, th√≠ nghi·ªám
2. M√¥ t·∫£ n·ªôi dung ch√≠nh v√† c√°c y·∫øu t·ªë quan tr·ªçng
3. Gi·∫£i th√≠ch m·ª•c ƒë√≠ch gi√°o d·ª•c v√† c√°ch s·ª≠ d·ª•ng trong gi·∫£ng d·∫°y
4. ƒê·ªÅ xu·∫•t c√°ch gi·∫£i th√≠ch cho h·ªçc sinh
5. M√¥ t·∫£ ng·∫Øn g·ªçn, r√µ r√†ng b·∫±ng ti·∫øng Vi·ªát (t·ªëi ƒëa 200 t·ª´)

V√≠ d·ª• format mong mu·ªën:
"Bi·ªÉu ƒë·ªì chu tr√¨nh n∆∞·ªõc trong t·ª± nhi√™n, minh h·ªça qu√° tr√¨nh bay h∆°i, ng∆∞ng t·ª• v√† m∆∞a.
H√¨nh ·∫£nh n√†y gi√∫p h·ªçc sinh hi·ªÉu r√µ c√°c giai ƒëo·∫°n c·ªßa chu tr√¨nh n∆∞·ªõc v√† vai tr√≤ c·ªßa
m·∫∑t tr·ªùi trong qu√° tr√¨nh n√†y. C√≥ th·ªÉ s·ª≠ d·ª•ng ƒë·ªÉ gi·∫£i th√≠ch hi·ªán t∆∞·ª£ng th·ªùi ti·∫øt v√†
t·∫ßm quan tr·ªçng c·ªßa n∆∞·ªõc trong h·ªá sinh th√°i."

H√£y m√¥ t·∫£ h√¨nh ·∫£nh:"""

            # T·∫°o image part cho Gemini
            import base64
            from PIL import Image
            import io

            # Decode base64 ƒë·ªÉ ki·ªÉm tra v√† resize n·∫øu c·∫ßn
            img_data = base64.b64decode(image_base64)
            image = Image.open(io.BytesIO(img_data))

            # Resize n·∫øu ·∫£nh qu√° l·ªõn ƒë·ªÉ ti·∫øt ki·ªám API cost
            max_size = (800, 800)
            if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
                image.thumbnail(max_size, Image.Resampling.LANCZOS)

                # Convert back to base64
                buffer = io.BytesIO()
                image.save(buffer, format="PNG")
                img_data = buffer.getvalue()
                image_base64 = base64.b64encode(img_data).decode()

            # T·∫°o content v·ªõi image ƒë·ªÉ Gemini ph√¢n t√≠ch
            image_part = {
                "mime_type": "image/png",
                "data": base64.b64decode(image_base64),
            }

            response = llm_service.model.generate_content([prompt, image_part])
            description = response.text.strip()

            # Validate v√† clean description
            if description and len(description) > 10:
                # Gi·ªõi h·∫°n ƒë·ªô d√†i m√¥ t·∫£
                if len(description) > 500:
                    description = description[:500] + "..."
                return description
            else:
                return "H√¨nh ·∫£nh minh h·ªça trong s√°ch gi√°o khoa (kh√¥ng th·ªÉ t·∫°o m√¥ t·∫£ chi ti·∫øt)"

        except Exception as e:
            logger.error(f"Image description with LLM failed: {e}")

            # Ki·ªÉm tra lo·∫°i l·ªói ƒë·ªÉ x·ª≠ l√Ω ph√π h·ª£p
            error_msg = str(e).lower()
            if "not valid" in error_msg or "invalid" in error_msg:
                logger.warning("Image format may be incompatible with Gemini Vision API")
            elif "quota" in error_msg or "limit" in error_msg:
                logger.warning("API quota exceeded or rate limit hit")
            elif "api key" in error_msg or "authentication" in error_msg:
                logger.warning("API key issue detected")

            # Fallback descriptions based on context
            fallback_descriptions = [
                "Bi·ªÉu ƒë·ªì ho·∫∑c s∆° ƒë·ªì minh h·ªça kh√°i ni·ªám trong b√†i h·ªçc",
                "H√¨nh ·∫£nh th√≠ nghi·ªám ho·∫∑c th·ª±c h√†nh trong ph√≤ng lab",
                "C√¥ng th·ª©c to√°n h·ªçc ho·∫∑c ph∆∞∆°ng tr√¨nh h√≥a h·ªçc",
                "B·∫£ng bi·ªÉu th·ªëng k√™ ho·∫∑c d·ªØ li·ªáu khoa h·ªçc",
                "H√¨nh minh h·ªça c·∫•u tr√∫c ho·∫∑c quy tr√¨nh t·ª± nhi√™n",
                "S∆° ƒë·ªì t∆∞ duy ho·∫∑c b·∫£n ƒë·ªì kh√°i ni·ªám",
            ]
            import random

            return random.choice(fallback_descriptions)

    async def _add_image_descriptions(self, pages_data: List[Dict[str, Any]]) -> None:
        """Add LLM-generated descriptions for all images in pages_data"""

        if not llm_service.is_available():
            logger.warning("LLM not available for image descriptions")
            return

        image_tasks = []
        total_images = 0

        for page in pages_data:
            for img in page.get("images", []):
                total_images += 1

                # Check if image already has description from Docling
                existing_description = img.get("description", "").strip()
                extraction_method = img.get("extraction_method", "")

                if existing_description and extraction_method == "docling":
                    logger.debug(f"Image on page {page.get('page_number')} already has Docling description: {existing_description[:50]}...")
                    continue

                if img.get("data"):
                    image_tasks.append(self._describe_image_with_llm(img["data"]))
                else:
                    logger.debug(f"Image on page {page.get('page_number')} has no data")

        logger.info(f"üñºÔ∏è Found {total_images} total images, {len(image_tasks)} need LLM descriptions")

        if image_tasks:
            logger.info(f"üñºÔ∏è Generating descriptions for {len(image_tasks)} images...")
            descriptions = await asyncio.gather(*image_tasks, return_exceptions=True)

            # Apply descriptions back to images (only for those without existing descriptions)
            desc_index = 0
            success_count = 0
            fallback_count = 0
            docling_count = 0

            for page in pages_data:
                for img in page.get("images", []):
                    # Skip images that already have Docling descriptions
                    existing_description = img.get("description", "").strip()
                    extraction_method = img.get("extraction_method", "")

                    if existing_description and extraction_method == "docling":
                        img["description_method"] = "docling_generated"
                        docling_count += 1
                        continue

                    if img.get("data") and desc_index < len(descriptions):
                        if not isinstance(descriptions[desc_index], Exception):
                            img["description"] = descriptions[desc_index]
                            img["description_method"] = "llm_generated"
                            success_count += 1
                            logger.debug(f"‚úÖ Generated description: {descriptions[desc_index][:50]}...")
                        else:
                            img["description"] = (
                                "H√¨nh ·∫£nh minh h·ªça trong s√°ch gi√°o khoa"
                            )
                            img["description_method"] = "fallback"
                            fallback_count += 1
                            logger.warning(f"‚ùå Failed to describe image: {descriptions[desc_index]}")
                        desc_index += 1

            logger.info(f"üéØ Image description results: {docling_count} docling, {success_count} llm, {fallback_count} fallback, {total_images} total")

    async def _build_final_structure(
        self,
        analysis_result: Dict[str, Any],
        pages_data: List[Dict[str, Any]],
        book_metadata: Dict[str, Any],
        external_lesson_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """Build final book structure from analysis result with lessonID and improved image handling"""

        book_structure = {
            "title": analysis_result.get("book_info", {}).get(
                "title", book_metadata["title"]
            ),
            "subject": analysis_result.get("book_info", {}).get(
                "subject", book_metadata["subject"]
            ),
            "grade": analysis_result.get("book_info", {}).get(
                "grade", book_metadata["grade"]
            ),
            "chapters": [],
        }  # Process chapters and lessons
        lesson_counter = 0  # Track total lesson count for lesson_id variants
        for chapter_index, chapter in enumerate(analysis_result.get("chapters", [])):
            chapter_obj = {
                "chapter_id": f"chapter_{chapter_index:02d}",  # Add chapter_id
                "title": chapter.get("chapter_title", "Ch∆∞∆°ng kh√¥ng x√°c ƒë·ªãnh"),
                "lessons": [],
            }

            # Extract lessons
            for lesson in chapter.get("lessons", []):
                lesson_content = ""
                lesson_images = []
                start_page = lesson.get("start_page", 1)
                end_page = lesson.get("end_page", start_page)

                # Collect content and images from lesson pages
                for page in pages_data:
                    page_num = page.get("page_number", 0)
                    if start_page <= page_num <= end_page:
                        lesson_content += (
                            page.get("text", "") + "\n"
                        )  # Add images with enhanced metadata
                        for img in page.get("images", []):
                            image_info = {
                                "page": page_num,
                                "description": img.get(
                                    "description", "H√¨nh ·∫£nh minh h·ªça"
                                ),
                                "format": img.get("format", "png"),
                                "description_method": img.get(
                                    "description_method", "auto"
                                ),
                                "extraction_method": img.get(
                                    "extraction_method", "unknown"
                                ),  # Add extraction method
                                "type": img.get(
                                    "type", "unknown"
                                ),  # Add image type
                                "image_index": img.get(
                                    "index", 0
                                ),  # Original index in page
                                "base64_data": img.get(
                                    "data", ""
                                ),  # Store base64 for embedding if needed
                                "image_id": str(
                                    uuid.uuid4()
                                ),  # Unique ID for each image
                                "has_data": bool(
                                    img.get("data", "")
                                ),  # Flag to check if image data exists
                                "width": img.get("width", 0),  # Add width
                                "height": img.get("height", 0),  # Add height
                                # Supabase storage info
                                "image_url": img.get("image_url", ""),  # Supabase public URL
                                "filename": img.get("filename", ""),  # Supabase filename
                                "upload_status": img.get("upload_status", "pending"),  # Upload status
                                "storage_path": img.get("storage_path", ""),  # Supabase storage path
                            }
                            lesson_images.append(
                                image_info
                            )  # Generate lesson ID - use external_lesson_id if provided, otherwise create UUID
                if external_lesson_id:
                    if lesson_counter == 0:
                        lesson_id = external_lesson_id
                        logger.info(f"Using provided lesson_id: {lesson_id}")
                    else:
                        lesson_id = f"{external_lesson_id}_{lesson_counter}"
                        logger.info(f"Using variant lesson_id: {lesson_id}")
                else:
                    lesson_id = str(uuid.uuid4())
                    logger.debug(f"Generated new lesson_id: {lesson_id}")

                lesson_counter += 1  # Increment for next lesson

                lesson_obj = {
                    "lesson_id": lesson_id,  # Add unique lesson ID
                    "title": lesson.get("lesson_title", "B√†i h·ªçc kh√¥ng x√°c ƒë·ªãnh"),
                    "content": lesson_content.strip(),
                    "page_numbers": list(range(start_page, end_page + 1)),
                    "images": lesson_images,
                    "image_count": len(
                        lesson_images
                    ),  # Add image count for easy reference
                    "has_images": len(lesson_images) > 0,  # Boolean flag for filtering
                }
                chapter_obj["lessons"].append(lesson_obj)

            book_structure["chapters"].append(chapter_obj)

        return book_structure

    def extract_images_for_storage(
        self, book_structure: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Extract all images from book structure for separate storage

        Since Qdrant cannot store image data directly, this method extracts
        all images with their metadata for storage in a separate system.

        Returns:
            List of image objects with metadata and base64 data
        """
        images_data = []

        for chapter in book_structure.get("chapters", []):
            for lesson in chapter.get("lessons", []):
                lesson_id = lesson.get("lesson_id", "unknown")

                for image in lesson.get("images", []):
                    if image.get("has_data", False):
                        image_record = {
                            "image_id": image.get("image_id"),
                            "lesson_id": lesson_id,
                            "lesson_title": lesson.get("title", ""),
                            "chapter_title": chapter.get("title", ""),
                            "page": image.get("page"),
                            "description": image.get("description", ""),
                            "description_method": image.get("description_method", ""),
                            "extraction_method": image.get("extraction_method", "unknown"),
                            "type": image.get("type", "unknown"),
                            "format": image.get("format", "png"),
                            "image_index": image.get("image_index", 0),
                            "index": image.get("image_index", 0),  # For Docling compatibility
                            "base64_data": image.get("base64_data", ""),
                            "image_data": image.get("base64_data", ""),  # For Docling compatibility
                            "width": image.get("width", 0),
                            "height": image.get("height", 0),
                            "book_title": book_structure.get("title", ""),
                            "subject": book_structure.get("subject", ""),
                            "grade": book_structure.get("grade", ""),
                        }
                        images_data.append(image_record)

        return images_data

    def _update_lesson_images_with_supabase_urls(
        self,
        book_structure: Dict[str, Any],
        uploaded_images: List[Dict[str, Any]]
    ) -> None:
        """Update lesson_images in book structure with Supabase URLs"""

        # Create mapping from image_id to Supabase data
        supabase_mapping = {}
        for img in uploaded_images:
            image_id = img.get("image_id")
            if image_id:
                supabase_mapping[image_id] = {
                    "image_url": img.get("image_url", ""),
                    "filename": img.get("filename", ""),
                    "upload_status": img.get("upload_status", "pending"),
                    "storage_path": img.get("storage_path", ""),
                    "file_size": img.get("file_size", 0)
                }

        # Update lesson_images in book structure
        for chapter in book_structure.get("chapters", []):
            for lesson in chapter.get("lessons", []):
                for img in lesson.get("images", []):
                    image_id = img.get("image_id")
                    if image_id in supabase_mapping:
                        supabase_data = supabase_mapping[image_id]
                        img.update(supabase_data)
                        logger.debug(f"Updated lesson image {image_id} with Supabase URL: {supabase_data.get('image_url', '')[:50]}...")

    def prepare_structure_for_qdrant(
        self, book_structure: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Prepare book structure for Qdrant storage by removing image data

        This method creates a clean version of the book structure without
        base64 image data, suitable for Qdrant embedding.

        Returns:
            Clean book structure without image data
        """
        import copy

        clean_structure = copy.deepcopy(book_structure)

        for chapter in clean_structure.get("chapters", []):
            for lesson in chapter.get("lessons", []):
                for image in lesson.get("images", []):
                    # Remove base64 data to reduce size for Qdrant
                    image.pop("base64_data", None)

        return clean_structure


# Global instance
enhanced_textbook_service = EnhancedTextbookService()
