"""
Enhanced Textbook Service - C·∫£i ti·∫øn x·ª≠ l√Ω s√°ch gi√°o khoa v·ªõi OCR v√† LLM
Tr·∫£ v·ªÅ c·∫•u tr√∫c: S√°ch ‚Üí Ch∆∞∆°ng ‚Üí B√†i ‚Üí N·ªôi dung
"""

import logging
import asyncio
import json
import uuid
from typing import Dict, Any, List, Optional
from concurrent.futures import ThreadPoolExecutor
import fitz  # PyMuPDF
from PIL import Image
import io

from app.services.simple_ocr_service import simple_ocr_service

logger = logging.getLogger(__name__)


class EnhancedTextbookService:
    """Service c·∫£i ti·∫øn ƒë·ªÉ x·ª≠ l√Ω s√°ch gi√°o khoa v·ªõi OCR v√† LLM"""

    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=4)

    async def process_textbook_to_structure(
        self,
        pdf_content: bytes,
        filename: str,
        book_metadata: Optional[Dict[str, Any]] = None,
        lesson_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω PDF s√°ch gi√°o khoa v√† tr·∫£ v·ªÅ c·∫•u tr√∫c ho√†n ch·ªânh

        Args:
            pdf_content: N·ªôi dung PDF
            filename: T√™n file
            book_metadata: Metadata s√°ch (title, subject, grade, etc.)
            lesson_id: ID b√†i h·ªçc t√πy ch·ªçn ƒë·ªÉ li√™n k·∫øt v·ªõi lesson c·ª• th·ªÉ

        Returns:
            Dict v·ªõi c·∫•u tr√∫c: book -> chapters -> lessons -> content
        """
        try:
            logger.info(f"üöÄ Starting enhanced textbook processing: {filename}")

            # Step 1: Extract all pages with OCR
            logger.info("üìÑ Extracting pages with OCR...")
            pages_data = await self._extract_pages_with_ocr(pdf_content)
            logger.info(f"‚úÖ Extracted {len(pages_data)} pages")

            # Skip image analysis to improve speed
            logger.info("‚ö° Skipping image analysis for faster processing")

            # Step 3: Analyze book structure with LLM
            logger.info("üß† Analyzing book structure...")
            book_structure = await self._analyze_book_structure_enhanced(
                pages_data, book_metadata
            )
            logger.info(
                f"üìö Detected {len(book_structure.get('chapters', []))} chapters"
            )

            # Step 4: Build final structure with content and lesson IDs
            logger.info("üîÑ Building final lesson structure...")
            processed_book = await self._build_final_structure(
                book_structure,
                pages_data,
                book_metadata or {},
                lesson_id,  # Pass lesson_id
            )

            logger.info("‚úÖ Textbook processing completed successfully")

            # Skip image extraction for faster processing
            images_data = []
            logger.info("‚ö° Skipping image extraction for faster processing")

            # Refine content with OpenRouter LLM before saving to Qdrant
            logger.info("ü§ñ Refining content with OpenRouter LLM...")
            refined_book_structure = await self.refine_content_with_llm(processed_book)
            logger.info("‚úÖ Content refinement completed")

            # Prepare clean structure for Qdrant
            clean_book_structure = self.prepare_structure_for_qdrant(refined_book_structure)

            # T√≠nh to√°n th·ªëng k√™ ƒë∆°n gi·∫£n cho 1 b√†i h·ªçc
            total_lessons = sum(len(ch.get("lessons", [])) for ch in refined_book_structure.get("chapters", []))

            return {
                "success": True,
                "book": refined_book_structure,  # Full structure with refined content and image data
                "clean_book_structure": clean_book_structure,  # Structure without image data for Qdrant
                "images_data": images_data,  # Separate image data for external storage
                "total_pages": len(pages_data),
                "total_chapters": len(refined_book_structure.get("chapters", [])),
                "total_lessons": total_lessons,
                "total_images": len(images_data),
                "message": f"Textbook processed successfully with LLM content refinement ({total_lessons} lesson{'s' if total_lessons != 1 else ''})",
            }

        except Exception as e:
            logger.error(f"‚ùå Error processing textbook: {e}")
            return {
                "success": False,
                "error": str(e),
                "message": "Failed to process textbook",
            }

    async def _extract_pages_with_ocr(self, pdf_content: bytes) -> List[Dict[str, Any]]:
        """Extract t·∫•t c·∫£ pages v·ªõi OCR n·∫øu c·∫ßn"""

        def extract_page_data():
            doc = fitz.open(stream=pdf_content, filetype="pdf")
            pages_data = []

            for page_num in range(doc.page_count):
                page = doc[page_num]

                # Extract text normally first
                text = page.get_text("text")  # type: ignore

                # Skip image extraction for faster processing
                images = []

                pages_data.append(
                    {
                        "page_number": page_num + 1,
                        "text": text,
                        "images": images,
                        "has_text": len(text.strip()) > 50,
                    }
                )

            doc.close()
            return pages_data

        # Extract pages in background thread
        pages_data = await asyncio.get_event_loop().run_in_executor(
            self.executor, extract_page_data
        )

        # Apply OCR to pages with insufficient text
        ocr_tasks = []
        for page in pages_data:
            if not page["has_text"]:
                ocr_tasks.append(self._apply_ocr_to_page(page, pdf_content))

        if ocr_tasks:
            logger.info(
                f"üîç Applying OCR to {len(ocr_tasks)} pages with insufficient text"
            )
            ocr_results = await asyncio.gather(*ocr_tasks, return_exceptions=True)

            # Update pages with OCR results
            ocr_index = 0
            for page in pages_data:
                if not page["has_text"] and ocr_index < len(ocr_results):
                    if not isinstance(ocr_results[ocr_index], Exception):
                        page["text"] = ocr_results[ocr_index]
                        page["ocr_applied"] = True
                    ocr_index += 1

        return pages_data

    async def _apply_ocr_to_page(
        self, page_data: Dict[str, Any], pdf_content: bytes
    ) -> str:
        """Apply OCR to a specific page"""
        try:
            # Use existing OCR service for this page
            page_num = page_data["page_number"]

            # Extract just this page as bytes
            def extract_single_page():
                doc = fitz.open(stream=pdf_content, filetype="pdf")
                page = doc[page_num - 1]

                # Convert page to image
                mat = fitz.Matrix(2.0, 2.0)  # 2x zoom for better OCR
                pix = page.get_pixmap(matrix=mat)
                img_data = pix.tobytes("png")
                pix = None
                doc.close()

                return img_data

            img_data = await asyncio.get_event_loop().run_in_executor(
                self.executor, extract_single_page
            )

            # Apply OCR using PIL and simple_ocr_service logic
            image = Image.open(io.BytesIO(img_data))

            # Use simple OCR service's OCR logic
            if (
                hasattr(simple_ocr_service, "easyocr_reader")
                and simple_ocr_service.easyocr_reader
            ):
                import numpy as np

                results = simple_ocr_service.easyocr_reader.readtext(np.array(image))
                text_parts = []
                for result in results:
                    if isinstance(result, (list, tuple)) and len(result) >= 2:
                        # EasyOCR returns [bbox, text, confidence]
                        text_parts.append(str(result[1]))
                return " ".join(text_parts)
            else:
                # Fallback to Tesseract
                import pytesseract

                return pytesseract.image_to_string(
                    image, config=simple_ocr_service.tesseract_config
                )

        except Exception as e:
            logger.error(f"OCR failed for page {page_data['page_number']}: {e}")
            return ""

    async def _analyze_book_structure_enhanced(
        self,
        pages_data: List[Dict[str, Any]],
        book_metadata: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """T·∫°o c·∫•u tr√∫c ƒë∆°n gi·∫£n: 1 PDF = 1 b√†i h·ªçc"""

        logger.info("üìö Creating simple structure: 1 PDF = 1 lesson")

        # T·∫°o c·∫•u tr√∫c ƒë∆°n gi·∫£n c·ªë ƒë·ªãnh - kh√¥ng c·∫ßn LLM ph·ª©c t·∫°p
        total_pages = len(pages_data)

        # L·∫•y ti√™u ƒë·ªÅ t·ª´ metadata ho·∫∑c trang ƒë·∫ßu
        title = "B√†i h·ªçc"
        if book_metadata and book_metadata.get("title"):
            title = book_metadata["title"]
        else:
            # Th·ª≠ extract ti√™u ƒë·ªÅ t·ª´ trang ƒë·∫ßu
            if pages_data and pages_data[0]["text"].strip():
                first_lines = pages_data[0]["text"].strip().split('\n')[:5]
                for line in first_lines:
                    if len(line.strip()) > 5 and len(line.strip()) < 100:
                        title = line.strip()
                        break

        structure = {
            "book_info": {
                "title": title,
                "subject": book_metadata.get("subject", "Ch∆∞a x√°c ƒë·ªãnh") if book_metadata else "Ch∆∞a x√°c ƒë·ªãnh",
                "total_chapters": 1,
                "total_lessons": 1
            },
            "chapters": [
                {
                    "chapter_id": "chapter_01",
                    "chapter_title": "N·ªôi dung ch√≠nh",
                    "start_page": 1,
                    "end_page": total_pages,
                    "lessons": [
                        {
                            "lesson_id": "lesson_01",
                            "lesson_title": title,
                            "start_page": 1,
                            "end_page": total_pages
                        }
                    ]
                }
            ]
        }

        logger.info(f"‚úÖ Created simple structure: 1 chapter, 1 lesson, {total_pages} pages")
        return structure











    async def _build_final_structure(
        self,
        analysis_result: Dict[str, Any],
        pages_data: List[Dict[str, Any]],
        book_metadata: Dict[str, Any],
        external_lesson_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """T·∫°o c·∫•u tr√∫c ƒë∆°n gi·∫£n: 1 PDF = 1 b√†i h·ªçc"""

        logger.info("üèóÔ∏è Building simple structure: 1 PDF = 1 lesson")

        # T·∫≠p h·ª£p to√†n b·ªô n·ªôi dung t·ª´ t·∫•t c·∫£ c√°c trang
        full_content = ""
        all_page_numbers = []

        for page in pages_data:
            full_content += page.get("text", "") + "\n"
            all_page_numbers.append(page.get("page_number", 0))

        # T·∫°o lesson_id
        if external_lesson_id:
            lesson_id = external_lesson_id
            logger.info(f"Using provided lesson_id: {lesson_id}")
        else:
            lesson_id = str(uuid.uuid4())
            logger.info(f"Generated new lesson_id: {lesson_id}")

        # L·∫•y ti√™u ƒë·ªÅ t·ª´ analysis_result ho·∫∑c metadata
        lesson_title = analysis_result.get("book_info", {}).get("title", book_metadata.get("title", "B√†i h·ªçc"))

        # T·∫°o c·∫•u tr√∫c ƒë∆°n gi·∫£n
        book_structure = {
            "title": lesson_title,
            "subject": analysis_result.get("book_info", {}).get("subject", book_metadata.get("subject", "Ch∆∞a x√°c ƒë·ªãnh")),
            "grade": analysis_result.get("book_info", {}).get("grade", book_metadata.get("grade", "Ch∆∞a x√°c ƒë·ªãnh")),
            "chapters": [
                {
                    "chapter_id": "chapter_01",
                    "title": "N·ªôi dung ch√≠nh",
                    "lessons": [
                        {
                            "lesson_id": lesson_id,
                            "title": lesson_title,
                            "content": full_content.strip(),
                            "page_numbers": all_page_numbers,
                        }
                    ]
                }
            ]
        }

        logger.info(f"‚úÖ Created simple structure with lesson_id: {lesson_id}")
        return book_structure



    async def refine_content_with_llm(
        self, book_structure: Dict[str, Any]
    ) -> Dict[str, Any]:
        """G·ª≠i n·ªôi dung ƒë·∫øn OpenRouter LLM ƒë·ªÉ l·ªçc v√† ch·ªânh s·ª≠a n·ªôi dung b√†i gi·∫£ng

        T·ªëi ∆∞u cho vi·ªác x·ª≠ l√Ω 1 b√†i h·ªçc duy nh·∫•t trong m·ªói PDF
        """
        try:
            from app.services.openrouter_service import OpenRouterService

            openrouter_service = OpenRouterService()
            if not openrouter_service.available:
                logger.warning("OpenRouter service not available, skipping content refinement")
                return book_structure

            import copy
            refined_structure = copy.deepcopy(book_structure)

            logger.info("ü§ñ Starting content refinement with OpenRouter LLM...")

            # T√¨m b√†i h·ªçc ƒë·∫ßu ti√™n ƒë·ªÉ x·ª≠ l√Ω (v√¨ ch·ªâ c√≥ 1 b√†i/PDF)
            first_lesson = None
            for chapter in refined_structure.get("chapters", []):
                for lesson in chapter.get("lessons", []):
                    if lesson.get("content"):
                        first_lesson = lesson
                        break
                if first_lesson:
                    break

            if not first_lesson:
                logger.warning("No lesson content found to refine")
                return book_structure

            # T·∫≠p h·ª£p t·∫•t c·∫£ text content t·ª´ lesson
            all_text_content = []
            for content_item in first_lesson.get("content", []):
                if content_item.get("type") == "text" and content_item.get("text"):
                    all_text_content.append(content_item.get("text", ""))

            if not all_text_content:
                logger.warning("No text content found in lesson")
                return book_structure

            # Gh√©p n·ªôi dung l·∫°i
            combined_content = "\n\n".join(all_text_content)

            # T·∫°o prompt ƒë·ªÉ LLM l·ªçc n·ªôi dung
            prompt = f"""
B·∫°n l√† chuy√™n gia gi√°o d·ª•c, h√£y l·ªçc v√† ch·ªânh s·ª≠a n·ªôi dung b√†i gi·∫£ng sau ƒë·ªÉ ch·ªâ gi·ªØ l·∫°i nh·ªØng th√¥ng tin quan tr·ªçng v√† chi ti·∫øt c·ªßa b√†i gi·∫£ng.

Y√äU C·∫¶U:
1. Lo·∫°i b·ªè th√¥ng tin kh√¥ng li√™n quan ƒë·∫øn n·ªôi dung b√†i h·ªçc (header, footer, s·ªë trang, th√¥ng tin xu·∫•t b·∫£n, etc.)
2. Gi·ªØ l·∫°i to√†n b·ªô ki·∫øn th·ª©c ch√≠nh, kh√°i ni·ªám, ƒë·ªãnh nghƒ©a, c√¥ng th·ª©c, v√≠ d·ª•
3. Gi·ªØ l·∫°i c√°c b√†i t·∫≠p, c√¢u h·ªèi, ho·∫°t ƒë·ªông th·ª±c h√†nh
4. S·∫Øp x·∫øp n·ªôi dung theo logic r√µ r√†ng, d·ªÖ hi·ªÉu
5. ƒê·∫£m b·∫£o n·ªôi dung ƒë·∫ßy ƒë·ªß v√† ch√≠nh x√°c, kh√¥ng b·ªè s√≥t th√¥ng tin quan tr·ªçng
6. Tr·∫£ v·ªÅ n·ªôi dung ƒë√£ ƒë∆∞·ª£c ch·ªânh s·ª≠a b·∫±ng ti·∫øng Vi·ªát

TI√äU ƒê·ªÄ B√ÄI H·ªåC: {first_lesson.get("lesson_title", "Kh√¥ng c√≥ ti√™u ƒë·ªÅ")}

N·ªòI DUNG G·ªêC:
{combined_content[:3000]}  # Gi·ªõi h·∫°n 3000 k√Ω t·ª± ƒë·ªÉ tr√°nh v∆∞·ª£t qu√° token limit

H√£y tr·∫£ v·ªÅ n·ªôi dung ƒë√£ ƒë∆∞·ª£c l·ªçc v√† ch·ªânh s·ª≠a:
"""

            # G·ªçi OpenRouter API
            result = await openrouter_service.generate_content(
                prompt=prompt,
                temperature=0.1,
                max_tokens=2048
            )

            if result.get("success") and result.get("text"):
                refined_content = result.get("text", "").strip()

                # C·∫≠p nh·∫≠t n·ªôi dung ƒë√£ ƒë∆∞·ª£c ch·ªânh s·ª≠a
                first_lesson["content"] = [
                    {
                        "type": "text",
                        "text": refined_content,
                        "page": first_lesson["content"][0].get("page", 1) if first_lesson["content"] else 1,
                        "section": "refined_content",
                        "refined_by_llm": True
                    }
                ]

                logger.info(f"‚úÖ Refined content for lesson: {first_lesson.get('lesson_title', 'Unknown')}")
            else:
                logger.warning(f"‚ùå Failed to refine content for lesson: {first_lesson.get('lesson_title', 'Unknown')}")

            logger.info("üéØ Content refinement completed")
            return refined_structure

        except Exception as e:
            logger.error(f"Error in content refinement: {e}")
            # Tr·∫£ v·ªÅ c·∫•u tr√∫c g·ªëc n·∫øu c√≥ l·ªói
            return book_structure

    def prepare_structure_for_qdrant(
        self, book_structure: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Prepare book structure for Qdrant storage (no image processing needed)"""
        # Since we skip image processing, just return the structure as-is
        return book_structure


# Global instance
enhanced_textbook_service = EnhancedTextbookService()
