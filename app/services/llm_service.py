"""
LLM Service Ä‘á»ƒ cáº¥u trÃºc láº¡i text báº±ng Gemini API hoáº·c OpenRouter API
"""
import logging
import threading
from typing import Dict, Any, Optional
import google.generativeai as genai
from app.core.config import settings
from app.services.openrouter_service import get_openrouter_service

logger = logging.getLogger(__name__)

class LLMService:
    """
    Service sá»­ dá»¥ng Gemini API hoáº·c OpenRouter API Ä‘á»ƒ cáº¥u trÃºc láº¡i text
    """

    def __init__(self):
        """Initialize LLM service"""
        self.model = None
        self.openrouter_service = None
        self.use_openrouter = False
        # KhÃ´ng khá»Ÿi táº¡o ngay - sáº½ khá»Ÿi táº¡o khi láº§n Ä‘áº§u Ä‘Æ°á»£c sá»­ dá»¥ng
        self._service_initialized = False

    def _ensure_service_initialized(self):
        """Ensure LLM service is initialized"""
        if not self._service_initialized:
            logger.info("ðŸ”„ LLMService: First-time initialization triggered")
            self._init_llm_service()
            self._service_initialized = True
            logger.info("âœ… LLMService: Initialization completed")

    def _init_llm_service(self):
        """Initialize LLM service - prioritize OpenRouter, fallback to Gemini"""
        try:
            # Æ¯u tiÃªn sá»­ dá»¥ng OpenRouter náº¿u cÃ³ API key
            if settings.OPENROUTER_API_KEY:
                logger.info("ðŸ”§ LLMService: Setting up OpenRouter integration...")
                self.openrouter_service = get_openrouter_service()
                # Äáº£m báº£o service Ä‘Æ°á»£c khá»Ÿi táº¡o Ä‘áº§y Ä‘á»§
                self.openrouter_service._ensure_service_initialized()
                if self.openrouter_service.is_available():
                    self.use_openrouter = True
                    logger.info("âœ… LLMService: OpenRouter integration ready")
                    return
                else:
                    logger.warning("OpenRouter service not available, falling back to Gemini")

            # Fallback to Gemini API
            if settings.GEMINI_API_KEY:
                logger.info("Initializing Gemini API...")
                self._init_gemini()
            else:
                logger.warning("No API keys available. LLM features will be disabled.")

        except Exception as e:
            logger.error(f"Failed to initialize LLM service: {e}")
            self.model = None
            self.openrouter_service = None

    def _init_gemini(self):
        """Initialize Gemini API"""
        try:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            # Use the latest available model
            self.model = genai.GenerativeModel('models/gemini-1.5-flash-latest')
            logger.info("Gemini API initialized with gemini-1.5-flash-latest")

        except Exception as e:
            logger.error(f"Failed to initialize Gemini API: {e}")
            self.model = None
    
    async def format_cv_text(self, raw_text: str) -> Dict[str, Any]:
        """
        Cáº¥u trÃºc láº¡i text CV thÃ nh format Ä‘áº¹p

        Args:
            raw_text: Text thÃ´ tá»« PDF
            
        Returns:
            Dict chá»©a text Ä‘Ã£ Ä‘Æ°á»£c cáº¥u trÃºc láº¡i
        """
        self._ensure_service_initialized()
        try:
            if not self.is_available():
                return {
                    "success": False,
                    "error": "LLM service not available. Please set API keys.",
                    "formatted_text": raw_text
                }

            prompt = f"""
Báº¡n lÃ  má»™t chuyÃªn gia HR vÃ  CV formatting chuyÃªn nghiá»‡p. HÃ£y cáº¥u trÃºc láº¡i CV sau thÃ nh format CHUáº¨N QUá»C Táº¾, Ä‘áº¹p máº¯t vÃ  chuyÃªn nghiá»‡p vá»›i LAYOUT Äáº¸P.

YÃŠU Cáº¦U FORMAT CHUYÃŠN NGHIá»†P:

1. **HEADER LAYOUT Äáº¸P:**
   ```
   # TÃŠN Äáº¦Y Äá»¦
   ## Chá»©c danh chuyÃªn nghiá»‡p

   ðŸ“§ Email | ðŸ“± Phone | ðŸ”— LinkedIn | ðŸ’» GitHub
   ðŸ“ Location
   ```

2. **Cáº¤U TRÃšC CHUáº¨N:**
   - Professional Summary (2-3 cÃ¢u ngáº¯n gá»n, highlight value)
   - Core Skills (dáº¡ng grid 3-4 cá»™t, khÃ´ng quÃ¡ dÃ i 1 hÃ ng)
   - Professional Experience (format Ä‘áº¹p vá»›i icons)
   - Education (compact, highlight achievements)
   - Key Projects (3-4 dá»± Ã¡n top, format card-style)
   - Technical Skills (phÃ¢n loáº¡i rÃµ rÃ ng theo nhÃ³m)

3. **FORMATTING RULES Äáº¸P:**
   - Sá»­ dá»¥ng icons/emojis cho sections: ðŸ’¼ ðŸŽ“ ðŸš€ âš¡
   - Skills dáº¡ng grid: `Skill1` `Skill2` `Skill3` (3-4 per line)
   - Dates format: MM/YYYY - MM/YYYY
   - Bullet points vá»›i action verbs máº¡nh
   - Spacing Ä‘á»u Ä‘áº·n, khÃ´ng quÃ¡ dÃ i 1 hÃ ng
   - Contact info trÃªn nhiá»u dÃ²ng cho Ä‘áº¹p

4. **LAYOUT OPTIMIZATION:**
   - Header: TÃªn to, chá»©c danh nhá» hÆ¡n, contact info xuá»‘ng dÃ²ng
   - Skills: Chia thÃ nh 3-4 skills per line
   - Experience: Company | Position | Duration (xuá»‘ng dÃ²ng)
   - Projects: Title trÃªn, description vÃ  tech stack xuá»‘ng dÃ²ng
   - KhÃ´ng Ä‘á»ƒ text quÃ¡ dÃ i 1 hÃ ng

5. **PROFESSIONAL CONTENT:**
   - Quantify achievements vá»›i sá»‘ liá»‡u
   - Action verbs: Developed, Implemented, Led, Achieved
   - Focus vÃ o impact vÃ  results
   - Technical skills phÃ¢n nhÃ³m: Frontend | Backend | Database | Tools

Text CV cáº§n format:
{raw_text}

HÃ£y tráº£ vá» CV vá»›i LAYOUT Äáº¸P, khÃ´ng dÃ i 1 hÃ ng, format chuyÃªn nghiá»‡p:
"""

            result = await self._generate_content(prompt)

            if result["success"]:
                return {
                    "success": True,
                    "formatted_text": result["text"],
                    "original_length": len(raw_text),
                    "formatted_length": len(result["text"])
                }
            else:
                return {
                    "success": False,
                    "error": result["error"],
                    "formatted_text": raw_text
                }
            
        except Exception as e:
            logger.error(f"Error formatting CV text: {e}")
            return {
                "success": False,
                "error": str(e),
                "formatted_text": raw_text
            }
    
    async def format_document_text(self, raw_text: str, document_type: str = "general") -> Dict[str, Any]:
        """
        Cáº¥u trÃºc láº¡i text tÃ i liá»‡u thÃ nh format Ä‘áº¹p
        
        Args:
            raw_text: Text thÃ´ tá»« PDF
            document_type: Loáº¡i tÃ i liá»‡u (cv, report, letter, etc.)
            
        Returns:
            Dict chá»©a text Ä‘Ã£ Ä‘Æ°á»£c cáº¥u trÃºc láº¡i
        """
        self._ensure_service_initialized()
        try:
            if not self.is_available():
                return {
                    "success": False,
                    "error": "LLM service not available. Please set API keys.",
                    "formatted_text": raw_text
                }
            
            # TÃ¹y chá»‰nh prompt theo loáº¡i tÃ i liá»‡u
            if document_type.lower() == "cv":
                return await self.format_cv_text(raw_text)

            # Xá»­ lÃ½ exam questions
            if document_type.lower() == "exam_questions":
                return await self.generate_exam_questions(raw_text)

            # Náº¿u lÃ  general nhÆ°ng cÃ³ váº» nhÆ° CV, format nhÆ° CV
            if document_type.lower() == "general" and self._is_cv_content(raw_text):
                return await self.format_cv_text(raw_text)

            # Xá»­ lÃ½ trÆ°á»ng há»£p Ä‘áº·c biá»‡t khi text extraction tháº¥t báº¡i
            if raw_text.startswith("[PDF_EXTRACTION_FAILED]") or raw_text.startswith("[PDF_PROCESSING_INFO]"):
                prompt = f"""
Báº¡n lÃ  má»™t chuyÃªn gia há»— trá»£ xá»­ lÃ½ tÃ i liá»‡u. NgÆ°á»i dÃ¹ng Ä‘Ã£ gáº·p váº¥n Ä‘á» khi xá»­ lÃ½ file PDF.

ThÃ´ng tin lá»—i:
{raw_text}

HÃ£y táº¡o má»™t thÃ´ng bÃ¡o há»¯u Ã­ch vÃ  chuyÃªn nghiá»‡p báº±ng tiáº¿ng Viá»‡t Ä‘á»ƒ:
1. Giáº£i thÃ­ch váº¥n Ä‘á» Ä‘Ã£ xáº£y ra
2. ÄÆ°a ra cÃ¡c giáº£i phÃ¡p kháº£ thi
3. HÆ°á»›ng dáº«n cÃ¡ch kháº¯c phá»¥c
4. Sá»­ dá»¥ng markdown formatting Ä‘á»ƒ dá»… Ä‘á»c

Tráº£ vá» thÃ´ng bÃ¡o há»— trá»£:
"""
            else:
                prompt = f"""
Báº¡n lÃ  má»™t chuyÃªn gia vá» formatting vÃ  editing tÃ i liá»‡u. HÃ£y cáº¥u trÃºc láº¡i tÃ i liá»‡u sau thÃ nh format Ä‘áº¹p, dá»… Ä‘á»c vÃ  chuyÃªn nghiá»‡p.

YÃªu cáº§u:
1. Sáº¯p xáº¿p thÃ´ng tin theo thá»© tá»± logic
2. Äá»‹nh dáº¡ng rÃµ rÃ ng vá»›i tiÃªu Ä‘á» vÃ  cáº¥u trÃºc phÃ¢n cáº¥p
3. Sá»­a lá»—i chÃ­nh táº£ vÃ  ngá»¯ phÃ¡p
4. Giá»¯ nguyÃªn táº¥t cáº£ thÃ´ng tin quan trá»ng
5. Sá»­ dá»¥ng markdown formatting
6. Loáº¡i bá» cÃ¡c kÃ½ tá»± láº¡ vÃ  format lá»—i

Loáº¡i tÃ i liá»‡u: {document_type}

Text cáº§n format:
{raw_text}

HÃ£y tráº£ vá» tÃ i liá»‡u Ä‘Ã£ Ä‘Æ°á»£c format Ä‘áº¹p:
"""

            result = await self._generate_content(prompt)

            if result["success"]:
                return {
                    "success": True,
                    "formatted_text": result["text"],
                    "original_length": len(raw_text),
                    "formatted_length": len(result["text"]),
                    "document_type": document_type
                }
            else:
                return {
                    "success": False,
                    "error": result["error"],
                    "formatted_text": raw_text
                }
            
        except Exception as e:
            logger.error(f"Error formatting document text: {e}")
            return {
                "success": False,
                "error": str(e),
                "formatted_text": raw_text
            }
    
    def _is_cv_content(self, text: str) -> bool:
        """Check if text content looks like a CV/Resume"""
        cv_keywords = [
            'curriculum vitae', 'cv', 'resume', 'experience', 'education', 'skills',
            'objective', 'work experience', 'employment', 'projects', 'achievements',
            'qualifications', 'developer', 'engineer', 'manager', 'analyst',
            'university', 'college', 'degree', 'gpa', 'graduation',
            'github', 'linkedin', 'portfolio', 'email', 'phone',
            'kinh nghiem', 'hoc van', 'ky nang', 'du an', 'thanh tich',
            'bang cap', 'tot nghiep', 'cong ty', 'lam viec'
        ]

        text_lower = text.lower()
        keyword_count = sum(1 for keyword in cv_keywords if keyword in text_lower)

        # If more than 3 CV-related keywords found, likely a CV
        return keyword_count >= 3

    def is_available(self) -> bool:
        """Check if LLM service is available"""
        self._ensure_service_initialized()
        if self.use_openrouter:
            return self.openrouter_service is not None and self.openrouter_service.is_available()
        return self.model is not None

    async def generate_content(self, prompt: str, temperature: float = 0.1, max_tokens: int = 4096) -> Dict[str, Any]:
        """
        Public method Ä‘á»ƒ gá»i LLM vá»›i cÃ¡c tham sá»‘ tÃ¹y chá»‰nh

        Args:
            prompt: Text prompt Ä‘á»ƒ gá»­i tá»›i model
            temperature: Temperature cho response (0.0 - 1.0)
            max_tokens: Sá»‘ token tá»‘i Ä‘a cho response

        Returns:
            Dict chá»©a response tá»« LLM
        """
        self._ensure_service_initialized()
        try:
            if self.use_openrouter and self.openrouter_service:
                # Sá»­ dá»¥ng OpenRouter vá»›i tham sá»‘ tÃ¹y chá»‰nh
                result = await self.openrouter_service.generate_content(
                    prompt=prompt,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
                return result

            elif self.model:
                # Sá»­ dá»¥ng Gemini - Gemini khÃ´ng há»— trá»£ temperature vÃ  max_tokens nhÆ° OpenRouter
                response = self.model.generate_content(prompt)
                if response and response.text:
                    return {
                        "success": True,
                        "text": response.text,
                        "error": None
                    }
                else:
                    return {
                        "success": False,
                        "text": "",
                        "error": "No response from Gemini API"
                    }
            else:
                return {
                    "success": False,
                    "text": "",
                    "error": "No LLM service available"
                }

        except Exception as e:
            logger.error(f"Error in generate_content: {e}")
            return {
                "success": False,
                "text": "",
                "error": str(e)
            }

    async def _generate_content(self, prompt: str) -> Dict[str, Any]:
        """
        Helper method Ä‘á»ƒ gá»i LLM (OpenRouter hoáº·c Gemini)

        Args:
            prompt: Text prompt Ä‘á»ƒ gá»­i tá»›i model

        Returns:
            Dict chá»©a response tá»« LLM
        """
        try:
            if self.use_openrouter and self.openrouter_service:
                # Sá»­ dá»¥ng OpenRouter
                result = await self.openrouter_service.generate_content(prompt)
                if result["success"]:
                    return {
                        "success": True,
                        "text": result["text"],
                        "error": None
                    }
                else:
                    return {
                        "success": False,
                        "text": "",
                        "error": result["error"]
                    }

            elif self.model:
                # Sá»­ dá»¥ng Gemini
                response = self.model.generate_content(prompt)
                if response and response.text:
                    return {
                        "success": True,
                        "text": response.text,
                        "error": None
                    }
                else:
                    return {
                        "success": False,
                        "text": "",
                        "error": "No response from Gemini API"
                    }
            else:
                return {
                    "success": False,
                    "text": "",
                    "error": "No LLM service available"
                }

        except Exception as e:
            logger.error(f"Error in _generate_content: {e}")
            return {
                "success": False,
                "text": "",
                "error": str(e)
            }

    async def generate_exam_questions(self, prompt: str) -> Dict[str, Any]:
        """
        Táº¡o cÃ¢u há»i thi tráº¯c nghiá»‡m báº±ng LLM API

        Args:
            prompt: Prompt Ä‘á»ƒ táº¡o cÃ¢u há»i

        Returns:
            Dict chá»©a response tá»« LLM
        """
        self._ensure_service_initialized()
        try:
            if not self.is_available():
                return {
                    "success": False,
                    "error": "LLM service not available. Please set API keys.",
                    "formatted_text": ""
                }

            # Gá»i LLM API Ä‘á»ƒ táº¡o cÃ¢u há»i
            result = await self._generate_content(prompt)

            if result["success"]:
                return {
                    "success": True,
                    "formatted_text": result["text"],
                    "error": None
                }
            else:
                return {
                    "success": False,
                    "error": result["error"],
                    "formatted_text": ""
                }

        except Exception as e:
            logger.error(f"Error generating exam questions: {e}")
            return {
                "success": False,
                "error": str(e),
                "formatted_text": ""
            }

# Factory function Ä‘á»ƒ táº¡o LLMService instance
def get_llm_service() -> LLMService:
    """
    Táº¡o LLMService instance má»›i

    Returns:
        LLMService: Fresh instance
    """
    return LLMService()
