"""
RAG (Retrieval-Augmented Generation) Service
X·ª≠ l√Ω logic RAG: semantic search + LLM generation
"""

import logging
import time
from typing import Dict, Any, Optional, List
from app.services.enhanced_textbook_service import get_enhanced_textbook_service

logger = logging.getLogger(__name__)

class RAGService:
    """Service x·ª≠ l√Ω RAG workflow"""
    
    def __init__(self):
        self.textbook_service = get_enhanced_textbook_service()
    
    async def process_rag_query(
        self,
        query: str,
        book_id: Optional[str] = None,
        lesson_id: Optional[str] = None,
        limit: int = 5,
        semantic_tags: Optional[str] = None,
        temperature: float = 0.3,
        max_tokens: int = 2000
    ) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω RAG query ho√†n ch·ªânh v·ªõi semantic search

        Args:
            query: C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
            book_id: ID s√°ch c·ª• th·ªÉ (t√πy ch·ªçn)
            lesson_id: ID b√†i h·ªçc c·ª• th·ªÉ (t√πy ch·ªçn)
            limit: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ t√¨m ki·∫øm t·ªëi ƒëa
            semantic_tags: L·ªçc theo semantic tags (ph√¢n c√°ch b·∫±ng d·∫•u ph·∫©y)
            temperature: Temperature cho LLM response
            max_tokens: S·ªë token t·ªëi ƒëa cho response

        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ RAG v·ªõi answer, sources v√† metadata
        """
        start_time = time.time()

        try:
            logger.info(f"üîç Processing RAG query: {query[:100]}...")

            # B∆∞·ªõc 1: Semantic Search
            search_result = await self._perform_semantic_search(
                query=query,
                book_id=book_id,
                lesson_id=lesson_id,
                limit=limit,
                semantic_tags=semantic_tags
            )

            if not search_result.get("success"):
                return {
                    "success": False,
                    "error": f"Search failed: {search_result.get('error')}",
                    "query": query
                }

            search_results = search_result.get("results", [])
            if not search_results:
                return {
                    "success": True,
                    "query": query,
                    "answer": "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi c·ªßa b·∫°n trong t√†i li·ªáu.",
                    "sources": [],
                    "context_used": "",
                    "total_sources": 0,
                    "processing_time": time.time() - start_time
                }

            # B∆∞·ªõc 2: T·∫°o context t·ª´ search results
            context, sources = self._build_context_and_sources(search_results, book_id)

            # B∆∞·ªõc 3: Generate answer v·ªõi LLM
            answer = await self._generate_answer_with_llm(
                query=query,
                context=context,
                temperature=temperature,
                max_tokens=max_tokens
            )

            processing_time = time.time() - start_time

            return {
                "success": True,
                "query": query,
                "answer": answer,
                "sources": sources,
                "context_used": context,
                "total_sources": len(sources),
                "processing_time": processing_time
            }

        except Exception as e:
            logger.error(f"‚ùå Error in RAG processing: {e}")
            return {
                "success": False,
                "error": str(e),
                "query": query,
                "processing_time": time.time() - start_time
            }

    async def _perform_semantic_search(
        self,
        query: str,
        book_id: Optional[str],
        lesson_id: Optional[str],
        limit: int,
        semantic_tags: Optional[str]
    ) -> Dict[str, Any]:
        """Th·ª±c hi·ªán semantic search"""
        from app.services.qdrant_service import get_qdrant_service
        qdrant_service = get_qdrant_service()
            
        # ƒê·∫£m b·∫£o service ƒë∆∞·ª£c kh·ªüi t·∫°o ƒë·∫ßy ƒë·ªß tr∆∞·ªõc khi ki·ªÉm tra
        qdrant_service._ensure_service_initialized()
        search_params = {
            "query": query,
            "limit": limit
        }
        
        # Th√™m filters n·∫øu c√≥
        semantic_filters = {}
        if semantic_tags:
            semantic_filters["semantic_tags"] = semantic_tags.split(",")
        
        # Th√™m lesson_id filter n·∫øu c√≥
        if lesson_id:
            semantic_filters["lesson_id"] = lesson_id
        
        if semantic_filters:
            search_params["semantic_filters"] = semantic_filters
        
        # T√¨m ki·∫øm trong book c·ª• th·ªÉ ho·∫∑c to√†n b·ªô
        if book_id:
            return await qdrant_service.search_textbook(book_id, **search_params)
        else:
            # Global search across all books
            return await qdrant_service.global_search(**search_params)
    
    def _build_context_and_sources(self, search_results: List[Dict], book_id: Optional[str]) -> tuple:
        """T·∫°o context v√† sources t·ª´ search results"""
        context_parts = []
        sources = []
        
        for i, result in enumerate(search_results, 1):
            context_parts.append(f"[Ngu·ªìn {i}] {result.get('text', '')}")
            sources.append({
                "source_id": i,
                "text": result.get('text', '')[:200] + "..." if len(result.get('text', '')) > 200 else result.get('text', ''),
                "score": result.get('score', 0),
                "lesson_id": result.get('lesson_id', ''),
                "semantic_tags": result.get('semantic_tags', []),
                "book_id": result.get('book_id', book_id)
            })
        
        context = "\n\n".join(context_parts)
        return context, sources
    
    def _build_rag_prompt(self, context: str, query: str) -> str:
        """T·∫°o prompt cho LLM ƒë·ªÉ tr·∫£ v·ªÅ n·ªôi dung HTML thu·∫ßn t√∫y"""
        return f"""B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n v·ªÅ gi√°o d·ª•c. H√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p.

NGUY√äN T·∫ÆC:
- Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin t·ª´ c√°c ngu·ªìn ƒë∆∞·ª£c cung c·∫•p
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, r√µ r√†ng v√† d·ªÖ hi·ªÉu
- Tr·∫£ v·ªÅ n·ªôi dung HTML v·ªõi style inline, KH√îNG c·∫ßn th·∫ª div bao b·ªçc b√™n ngo√†i
- S·ª≠ d·ª•ng c√°c th·∫ª HTML ph√π h·ª£p: <h3>, <p>, <ul>, <li>, <strong>, <em>
- Kh√¥ng s·ª≠ d·ª•ng k√Ω t·ª± ƒë·∫∑c bi·ªát, ch·ªâ HTML thu·∫ßn
- Ch·ªâ hi·ªán th·ªã tr√™n c√πng 1 d√≤ng v√† kh√¥ng c√≥ b·∫•t k√¨ kho·∫£ng c√°ch n√†o
- N·∫øu th√¥ng tin kh√¥ng ƒë·ªß ƒë·ªÉ tr·∫£ l·ªùi, h√£y n√≥i r√µ

FORMAT TR·∫¢ L·ªúI (ch·ªâ n·ªôi dung HTML thu·∫ßn):
<div style="padding: 15px; margin-bottom: 2px;line-height: 1.6; color: #333;">
    [N·ªôi dung tr·∫£ l·ªùi ·ªü ƒë√¢y v·ªõi c√°c th·∫ª HTML ph√π h·ª£p nh∆∞ <p>, <strong>, <em>]
</div>

<h4 style="color: #2c5aa0; margin-bottom: 2px; font-size: 16px;">Ngu·ªìn tham kh·∫£o:</h4>
<ul style="list-style-type: none; padding: 0;">
    [Danh s√°ch ngu·ªìn n·∫øu c·∫ßn tr√≠ch d·∫´n v·ªõi <li> c√≥ style]
</ul>

TH√îNG TIN T·ª™ T√ÄI LI·ªÜU:
{context}

C√ÇU H·ªéI: {query}

TR·∫¢ L·ªúI:"""

    async def _generate_answer_with_llm(
        self,
        query: str,
        context: str,
        temperature: float = 0.3,
        max_tokens: int = 2000
    ) -> str:
        """Generate answer using LLM v·ªõi context ƒë√£ ƒë∆∞·ª£c chu·∫©n b·ªã"""
        try:
            # L·∫•y LLM service
            from app.services.openrouter_service import get_openrouter_service
            llm_service = get_openrouter_service()

            # ƒê·∫£m b·∫£o service ƒë∆∞·ª£c kh·ªüi t·∫°o
            llm_service._ensure_service_initialized()

            if not llm_service.available:
                return "Xin l·ªói, d·ªãch v·ª• AI hi·ªán kh√¥ng kh·∫£ d·ª•ng. Vui l√≤ng th·ª≠ l·∫°i sau."

            # T·∫°o prompt
            prompt = self._build_rag_prompt(context, query)

            # G·ªçi LLM
            llm_result = await llm_service.generate_content(
                prompt=prompt,
                temperature=temperature,
                max_tokens=max_tokens
            )

            if not llm_result.get("success"):
                logger.error(f"LLM generation failed: {llm_result.get('error')}")
                return "Xin l·ªói, c√≥ l·ªói x·∫£y ra khi t·∫°o c√¢u tr·∫£ l·ªùi. Vui l√≤ng th·ª≠ l·∫°i."

            # L√†m s·∫°ch HTML response
            html_answer = llm_result.get("text", "")
            html_answer = self._clean_html_response(html_answer)

            return html_answer

        except Exception as e:
            logger.error(f"Error generating answer with LLM: {e}")
            return "Xin l·ªói, c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω c√¢u h·ªèi c·ªßa b·∫°n."

    def _clean_html_response(self, html_text: str) -> str:
        """L√†m s·∫°ch HTML response t·ª´ LLM"""
        if not html_text:
            return "Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi."

        # L√†m s·∫°ch escape characters v√† k√Ω t·ª± ƒë·∫∑c bi·ªát
        cleaned = (html_text
                  .replace('\\n', '')
                  .replace('\\r', '')
                  .replace('\\t', '')
                  .replace('\\"', '"')
                  .replace('\\', '')
                  .replace('\n', '')
                  .replace('\r', '')
                  .replace('\t', '')
                  .replace('  ', ' ')
                  .strip())

        return cleaned

    def _build_filters_info(self, semantic_tags: Optional[str], lesson_id: Optional[str], book_id: Optional[str]) -> Dict[str, Any]:
        """T·∫°o th√¥ng tin filters ƒë√£ √°p d·ª•ng"""
        return {
            "semantic_tags": semantic_tags.split(",") if semantic_tags else None,
            "lesson_id": lesson_id,
            "book_id": book_id
        }

    async def search_with_semantic_filters(
        self,
        query: str,
        book_id: Optional[str] = None,
        semantic_tags: Optional[str] = None,
        difficulty: Optional[str] = None,
        has_examples: Optional[bool] = None,
        has_formulas: Optional[bool] = None,
        min_confidence: float = 0.0,
        limit: int = 10
    ) -> Dict[str, Any]:
        """
        T√¨m ki·∫øm v·ªõi semantic filters n√¢ng cao

        Args:
            query: C√¢u truy v·∫•n t√¨m ki·∫øm
            book_id: ID s√°ch c·ª• th·ªÉ (optional)
            semantic_tags: Danh s√°ch semantic tags ƒë·ªÉ filter
            difficulty: M·ª©c ƒë·ªô kh√≥
            has_examples: C√≥ v√≠ d·ª• hay kh√¥ng
            has_formulas: C√≥ c√¥ng th·ª©c hay kh√¥ng
            min_confidence: Confidence t·ªëi thi·ªÉu
            limit: S·ªë l∆∞·ª£ng k·∫øt qu·∫£

        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ t√¨m ki·∫øm v·ªõi semantic metadata
        """
        try:
            from app.services.qdrant_service import qdrant_service

            logger.info(f"Semantic search: query='{query}', book_id={book_id}, semantic_tags={semantic_tags}")

            # Chu·∫©n b·ªã semantic filters
            semantic_filters = {}

            if semantic_tags:
                tag_list = [tag.strip() for tag in semantic_tags.split(",") if tag.strip()]
                if tag_list:
                    semantic_filters["semantic_tags"] = tag_list

            if difficulty:
                semantic_filters["difficulty"] = difficulty

            if has_examples is not None:
                semantic_filters["has_examples"] = has_examples

            if has_formulas is not None:
                semantic_filters["has_formulas"] = has_formulas

            # Th·ª±c hi·ªán t√¨m ki·∫øm
            if book_id:
                # T√¨m ki·∫øm trong s√°ch c·ª• th·ªÉ
                result = await qdrant_service.search_textbook(
                    book_id=book_id,
                    query=query,
                    limit=limit,
                    semantic_filters=semantic_filters if semantic_filters else None
                )
            else:
                # T√¨m ki·∫øm global (t·∫•t c·∫£ s√°ch)
                result = await self._global_semantic_search(
                    query=query,
                    semantic_filters=semantic_filters,
                    min_confidence=min_confidence,
                    limit=limit
                )

            return result

        except Exception as e:
            logger.error(f"Error in semantic search: {e}")
            return {
                "success": False,
                "error": f"Semantic search failed: {str(e)}"
            }

    async def _global_semantic_search(
        self,
        query: str,
        semantic_filters: Dict[str, Any],
        min_confidence: float,
        limit: int
    ) -> Dict[str, Any]:
        """Th·ª±c hi·ªán global semantic search s·ª≠ d·ª•ng unified collection"""
        from app.services.qdrant_service import get_qdrant_service

        qdrant_service = get_qdrant_service()

        if not qdrant_service.qdrant_client:
            return {
                "success": False,
                "error": "Qdrant service not available"
            }

        # S·ª≠ d·ª•ng global_search t·ª´ unified collection
        result = await qdrant_service.global_search(
            query=query,
            limit=limit,
            book_id=semantic_filters.get("book_id") if semantic_filters else None,
            lesson_id=semantic_filters.get("lesson_id") if semantic_filters else None
        )

        if not result.get("success"):
            return result

        # Filter by confidence if specified
        if min_confidence > 0.0:
            filtered_results = []
            for res in result.get("results", []):
                semantic_tags_data = res.get("semantic_tags", [])
                max_confidence = max([tag.get("confidence", 0.0) for tag in semantic_tags_data], default=0.0)
                if max_confidence >= min_confidence:
                    filtered_results.append(res)

            result["results"] = filtered_results
            result["total_results_found"] = len(filtered_results)
            result["message"] = f"Found {len(filtered_results)} results with confidence >= {min_confidence}"

        return result



# Factory function
def get_rag_service() -> RAGService:
    """
    Factory function ƒë·ªÉ t·∫°o RAGService instance

    Returns:
        RAGService: Instance c·ªßa RAG service
    """
    return RAGService()
