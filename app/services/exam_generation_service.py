"""
Service ƒë·ªÉ t·∫°o c√¢u h·ªèi thi s·ª≠ d·ª•ng Gemini LLM
"""

import asyncio
import logging
import json
import re
from typing import Dict, List, Any, Optional, cast
from datetime import datetime
from app.services.llm_service import get_llm_service
from app.core.logging_config import safe_log_text
from app.models.exam_models import (
    ExamMatrixRequest,
    MucDoModel,
    CauHinhDeModel,
)
from datetime import datetime

logger = logging.getLogger(__name__)


class ExamGenerationService:
    """Service ƒë·ªÉ t·∫°o c√¢u h·ªèi thi t·ª´ ma tr·∫≠n ƒë·ªÅ thi"""

    def __init__(self):
        self.llm_service = get_llm_service()
        logger.info("üîÑ ExamGenerationService: First-time initialization triggered")

    async def generate_questions_from_matrix(
        self, exam_request: ExamMatrixRequest, lesson_content: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        T·∫°o c√¢u h·ªèi t·ª´ ma tr·∫≠n ƒë·ªÅ thi v√† n·ªôi dung b√†i h·ªçc

        Args:
            exam_request: Ma tr·∫≠n ƒë·ªÅ thi
            lesson_content: N·ªôi dung b√†i h·ªçc t·ª´ Qdrant

        Returns:
            Dict ch·ª©a danh s√°ch c√¢u h·ªèi ƒë√£ t·∫°o
        """
        try:
            # Debug logging
            logger.info(f"=== EXAM GENERATION DEBUG ===")
            logger.info(f"Exam ID: {exam_request.exam_id}")
            # Encode Vietnamese text safely for logging
            school_safe = safe_log_text(exam_request.ten_truong) if exam_request.ten_truong else "N/A"
            subject_safe = safe_log_text(exam_request.mon_hoc) if exam_request.mon_hoc else "N/A"
            logger.info(f"School: {school_safe}")
            logger.info(f"Subject: {subject_safe}")
            logger.info(f"Grade: {exam_request.lop}")
            logger.info(f"Total questions requested: {exam_request.tong_so_cau}")
            logger.info(f"Number of lessons: {len(exam_request.cau_hinh_de)}")

            # Ensure LLM service is initialized
            self.llm_service._ensure_service_initialized()

            if not self.llm_service.is_available():
                logger.error(
                    "LLM service not available - check API configuration"
                )
                return {"success": False, "error": "LLM service not available"}

            logger.info(f"LLM service is available: {self.llm_service.is_available()}")
            logger.info(f"Lesson content keys: {list(lesson_content.keys())}")

            # T·∫°o c√¢u h·ªèi cho t·ª´ng lesson trong c·∫•u h√¨nh ƒë·ªÅ
            all_questions = []
            question_counter = 1

            for i, cau_hinh in enumerate(exam_request.cau_hinh_de):
                logger.info(
                    f"Processing cau_hinh {i+1}/{len(exam_request.cau_hinh_de)}: lesson_id {cau_hinh.lesson_id}"
                )
                logger.info(
                    f"Yeu cau can dat: {cau_hinh.yeu_cau_can_dat}"
                )

                lesson_questions = await self._generate_questions_for_lesson(
                    cau_hinh, lesson_content, question_counter
                )
                logger.info(
                    f"Generated {len(lesson_questions)} questions for lesson_id: {cau_hinh.lesson_id}"
                )
                all_questions.extend(lesson_questions)
                question_counter += len(lesson_questions)

            logger.info(f"Total questions generated: {len(all_questions)}")

            # Ki·ªÉm tra n·∫øu kh√¥ng c√≥ c√¢u h·ªèi n√†o ƒë∆∞·ª£c t·∫°o
            if len(all_questions) == 0:
                logger.error("No questions were generated. This might indicate an API issue.")
                return {"success": False, "error": "Kh√¥ng th·ªÉ t·∫°o c√¢u h·ªèi. Vui l√≤ng ki·ªÉm tra API key ho·∫∑c th·ª≠ l·∫°i sau."}

            # T·∫°o th·ªëng k√™
            statistics = self._create_exam_statistics(all_questions, exam_request)

            # S·ª≠ d·ª•ng exam_id t·ª´ request
            exam_id = exam_request.exam_id

            logger.info(f"=== EXAM GENERATION COMPLETED ===")
            logger.info(f"FINAL SUMMARY:")
            logger.info(f"  - Total questions requested: {exam_request.tong_so_cau}")
            logger.info(f"  - Total questions generated: {len(all_questions)}")
            logger.info(f"  - Success rate: {len(all_questions)/exam_request.tong_so_cau*100:.1f}%")

            # Ki·ªÉm tra n·∫øu thi·∫øu c√¢u h·ªèi
            if len(all_questions) < exam_request.tong_so_cau:
                missing_count = exam_request.tong_so_cau - len(all_questions)
                logger.warning(f"MISSING {missing_count} QUESTIONS!")

                # Ph√¢n t√≠ch thi·∫øu ·ªü m·ª©c ƒë·ªô n√†o
                for cau_hinh in exam_request.cau_hinh_de:
                    for muc_do in cau_hinh.muc_do:
                        actual_count = sum(1 for q in all_questions if q.get('muc_do') == muc_do.loai)
                        if actual_count < muc_do.so_cau:
                            # S·ª≠ d·ª•ng ASCII-safe logging ƒë·ªÉ tr√°nh encoding error
                            level_safe = safe_log_text(muc_do.loai)
                            logger.warning(f"  - {level_safe}: {actual_count}/{muc_do.so_cau} questions")

            return {
                "success": True,
                "exam_id": exam_id,
                "questions": all_questions,
                "statistics": statistics,
                "total_generated": len(all_questions),
            }

        except Exception as e:
            logger.error(f"Error generating questions from matrix: {e}")
            return {"success": False, "error": str(e)}

    def _get_content_for_lesson(self, lesson_content: Dict[str, Any], lesson_id: str) -> Dict[str, Any]:
        """
        L·∫•y n·ªôi dung c·ª• th·ªÉ cho m·ªôt lesson t·ª´ lesson_content ƒëa lesson

        Args:
            lesson_content: N·ªôi dung t·ª´ multiple lessons ho·∫∑c single lesson
            lesson_id: ID c·ªßa lesson c·∫ßn l·∫•y n·ªôi dung

        Returns:
            Dict ch·ª©a n·ªôi dung c·ªßa lesson c·ª• th·ªÉ
        """
        try:
            # Ki·ªÉm tra n·∫øu ƒë√¢y l√† format m·ªõi (multiple lessons)
            if "content" in lesson_content and isinstance(lesson_content["content"], dict):
                # N·∫øu c√≥ lesson_id trong content (multiple lessons format)
                if lesson_id in lesson_content["content"]:
                    specific_content = lesson_content["content"][lesson_id]
                    logger.info(f"Found specific content for lesson_id: {lesson_id}")
                    return specific_content
                else:
                    # Fallback: t√¨m trong t·∫•t c·∫£ lessons
                    for stored_lesson_id, stored_content in lesson_content["content"].items():
                        if stored_lesson_id == lesson_id:
                            logger.info(f"Found content for lesson_id: {lesson_id} via fallback search")
                            return stored_content


            # Fallback: n·∫øu ƒë√¢y l√† format c≈© (single lesson), s·ª≠ d·ª•ng tr·ª±c ti·∫øp
            elif "content" in lesson_content:
                logger.info(f"Using single lesson content format for lesson_id: {lesson_id}")
                return lesson_content

            # N·∫øu kh√¥ng c√≥ content n√†o
            logger.warning(f"No content structure found for lesson_id: {lesson_id}")
            return {}

        except Exception as e:
            logger.error(f"Error getting content for lesson {lesson_id}: {e}")
            return {}

    async def _generate_questions_for_lesson(
        self,
        cau_hinh: CauHinhDeModel,
        lesson_content: Dict[str, Any],
        start_counter: int,
    ) -> List[Dict[str, Any]]:
        """T·∫°o c√¢u h·ªèi cho m·ªôt lesson c·ª• th·ªÉ"""
        try:
            logger.info(f"--- Generating questions for lesson_id: {cau_hinh.lesson_id} ---")
            lesson_questions = []
            current_counter = start_counter

            # L·∫•y n·ªôi dung c·ª• th·ªÉ cho lesson n√†y
            specific_lesson_content = self._get_content_for_lesson(lesson_content, cau_hinh.lesson_id)

            if not specific_lesson_content:
                logger.warning(f"No content found for lesson_id: {cau_hinh.lesson_id}")
                logger.warning("Using fallback content or skipping this lesson")
                return []

            logger.info(f"Found content for lesson_id: {cau_hinh.lesson_id}")

            # T·∫°o c√¢u h·ªèi cho t·ª´ng m·ª©c ƒë·ªô trong lesson
            for i, muc_do in enumerate(cau_hinh.muc_do):
                logger.info(
                    f"Processing muc_do {i+1}/{len(cau_hinh.muc_do)}: {muc_do.loai} ({muc_do.so_cau} questions)"
                )
                logger.info(f"Question types for this muc_do: {muc_do.loai_cau}")

                # Chia ƒë·ªÅu s·ªë c√¢u h·ªèi gi·ªØa c√°c lo·∫°i c√¢u
                total_question_types = len(muc_do.loai_cau)
                questions_per_type = muc_do.so_cau // total_question_types
                remaining_questions = muc_do.so_cau % total_question_types

                logger.info(f"Distributing {muc_do.so_cau} questions across {total_question_types} types: {questions_per_type} per type, {remaining_questions} remaining")

                # T·∫°o c√¢u h·ªèi cho t·ª´ng lo·∫°i c√¢u trong m·ª©c ƒë·ªô n√†y
                for k, loai_cau in enumerate(muc_do.loai_cau):
                    # T√≠nh s·ªë c√¢u h·ªèi cho lo·∫°i c√¢u n√†y
                    questions_for_this_type = questions_per_type
                    if k < remaining_questions:  # Ph√¢n ph·ªëi c√¢u h·ªèi d∆∞ cho c√°c lo·∫°i ƒë·∫ßu ti√™n
                        questions_for_this_type += 1

                    logger.info(
                        f"Generating {questions_for_this_type} {loai_cau} questions for {muc_do.loai} level..."
                    )

                    # Chia nh·ªè request n·∫øu s·ªë c√¢u l·ªõn
                    questions = await self._generate_questions_with_batching_for_lesson(
                        cau_hinh,
                        muc_do.loai,
                        questions_for_this_type,
                        loai_cau,
                        specific_lesson_content,
                        current_counter,
                    )

                    logger.info(f"Generated {len(questions)} {loai_cau} questions")
                    lesson_questions.extend(questions)
                    current_counter += len(questions)

            logger.info(
                f"Total questions generated for lesson_id '{cau_hinh.lesson_id}': {len(lesson_questions)}"
            )
            return lesson_questions

        except Exception as e:
            logger.error(f"Error generating questions for lesson: {e}")
            return []


    def _create_question_prompt(
        self,
        noi_dung: Dict[str, Any],
        muc_do: MucDoModel,
        loai_cau: str,
        lesson_content: Dict[str, Any],
        bai_name: str,
    ) -> str:
        """T·∫°o prompt cho Gemini ƒë·ªÉ t·∫°o c√¢u h·ªèi"""

        # L·∫•y n·ªôi dung b√†i h·ªçc
        main_content = lesson_content.get("content", {}).get("main_content", "")
        lesson_info = lesson_content.get("content", {}).get("lesson_info", {})

        # Template prompt c∆° b·∫£n
        base_prompt = f"""
B·∫°n l√† m·ªôt chuy√™n gia gi√°o d·ª•c v√† ra ƒë·ªÅ thi chuy√™n nghi·ªáp. H√£y t·∫°o c√¢u h·ªèi ki·ªÉm tra cho h·ªçc sinh.

TH√îNG TIN B√ÄI H·ªåC:
- B√†i h·ªçc: {bai_name}
- Ch∆∞∆°ng: {lesson_info.get('chapter_title', '')}
- N·ªôi dung ki·∫øn th·ª©c: {noi_dung.get('ten_noi_dung', 'Unknown')}
- Y√™u c·∫ßu c·∫ßn ƒë·∫°t: {noi_dung.get('yeu_cau_can_dat', 'Unknown')}

N·ªòI DUNG B√ÄI H·ªåC:
{main_content[:2000]}...

Y√äU C·∫¶U T·∫†O C√ÇU H·ªéI:
- Lo·∫°i c√¢u h·ªèi: {self._get_question_type_description(loai_cau)}
- M·ª©c ƒë·ªô nh·∫≠n th·ª©c: {muc_do.loai}
- S·ªë l∆∞·ª£ng c√¢u h·ªèi: {muc_do.so_cau}

{self._get_specific_prompt_by_type(loai_cau, muc_do.loai)}

ƒê·ªäNH D·∫†NG TR‡∏≤‡∏≤·∫¢ L·ªúI (JSON):
[
    {{
        "cau_hoi": "N·ªôi dung c√¢u h·ªèi",
        "dap_an": {self._get_answer_format_by_type(loai_cau)},
        "giai_thich": "Gi·∫£i th√≠ch ƒë√°p √°n"
    }}
]

QUAN TR·ªåNG - ƒê·ªäNH D·∫†NG B·∫ÆT BU·ªòC:
- V·ªõi c√¢u tr·∫Øc nghi·ªám (TN), B·∫ÆT BU·ªòC ph·∫£i c√≥ tr∆∞·ªùng "dung" trong dap_an ƒë·ªÉ ch·ªâ ra ƒë√°p √°n ƒë√∫ng (A, B, C ho·∫∑c D)
- V√≠ d·ª•: "dap_an": {{"A": "...", "B": "...", "C": "...", "D": "...", "dung": "A"}}
- Tr∆∞·ªùng "dung" ph·∫£i ch·ª©a ch√≠nh x√°c m·ªôt trong c√°c gi√° tr·ªã: "A", "B", "C", "D"
- ƒê√°p √°n trong tr∆∞·ªùng "dung" ph·∫£i kh·ªõp v·ªõi n·ªôi dung gi·∫£i th√≠ch
- KH√îNG BAO GI·ªú ƒë·ªÉ tr·ªëng tr∆∞·ªùng "dung" - lu√¥n ph·∫£i ch·ªâ r√µ ƒë√°p √°n ƒë√∫ng
- Trong ph·∫ßn "giai_thich", h√£y b·∫Øt ƒë·∫ßu b·∫±ng "ƒê√°p √°n: [A/B/C/D]" ƒë·ªÉ r√µ r√†ng
- KH√îNG BAO GI·ªú th√™m th√¥ng tin kh√¥ng li√™n quan v√†o "giai_thich"
- KH√îNG BAO GI·ªú th√™m th√¥ng tin kh√¥ng li√™n quan v√†o "cau_hoi"
- KH√îNG BAO GI·ªú th√™m th√¥ng tin kh√¥ng li√™n quan v√†o "dap_an"
- KH√îNG BAO GI·ªú t·∫°o c√¢u h·ªèi c√≥ n·ªôi dung tr√πng l·∫∑p

H√£y t·∫°o {muc_do.so_cau} c√¢u h·ªèi ch·∫•t l∆∞·ª£ng cao, ph√π h·ª£p v·ªõi m·ª©c ƒë·ªô {muc_do.loai}.
"""
        return base_prompt

    def _get_question_type_description(self, loai_cau: str) -> str:
        """M√¥ t·∫£ lo·∫°i c√¢u h·ªèi"""
        descriptions = {
            "TN": "Tr·∫Øc nghi·ªám nhi·ªÅu l·ª±a ch·ªçn (4 ƒë√°p √°n A, B, C, D)",
            "DT": "ƒêi·ªÅn t·ª´/c·ª•m t·ª´ v√†o ch·ªó tr·ªëng",
            "DS": "ƒê√∫ng/Sai v·ªõi 4 √Ω nh·ªè",
            "TL": "T·ª± lu·∫≠n ng·∫Øn",
        }
        return descriptions.get(loai_cau, "Kh√¥ng x√°c ƒë·ªãnh")

    def _get_specific_prompt_by_type(self, loai_cau: str, muc_do: str) -> str:
        """T·∫°o prompt c·ª• th·ªÉ theo lo·∫°i c√¢u h·ªèi v√† m·ª©c ƒë·ªô"""

        if loai_cau == "TN":
            if muc_do == "Nh·∫≠n bi·∫øt":
                return """
H∆Ø·ªöNG D·∫™N T·∫†O C√ÇU TR·∫ÆC NGHI·ªÜM NH·∫¨N BI·∫æT:
- H·ªèi v·ªÅ ƒë·ªãnh nghƒ©a, kh√°i ni·ªám c∆° b·∫£n
- Nh·∫≠n bi·∫øt c√¥ng th·ª©c, k√Ω hi·ªáu
- 4 ƒë√°p √°n r√µ r√†ng, ch·ªâ 1 ƒë√°p √°n ƒë√∫ng
- Tr√°nh c√¢u h·ªèi m∆° h·ªì ho·∫∑c g√¢y nh·∫ßm l·∫´n
- ƒê·∫£m b·∫£o ƒë√°p √°n ƒë√∫ng ph·∫£n √°nh ch√≠nh x√°c ki·∫øn th·ª©c khoa h·ªçc
- C√°c ƒë√°p √°n sai ph·∫£i h·ª£p l√Ω nh∆∞ng r√µ r√†ng l√† sai
"""
            elif muc_do == "Th√¥ng hi·ªÉu":
                return """
H∆Ø·ªöNG D·∫™N T·∫†O C√ÇU TR·∫ÆC NGHI·ªÜM TH√îNG HI·ªÇU:
- H·ªèi v·ªÅ m·ªëi quan h·ªá gi·ªØa c√°c kh√°i ni·ªám
- Gi·∫£i th√≠ch hi·ªán t∆∞·ª£ng, qu√° tr√¨nh
- So s√°nh, ph√¢n lo·∫°i
- ƒê√°p √°n y√™u c·∫ßu hi·ªÉu bi·∫øt s√¢u h∆°n
"""
            else:  # V·∫≠n d·ª•ng
                return """
H∆Ø·ªöNG D·∫™N T·∫†O C√ÇU TR·∫ÆC NGHI·ªÜM V·∫¨N D·ª§NG:
- √Åp d·ª•ng ki·∫øn th·ª©c v√†o t√¨nh hu·ªëng c·ª• th·ªÉ
- Gi·∫£i quy·∫øt b√†i t·∫≠p, t√≠nh to√°n
- Ph√¢n t√≠ch, ƒë√°nh gi√°
- ƒê√°p √°n y√™u c·∫ßu t∆∞ duy logic
"""

        elif loai_cau == "DT":
            return """
H∆Ø·ªöNG D·∫™N T·∫†O C√ÇU ƒêI·ªÄN T·ª™:
- T·∫°o c√¢u c√≥ ch·ªó tr·ªëng (...) ho·∫∑c _____
- T·ª´ c·∫ßn ƒëi·ªÅn ph·∫£i ch√≠nh x√°c, kh√¥ng m∆° h·ªì
- C√≥ th·ªÉ c√≥ nhi·ªÅu t·ª´ ƒë·ªìng nghƒ©a ƒë∆∞·ª£c ch·∫•p nh·∫≠n
- ƒê·ªô d√†i t·ª´ c·∫ßn ƒëi·ªÅn ph√π h·ª£p v·ªõi m·ª©c ƒë·ªô
"""

        elif loai_cau == "DS":
            return """
H∆Ø·ªöNG D·∫™N T·∫†O C√ÇU ƒê√öNG/SAI:
- T·∫°o 4 √Ω nh·ªè (a, b, c, d)
- M·ªói √Ω c√≥ th·ªÉ ƒë√∫ng ho·∫∑c sai
- C√°c √Ω ph·∫£i li√™n quan ƒë·∫øn c√πng ch·ªß ƒë·ªÅ
- Tr√°nh √Ω qu√° d·ªÖ ho·∫∑c qu√° kh√≥
"""

        else:  # TL
            return """
H∆Ø·ªöNG D·∫™N T·∫†O C√ÇU T·ª∞ LU·∫¨N:
- C√¢u h·ªèi m·ªü, y√™u c·∫ßu tr√¨nh b√†y, gi·∫£i th√≠ch
- C√≥ th·ªÉ chia th√†nh nhi·ªÅu √Ω nh·ªè
- ƒê√°p √°n c√≥ th·ªÉ linh ho·∫°t nh∆∞ng ph·∫£i c√≥ ƒëi·ªÉm ch√≠nh
- Ph√π h·ª£p v·ªõi th·ªùi gian l√†m b√†i
"""

    def _get_answer_format_by_type(self, loai_cau: str) -> str:
        """ƒê·ªãnh d·∫°ng ƒë√°p √°n theo lo·∫°i c√¢u h·ªèi"""
        formats = {
            "TN": '{"A": "ƒê√°p √°n A", "B": "ƒê√°p √°n B", "C": "ƒê√°p √°n C", "D": "ƒê√°p √°n D", "dung": "A"}',
            "DT": '{"dap_an_chinh": "t·ª´ c·∫ßn ƒëi·ªÅn", "dap_an_khac": ["t·ª´ ƒë·ªìng nghƒ©a 1", "t·ª´ ƒë·ªìng nghƒ©a 2"]}',
            "DS": '{"a": true, "b": false, "c": true, "d": false}',
            "TL": '{"y_chinh": ["√ù 1", "√ù 2", "√ù 3"], "diem_toi_da": 2}',
        }
        return formats.get(loai_cau, "{}")

    def _parse_questions_response(self, response_text: str) -> List[Dict[str, Any]]:
        """Parse response t·ª´ Gemini th√†nh list c√¢u h·ªèi"""
        try:
            logger.info("Starting to parse Gemini response...")
            logger.debug(f"Original response text: {response_text}")

            original_text = response_text
            all_questions = []

            # T√¨m t·∫•t c·∫£ c√°c JSON blocks trong response
            import re

            # Pattern ƒë·ªÉ t√¨m JSON arrays trong ```json blocks
            json_pattern = r'```json\s*(\[.*?\])\s*```'
            matches = re.findall(json_pattern, response_text, re.DOTALL)

            logger.info(f"Found {len(matches)} JSON blocks in response")

            for i, match in enumerate(matches):
                try:
                    logger.info(f"Parsing JSON block {i+1}...")
                    logger.debug(f"JSON block {i+1}: {match}")

                    questions = json.loads(match)
                    if isinstance(questions, list):
                        all_questions.extend(questions)
                        logger.info(f"Added {len(questions)} questions from block {i+1}")
                    else:
                        all_questions.append(questions)
                        logger.info(f"Added 1 question from block {i+1}")

                except json.JSONDecodeError as e:
                    logger.error(f"Failed to parse JSON block {i+1}: {e}")
                    continue

            # N·∫øu kh√¥ng t√¨m th·∫•y JSON blocks, th·ª≠ t√¨m JSON array tr·ª±c ti·∫øp
            if not all_questions:
                logger.info("No JSON blocks found, trying direct JSON array extraction...")

                # T√¨m JSON array ƒë·∫ßu ti√™n
                start_idx = response_text.find("[")
                if start_idx != -1:
                    # T√¨m ] t∆∞∆°ng ·ª©ng
                    bracket_count = 0
                    end_idx = -1
                    for i in range(start_idx, len(response_text)):
                        if response_text[i] == '[':
                            bracket_count += 1
                        elif response_text[i] == ']':
                            bracket_count -= 1
                            if bracket_count == 0:
                                end_idx = i
                                break

                    if end_idx != -1:
                        json_text = response_text[start_idx:end_idx + 1]
                        logger.info(f"Extracted JSON array: {len(json_text)} characters")
                        logger.debug(f"JSON text: {json_text}")

                        try:
                            questions = json.loads(json_text)
                            if isinstance(questions, list):
                                all_questions.extend(questions)
                                logger.info(f"Added {len(questions)} questions from direct extraction")
                            else:
                                all_questions.append(questions)
                                logger.info(f"Added 1 question from direct extraction")
                        except json.JSONDecodeError as e:
                            logger.error(f"Failed to parse direct JSON: {e}")

            logger.info(f"Total questions parsed: {len(all_questions)}")

            # Debug: Log first question structure
            if all_questions:
                logger.info("=== DEBUGGING FIRST QUESTION ===")
                first_q = all_questions[0]
                logger.info(f"First question keys: {list(first_q.keys())}")
                logger.info(f"First question content: {first_q}")

                # Check specific fields
                cau_hoi = first_q.get('cau_hoi', 'MISSING')
                noi_dung = first_q.get('noi_dung', 'MISSING')
                de_bai = first_q.get('de_bai', 'MISSING')
                logger.info(f"cau_hoi field: '{cau_hoi}'")
                logger.info(f"noi_dung field: '{noi_dung}'")
                logger.info(f"de_bai field: '{de_bai}'")
                logger.info("=== END DEBUG ===")

            return all_questions

        except Exception as e:
            logger.error(f"Error parsing questions response: {e}")
            logger.error(f"Response text: {response_text}")
            return []

    def _create_exam_statistics(
        self, questions: List[Dict[str, Any]], exam_request: ExamMatrixRequest
    ) -> Dict[str, Any]:
        """T·∫°o th·ªëng k√™ cho ƒë·ªÅ thi"""
        try:
            # Th·ªëng k√™ theo lo·∫°i c√¢u h·ªèi
            loai_count = {}
            muc_do_count = {}
            bai_count = {}

            for q in questions:
                # ƒê·∫øm theo lo·∫°i c√¢u
                loai = q.get("loai_cau", "")
                loai_count[loai] = loai_count.get(loai, 0) + 1

                # ƒê·∫øm theo m·ª©c ƒë·ªô
                muc_do = q.get("muc_do", "")
                muc_do_count[muc_do] = muc_do_count.get(muc_do, 0) + 1

                # ƒê·∫øm theo b√†i
                bai = q.get("bai_hoc", "")
                bai_count[bai] = bai_count.get(bai, 0) + 1

            return {
                "tong_so_cau": len(questions),
                "phan_bo_theo_loai": loai_count,
                "phan_bo_theo_muc_do": muc_do_count,
                "phan_bo_theo_bai": bai_count,
                "mon_hoc": exam_request.mon_hoc,
                "lop": exam_request.lop,
            }

        except Exception as e:
            logger.error(f"Error creating exam statistics: {e}")
            return {}



    def _sanitize_id(self, id_string: str) -> str:
        """
        L√†m s·∫°ch ID ƒë·ªÉ tr√°nh l·ªói encoding

        Args:
            id_string: ID g·ªëc

        Returns:
            ID ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch (ch·ªâ ch·ª©a ASCII)
        """
        try:
            # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát v√† d·∫•u ti·∫øng Vi·ªát
            # Ch·ªâ gi·ªØ l·∫°i ch·ªØ c√°i, s·ªë, d·∫•u g·∫°ch d∆∞·ªõi v√† g·∫°ch ngang
            sanitized = re.sub(r"[^\w\-_]", "_", id_string)

            # Lo·∫°i b·ªè nhi·ªÅu d·∫•u g·∫°ch d∆∞·ªõi li√™n ti·∫øp
            sanitized = re.sub(r"_+", "_", sanitized)

            # Lo·∫°i b·ªè d·∫•u g·∫°ch d∆∞·ªõi ·ªü ƒë·∫ßu v√† cu·ªëi
            sanitized = sanitized.strip("_")

            # N·∫øu k·∫øt qu·∫£ r·ªóng, d√πng default
            if not sanitized:
                sanitized = "lesson"

            return sanitized

        except Exception as e:
            logger.warning(f"Error sanitizing ID '{id_string}': {e}")
            return "lesson"

    def _extract_correct_answer_from_explanation(self, explanation: str, dap_an: dict) -> str:
        """Tr√≠ch xu·∫•t ƒë√°p √°n ƒë√∫ng t·ª´ gi·∫£i th√≠ch"""
        try:
            if not explanation or not isinstance(dap_an, dict):
                return ""

            explanation_lower = explanation.lower()
            logger.debug(f"Analyzing explanation: {explanation[:100]}...")

            # T√¨m c√°c pattern r√µ r√†ng nh·∫•t tr∆∞·ªõc (pattern c√≥ t·ª´ "ƒë√∫ng")
            strong_patterns = [
                r"ƒë√°p √°n ([abcd]) ƒë√∫ng",
                r"ƒë√°p √°n ƒë√∫ng l√† ([abcd])",
                r"([abcd]) ƒë√∫ng v√¨",
                r"([abcd]) l√† ƒë√°p √°n ƒë√∫ng",
                r"([abcd]) ƒë√∫ng",
                r"ch·ªçn ƒë√°p √°n ([abcd])",
                r"ƒë√°p √°n:\s*([abcd])",
                r"ƒë√°p √°n\s+([abcd])"
            ]

            for pattern in strong_patterns:
                match = re.search(pattern, explanation_lower)
                if match:
                    answer = match.group(1).upper()
                    if answer in dap_an:
                        logger.info(f"Found correct answer '{answer}' using strong pattern: {pattern}")
                        return answer

            # T√¨m pattern y·∫øu h∆°n (ch·ªâ ƒë·ªÅ c·∫≠p ƒë·∫øn ƒë√°p √°n)
            weak_patterns = [
                r"ƒë√°p √°n ([abcd])",
                r"ch·ªçn ([abcd])",
                r"([abcd])\s*[:\-\.]",
                r"^([abcd])\s",
                r"\b([abcd])\b.*ch√≠nh x√°c",
                r"\b([abcd])\b.*ƒë√∫ng"
            ]

            for pattern in weak_patterns:
                match = re.search(pattern, explanation_lower)
                if match:
                    answer = match.group(1).upper()
                    if answer in dap_an:
                        logger.info(f"Found correct answer '{answer}' using weak pattern: {pattern}")
                        return answer

            # Ph√¢n t√≠ch ng·ªØ c·∫£nh th√¥ng minh h∆°n
            # T√¨m c√°c t·ª´ kh√≥a ch·ªâ ra ƒë√°p √°n ƒë√∫ng
            context_keywords = [
                'ƒë√∫ng', 'ch√≠nh x√°c', 'ph√π h·ª£p', 'l√†', 'v√¨', 'do', 'b·ªüi v√¨',
                'n√™n', 'n√≥', 'ƒëi·ªÅu n√†y', 'v·∫≠y', 'nh∆∞ v·∫≠y'
            ]

            # T√°ch th√†nh c√°c c√¢u v√† ph√¢n t√≠ch
            sentences = explanation_lower.split('.')
            for sentence in sentences:
                sentence = sentence.strip()
                if any(keyword in sentence for keyword in context_keywords):
                    # T√¨m ƒë√°p √°n ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn trong c√¢u n√†y
                    for option in ['A', 'B', 'C', 'D']:
                        if option.lower() in sentence and option in dap_an:
                            # Ki·ªÉm tra xem c√≥ ph·∫£i ƒëang n√≥i v·ªÅ ƒë√°p √°n ƒë√∫ng kh√¥ng
                            if any(keyword in sentence for keyword in ['ƒë√∫ng', 'ch√≠nh x√°c', 'ph√π h·ª£p']):
                                logger.info(f"Found correct answer '{option}' by context analysis in sentence: {sentence[:50]}...")
                                return option

            # N·∫øu v·∫´n kh√¥ng t√¨m th·∫•y, th·ª≠ ph√¢n t√≠ch n·ªôi dung ƒë√°p √°n
            # T√¨m ƒë√°p √°n c√≥ n·ªôi dung ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn nhi·ªÅu nh·∫•t trong gi·∫£i th√≠ch
            option_scores = {}
            for option, content in dap_an.items():
                if option in ['A', 'B', 'C', 'D'] and isinstance(content, str):
                    # ƒê·∫øm s·ªë t·ª´ kh√≥a t·ª´ n·ªôi dung ƒë√°p √°n xu·∫•t hi·ªán trong gi·∫£i th√≠ch
                    content_words = content.lower().split()
                    score = 0
                    for word in content_words:
                        if len(word) > 2 and word in explanation_lower:  # Ch·ªâ ƒë·∫øm t·ª´ c√≥ √Ω nghƒ©a
                            score += 1
                    option_scores[option] = score

            if option_scores:
                best_option = max(option_scores.keys(), key=lambda x: option_scores[x])
                if option_scores[best_option] > 0:
                    logger.info(f"Found correct answer '{best_option}' by content analysis with score: {option_scores[best_option]}")
                    return best_option

            logger.warning("Could not extract correct answer from explanation")
            logger.debug(f"Full explanation: {explanation}")
            logger.debug(f"Available options: {list(dap_an.keys())}")
            return ""

        except Exception as e:
            logger.error(f"Error extracting correct answer: {e}")
            return ""


    async def _generate_questions_with_batching_for_lesson(
        self,
        cau_hinh: CauHinhDeModel,
        muc_do_loai: str,
        total_questions: int,
        loai_cau: str,
        lesson_content: Dict[str, Any],
        start_counter: int,
    ) -> List[Dict[str, Any]]:
        """T·∫°o c√¢u h·ªèi v·ªõi c∆° ch·∫ø chia nh·ªè batch cho lesson format m·ªõi"""
        try:
            logger.info(f"Starting batched question generation for lesson: {total_questions} questions")

            # C·∫•u h√¨nh batch size
            max_questions_per_batch = 8
            all_questions = []

            if total_questions <= max_questions_per_batch:
                # T·∫°o m·ªôt l·∫ßn n·∫øu s·ªë c√¢u √≠t
                temp_muc_do = MucDoModel(
                    loai=cast(Any, muc_do_loai),
                    so_cau=total_questions,
                    loai_cau=cast(Any, [loai_cau])
                )

                questions = await self._generate_questions_by_type_for_lesson(
                    cau_hinh, temp_muc_do, loai_cau, lesson_content, start_counter
                )
                all_questions.extend(questions)
            else:
                # Chia th√†nh nhi·ªÅu batch
                remaining_questions = total_questions
                current_counter = start_counter
                batch_number = 1

                while remaining_questions > 0:
                    batch_size = min(remaining_questions, max_questions_per_batch)
                    logger.info(f"Processing batch {batch_number}: {batch_size} questions")

                    temp_muc_do = MucDoModel(
                        loai=cast(Any, muc_do_loai),
                        so_cau=batch_size,
                        loai_cau=cast(Any, [loai_cau])
                    )

                    try:
                        batch_questions = await self._generate_questions_by_type_for_lesson(
                            cau_hinh, temp_muc_do, loai_cau, lesson_content, current_counter
                        )

                        if batch_questions:
                            all_questions.extend(batch_questions)
                            current_counter += len(batch_questions)
                            remaining_questions -= len(batch_questions)
                        else:
                            logger.warning(f"No questions generated for batch {batch_number}")
                            remaining_questions -= batch_size

                        batch_number += 1

                        if remaining_questions > 0:
                            await asyncio.sleep(1)

                    except Exception as e:
                        logger.error(f"Error in batch {batch_number}: {e}")
                        remaining_questions -= batch_size
                        batch_number += 1

            logger.info(f"Total batched questions generated for lesson: {len(all_questions)}")
            return all_questions

        except Exception as e:
            logger.error(f"Error in batched question generation for lesson: {e}")
            return []

    async def _generate_questions_by_type_for_lesson(
        self,
        cau_hinh: CauHinhDeModel,
        muc_do: MucDoModel,
        loai_cau: str,
        lesson_content: Dict[str, Any],
        start_counter: int,
    ) -> List[Dict[str, Any]]:
        """T·∫°o c√¢u h·ªèi theo lo·∫°i cho lesson format m·ªõi"""
        try:
            logger.info(f"Generating {muc_do.so_cau} {loai_cau} questions for lesson {cau_hinh.lesson_id}")

            # T·∫°o prompt cho LLM s·ª≠ d·ª•ng method c√≥ s·∫µn
            # T·∫°o fake noi_dung t·ª´ cau_hinh
            fake_noi_dung = {
                "ten_noi_dung": f"Lesson {cau_hinh.lesson_id}",
                "yeu_cau_can_dat": cau_hinh.yeu_cau_can_dat,
                "muc_do": [muc_do]
            }

            prompt = self._create_question_prompt(
                fake_noi_dung, muc_do, loai_cau, lesson_content, f"Lesson {cau_hinh.lesson_id}"
            )

            # G·ªçi LLM ƒë·ªÉ t·∫°o c√¢u h·ªèi
            response = await self.llm_service.format_document_text(prompt, "exam_questions")

            if not response or not response.get("success", False):
                logger.error(f"LLM failed to generate questions: {response}")
                return []

            # Parse response v√† format c√¢u h·ªèi
            questions_text = response.get("formatted_text", "")
            if not questions_text:
                logger.error("Empty response from LLM")
                return []

            # S·ª≠ d·ª•ng method c√≥ s·∫µn ƒë·ªÉ parse c√¢u h·ªèi
            parsed_questions = self._parse_questions_response(questions_text)

            # Format c√¢u h·ªèi v·ªõi metadata
            formatted_questions = []
            for i, q_data in enumerate(parsed_questions):
                if not q_data.get("cau_hoi") or not q_data.get("dap_an"):
                    continue

                question = {
                    "stt": start_counter + i,
                    "loai_cau": loai_cau,
                    "muc_do": muc_do.loai,
                    "noi_dung_cau_hoi": q_data.get("cau_hoi", ""),  # Fix: s·ª≠ d·ª•ng field name nh·∫•t qu√°n
                    "dap_an": q_data.get("dap_an", {}),
                    "giai_thich": q_data.get("giai_thich", ""),
                    "bai_hoc": f"Lesson {cau_hinh.lesson_id}",
                    "noi_dung_kien_thuc": cau_hinh.yeu_cau_can_dat,
                }
                formatted_questions.append(question)

            logger.info(f"Successfully generated {len(formatted_questions)} questions for lesson {cau_hinh.lesson_id}")
            return formatted_questions

        except Exception as e:
            logger.error(f"Error generating questions by type for lesson: {e}")
            return []


# Factory function ƒë·ªÉ t·∫°o ExamGenerationService instance
def get_exam_generation_service() -> ExamGenerationService:
    """
    T·∫°o ExamGenerationService instance m·ªõi

    Returns:
        ExamGenerationService: Fresh instance
    """
    return ExamGenerationService()
